{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "import torch\n",
    "import torch.nn.functional as F\n",
    "import numpy as np\n",
    "import random\n",
    "import sys\n",
    "sys.path.insert(0,'..')\n",
    "\n",
    "from dfibert.tracker.nn.rl import Agent\n",
    "import dfibert.envs.RLTractEnvironment as RLTe\n",
    "from dfibert.tracker import save_streamlines\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib notebook\n",
    "\n",
    "#from train import load_model"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "# I. HCP Tracking\n",
    "The environment is able to run tracking on a fixed set of datasets. At the moment, it is able to load HCP data as well as ISMRM data. The following cells shows the initalisation of our environment on HCP dataset `100307` while seed points are automatically determined at voxels with fa-value >= 0.2 via `seeds = None`."
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "env = RLTe.RLTractEnvironment(step_width=0.8, dataset = '100307',\n",
    "                              device = 'cpu', seeds = None, tracking_in_RAS = False,\n",
    "                              odf_state = False, odf_mode = \"DTI\")"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "streamlines = env.track()"
   ],
   "outputs": [],
   "metadata": {
    "scrolled": true
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "We can also directly visualize our streamlines in this notebook by `ax.plot3d`. However, a single streamline is typically very hard to comprehend so this is merely one tool to qualitatively reason about major bugs in our tracking code."
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "%matplotlib notebook\n",
    "streamline_index = 9\n",
    "streamline_np = np.stack(streamlines[streamline_index])\n",
    "\n",
    "fig = plt.figure()\n",
    "ax = plt.axes(projection='3d')\n",
    "#ax.plot3D(env.referenceStreamline_ijk.T[0], env.referenceStreamline_ijk.T[1], env.referenceStreamline_ijk.T[2], '-*')\n",
    "ax.plot3D(streamline_np[:,0], streamline_np[:,1], streamline_np[:,2])\n",
    "#plt.legend(['gt', 'agent'])\n",
    "plt.legend('agent')"
   ],
   "outputs": [],
   "metadata": {
    "scrolled": true
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "# II. Evaluation of Cortico Spinal Tract @ ISMRM benchmark data\n",
    "We will now be using our environment along with our reward function to track streamlines on the ISMRM dataset. For this purpose, we first initialise our environment and set seed points to the cortico spinal tract. We precomputed seed points in IJK for our ISMRM dataset. These seeds will now be loaded into our environment."
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "seeds_CST = np.load('data/ismrm_seeds_CST.npy')\n",
    "seeds_CST = torch.from_numpy(seeds_CST)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "env = RLTe.RLTractEnvironment(dataset = 'ISMRM', step_width=0.8,\n",
    "                            device = 'cpu', seeds = seeds_CST[0:100,:], action_space=100,\n",
    "                              tracking_in_RAS = False, odf_state = False, odf_mode = \"DTI\")"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "Tracking itself can now be done by basically calling the `.track()` function that tracks our streamlines from each of the provided seed points in a forward and backward direciton."
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "streamlines = env.track()"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "The streamlines are now stored as VTK file. The nice thing about this format is that we can directly import the streamlines into 3dSlicer via the slicer-dMRI extension."
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "streamlines_ras = [env.dataset.to_ras(sl) for sl in streamlines]"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "save_streamlines(streamlines=streamlines_ras, path=\"ismrm_cst2_ras_100actions_hemi.vtk\")"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "def convPoint(p, dims):\n",
    "    dims = dims - 1\n",
    "    return (p - dims/2.) / (dims/2.)\n",
    "\n",
    "def interpolate3dAtt(data, positions):\n",
    "    # Data is supposed to be CxHxWxD\n",
    "    # normalise coordinates into range [-1,1]\n",
    "    pts = positions.to(torch.float)\n",
    "    pts = convPoint(pts, torch.tensor(data.shape[1:4]))\n",
    "    # reverse pts\n",
    "    pts = pts[:,(2,1,0)]\n",
    "    # trilinear interpolation\n",
    "    return torch.nn.functional.grid_sample(data.unsqueeze(0), \n",
    "                               pts.unsqueeze(0).unsqueeze(0).unsqueeze(0),\n",
    "                               align_corners = False, mode = \"nearest\")"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "interpolate3dAtt(env.tractMasksAllBundles, torch.from_numpy(np.array([[30,50,30]]))).squeeze().shape"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "torch.mean(na_reward_history, dim = 0)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "na_reward_history[0,:] = 1"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "na_reward_history = torch.zeros((env.maxSteps, env.tractMasksAllBundles.shape[0]))"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "from torch.utils.data import Dataset, DataLoader\n",
    "from dfibert.tracker import save_streamlines, load_streamlines\n",
    "\n",
    "class FiberBundleDatasetv2(Dataset):\n",
    "    def __init__(self, path_to_files, b_val = 1000, device = \"cpu\", dataset = None):\n",
    "        streamlines = load_streamlines(path=path_to_files)\n",
    "        \n",
    "        if(dataset is None):\n",
    "            preprocessor = DataPreprocessor().normalize().crop(b_val).fa_estimate()\n",
    "            dataset = preprocessor.get_ismrm(f\"data/ISMRM2015/\")\n",
    "        self.dataset = dataset\n",
    "        self.streamlines = [torch.from_numpy(self.dataset.to_ijk(sl)).to(device) for sl in streamlines]\n",
    "        self.tractMask = torch.zeros(self.dataset.binary_mask.shape)\n",
    "        \n",
    "        for sl in self.streamlines:\n",
    "            pi = torch.floor(sl).to(torch.long)\n",
    "            self.tractMask[pi.chunk(chunks=3, dim = 1)] = 1\n",
    "    \n",
    "    def __len__(self):\n",
    "        return len(self.streamlines)\n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        streamline = self.streamlines[idx]\n",
    "        sl_1 = streamline[0:-2]\n",
    "        sl_2 = streamline[1:-1]\n",
    "        return sl_1, sl_2\n"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "fibv2.streamlines[0].chunk(chunks=3, dim = 1)[3]"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "fibv2 = FiberBundleDatasetv2(path_to_files=\"data/ISMRM2015/gt_bundles/SLF_left.fib\", dataset = dataset)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "fibv1 = FiberBundleDataset(path_to_files=\"data/ISMRM2015/gt_bundles/SLF_left.fib\", dataset = dataset)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "torch.sum(fibv2.tractMask)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "torch.sum(fibv1.tractMask)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Reinforcement Learning\n",
    "## DQN"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "from dfibert.envs.NARLTractEnvironment import NARLTractEnvironment as RLEnv"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "# init env\n",
    "#seeds_CST = np.load('data/ismrm_seeds_CST.npy')\n",
    "#seeds_CST = torch.from_numpy(seeds_CST)\n",
    "env = RLEnv(dataset = 'ISMRM', step_width=0.2,\n",
    "            device = 'cpu', action_space=20,\n",
    "            odf_mode = \"DTI\")#, seeds = seeds_CST)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "from dipy.tracking.utils import random_seeds_from_mask\n",
    "temp_seeds = env.seeds\n",
    "env.seeds = random_seeds_from_mask(env.dataset.binary_mask,\n",
    "seeds_count=10000,\n",
    "seed_count_per_voxel=False,\n",
    "affine=env.dataset.aff)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "from dfibert.tracker.nn.rainbow_agent import DQNAgent"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "# Hyperparameters:\n",
    "replay_memory_size = 100000\n",
    "batch_size = 512\n",
    "target_update = 10000\n",
    "gamma = 0.95\n",
    "max_steps = 60000000\n",
    "\n",
    "path = './training_lower_stepwidth'"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "agent = DQNAgent(env=env, memory_size = replay_memory_size,\n",
    "        batch_size = batch_size,\n",
    "        target_update = target_update,\n",
    "        gamma = gamma)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "# start training\n",
    "%matplotlib inline\n",
    "agent.train(num_steps = max_steps, checkpoint_interval=2000, path = path, plot=True)"
   ],
   "outputs": [],
   "metadata": {
    "scrolled": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "# resume the training process\n",
    "agent.resume_training(path='./training_test/checkpoints/rainbow_14000_16.65.pth', plot=True)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "# load a saved checkpoint\n",
    "agent = DQNAgent(env=env, \n",
    "        memory_size = replay_memory_size,   # memory + batch size and target update will be overwritten with the\n",
    "        batch_size = batch_size,            # saved parameters\n",
    "        target_update = target_update)\n",
    "num_steps, rewards, losses, max_steps = agent._load_model('./training_test/checkpoints/rainbow_248000_15.00.pth')"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "seeds = env.seeds\n",
    "env.seeds = env.seeds[:100]"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "# calculate and save tractogram with trained agent\n",
    "streamlines = agent.create_tractogram(path=\"ismrm_defi_15.0.vtk\")\n",
    "#streamlines = env.track()"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "save_streamlines(streamlines=streamlines, path=\"./ismrm_defi_15.0.vtk\")"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "counter = 0\n",
    "for i in range(len(streamlines)):\n",
    "    if len(streamlines[i])>10:\n",
    "        counter +=1\n",
    "\n",
    "print(counter)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "# plot rewards and losses for loaded checkpoint\n",
    "%matplotlib inline\n",
    "agent._plot(num_steps, rewards, losses)"
   ],
   "outputs": [],
   "metadata": {}
  }
 ],
 "metadata": {
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3.8.3 64-bit ('torch': conda)"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  },
  "latex_envs": {
   "LaTeX_envs_menu_present": true,
   "autoclose": false,
   "autocomplete": true,
   "bibliofile": "biblio.bib",
   "cite_by": "apalike",
   "current_citInitial": 1,
   "eqLabelWithNumbers": true,
   "eqNumInitial": 1,
   "hotkeys": {
    "equation": "Ctrl-E",
    "itemize": "Ctrl-I"
   },
   "labels_anchors": false,
   "latex_user_defs": false,
   "report_style_numbering": false,
   "user_envs_cfg": false
  },
  "interpreter": {
   "hash": "1e4b5a1841bd30e729e63a9b20a9353a393f272e2a601c049eb274749a4ab854"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}