{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn.functional as F\n",
    "import numpy as np\n",
    "import random\n",
    "import sys\n",
    "sys.path.insert(0,'..')\n",
    "\n",
    "from dfibert.tracker.nn.rl import Agent\n",
    "import dfibert.envs.RLTractEnvironment_fast as RLTe\n",
    "\n",
    "from dfibert.tracker import save_streamlines\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib notebook\n",
    "\n",
    "#from train import load_model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# I. HCP Tracking\n",
    "The environment is able to run tracking on a fixed set of datasets. At the moment, it is able to load HCP data as well as ISMRM data. The following cells shows the initalisation of our environment on HCP dataset `100307` while seed points are automatically determined at voxels with fa-value >= 0.2 via `seeds = None`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "env = RLTe.RLTractEnvironment(step_width=0.8, dataset = '100307',\n",
    "                              device = 'cpu', seeds = None, tracking_in_RAS = False,\n",
    "                              odf_state = False, odf_mode = \"DTI\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "streamlines = env.track()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can also directly visualize our streamlines in this notebook by `ax.plot3d`. However, a single streamline is typically very hard to comprehend so this is merely one tool to qualitatively reason about major bugs in our tracking code."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "%matplotlib notebook\n",
    "streamline_index = 9\n",
    "streamline_np = np.stack(streamlines[streamline_index])\n",
    "\n",
    "fig = plt.figure()\n",
    "ax = plt.axes(projection='3d')\n",
    "#ax.plot3D(env.referenceStreamline_ijk.T[0], env.referenceStreamline_ijk.T[1], env.referenceStreamline_ijk.T[2], '-*')\n",
    "ax.plot3D(streamline_np[:,0], streamline_np[:,1], streamline_np[:,2])\n",
    "#plt.legend(['gt', 'agent'])\n",
    "plt.legend('agent')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# II. Evaluation of Cortico Spinal Tract @ ISMRM benchmark data\n",
    "We will now be using our environment along with our reward function to track streamlines on the ISMRM dataset. For this purpose, we first initialise our environment and set seed points to the cortico spinal tract. We precomputed seed points in IJK for our ISMRM dataset. These seeds will now be loaded into our environment."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "seeds_CST = np.load('data/ismrm_seeds_CST.npy')\n",
    "seeds_CST = torch.from_numpy(seeds_CST)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Will be deprecated by NARLTractEnvironment as soon as Jos fixes all bugs in the reward function.\n",
      "Loading dataset #  ISMRM\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/hoffmnic/.local/lib/python3.8/site-packages/dipy/core/sphere.py:187: UserWarning: Vertices are not on the unit sphere.\n",
      "  warnings.warn(\"Vertices are not on the unit sphere.\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Interpolating ODF as state Value\n",
      "Init tract masks for neuroanatomical reward\n",
      "torch.Size([90, 108, 90, 25])\n"
     ]
    }
   ],
   "source": [
    "env = RLTe.RLTractEnvironment(dataset = 'ISMRM', step_width=0.8,\n",
    "                            device = 'cuda:0', seeds = seeds_CST, action_space=20,\n",
    "                              odf_mode = \"DTI\", \n",
    "                              fa_threshold=0.2, tracking_in_RAS=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([0.], device='cuda:0')"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "env.brainMask_interpolator(torch.from_numpy(np.array([0,0,0])).to(env.device))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Tracking itself can now be done by basically calling the `.track()` function that tracks our streamlines from each of the provided seed points in a forward and backward direciton."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 5701/5701 [06:36<00:00, 14.39it/s] \n"
     ]
    }
   ],
   "source": [
    "streamlines = env.track()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The streamlines are now stored as VTK file. The nice thing about this format is that we can directly import the streamlines into 3dSlicer via the slicer-dMRI extension."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "streamlines_ras = [env.dataset.to_ras(torch.stack(sl).cpu().numpy()) for sl in streamlines]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "save_streamlines(streamlines=streamlines_ras, path=\"ismrm_CST_ras_test10_noPeakFinding_20a.vtk\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can also write our bundle masks into a file for ease of visualisation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import nibabel as nib\n",
    "for i in range(25):\n",
    "    data = env.tractMasksAllBundles[i,:,:,:].squeeze().cpu().numpy()\n",
    "    new_image = nib.Nifti1Image(data, np.eye(4))\n",
    "    new_image.set_data_dtype(data.dtype)\n",
    "\n",
    "    nib.save(new_image, 'mask_%s_%d.nii.gz' % (env.bundleNames[i],i))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ml_alpha",
   "language": "python",
   "name": "ml_alpha"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.6"
  },
  "latex_envs": {
   "LaTeX_envs_menu_present": true,
   "autoclose": false,
   "autocomplete": true,
   "bibliofile": "biblio.bib",
   "cite_by": "apalike",
   "current_citInitial": 1,
   "eqLabelWithNumbers": true,
   "eqNumInitial": 1,
   "hotkeys": {
    "equation": "Ctrl-E",
    "itemize": "Ctrl-I"
   },
   "labels_anchors": false,
   "latex_user_defs": false,
   "report_style_numbering": false,
   "user_envs_cfg": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
