{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import gym\n",
    "import numpy as np\n",
    "\n",
    "\n",
    "import os, sys\n",
    "sys.path.insert(0,'..')\n",
    "\n",
    "from collections import deque \n",
    "\n",
    "from dfibert.tracker.nn.rl import Agent, Action_Scheduler, DQN\n",
    "import dfibert.envs.RLtractEnvironment as RLTe\n",
    "from dfibert.envs._state import TractographyState"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test on Lunar Lander to check functionality of agent\n",
    "#env = gym.make('LunarLander-v2')\n",
    "#n_actions= env.action_space.n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "max_steps = 3000000\n",
    "replay_memory_size = 300000\n",
    "agent_history_length = 1\n",
    "evaluate_every = 20000\n",
    "eval_runs = 20\n",
    "network_update_every = 10000\n",
    "start_learning = 2000\n",
    "eps_annealing_steps = 150000\n",
    "\n",
    "max_episode_length = 250\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "\n",
    "batch_size = 64\n",
    "#learning_rate = 0.0000000625\n",
    "#batch_size = 512\n",
    "learning_rate = 0.0001"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading precomputed streamlines (data/HCP307200_DTI_smallSet.vtk) for ID 100307\n"
     ]
    }
   ],
   "source": [
    "env = RLTe.RLtractEnvironment(stepWidth=0.81, device = 'cpu')\n",
    "n_actions = env.action_space.n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "def init_transition():\n",
    "    state = env.reset()[:2]\n",
    "    #transition = deque(maxlen=12)\n",
    "    #while len(transition) < 12:\n",
    "        #for i in range(len(state.getCoordinate())):\n",
    "        #    transition.append(state.getCoordinate()[i].item())\n",
    "    transition = deque(maxlen=8)\n",
    "    while len(transition) < 8:\n",
    "        for i in range(len(state)):\n",
    "            transition.append(state[i])\n",
    "    return transition\n",
    "\n",
    "def add_to_transition(state, transition):\n",
    "    #for i in range(len(state.getCoordinate())):\n",
    "    #        transition.append(state.getCoordinate()[i].item())\n",
    "    for i in range(len(state)):\n",
    "            transition.append(state[i])                   \n",
    "    return transition"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([46.1923, 58.1386, 18.6595])\n",
      "[46.192337 58.13857  18.659458  0.      ]\n"
     ]
    }
   ],
   "source": [
    "state = env.reset()\n",
    "print(state.getCoordinate())\n",
    "current_index = np.min([env.stepCounter,len(env.referenceStreamline_ijk)-1])\n",
    "qry_pt = state.getCoordinate().view(-1,3)\n",
    "distance = torch.sum((env.referenceStreamline_ijk[current_index] - qry_pt)**2)\n",
    "state = np.array([*state.getCoordinate(), distance])\n",
    "print(state)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "deque([73.6513442993164, 107.88105773925781, 93.29415130615234, 73.6513442993164, 107.88105773925781, 93.29415130615234, 73.6513442993164, 107.88105773925781, 93.29415130615234, 73.6513442993164, 107.88105773925781, 93.29415130615234], maxlen=12)\n",
      "[ 73.6513443  107.88105774  93.29415131  73.6513443  107.88105774\n",
      "  93.29415131  73.6513443  107.88105774  93.29415131  74.58926433\n",
      " 108.1431821   93.52130066]\n"
     ]
    }
   ],
   "source": [
    "transition = init_transition()\n",
    "print(transition)\n",
    "next_state, _, _ = env.step(42)\n",
    "next_transition = add_to_transition(next_state, transition)\n",
    "print(np.array(next_transition))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1, 12])\n",
      "tensor([[ 61.8814,  53.5273,  65.1122,  59.5295,  63.2473,  63.3582,  49.6618,\n",
      "          57.5226,  56.9831,  61.0424,  49.2360,  45.0796,  60.3465,  55.7477,\n",
      "          60.6391,  54.9909,  55.8694,  60.2220,  35.0820,  47.0737,  53.0218,\n",
      "          56.9755,  60.0529,  32.3047,  20.4098,  58.4533,  59.7584,  63.0841,\n",
      "          54.4836,  43.6310,  57.3373,  22.6192,  32.9992,  61.3936,  32.4899,\n",
      "          60.6012,   8.0376,  39.1546,  58.7364,  28.7151,  25.3395,  59.5876,\n",
      "          13.1139,  54.3735,  25.8479,  10.7677,  54.2027,  11.2558,  38.6437,\n",
      "          60.1825,  22.2333,  24.1235,   8.7726,  27.5614,   2.9120,  12.3545,\n",
      "          26.7937,  17.6043,  34.9672, -12.4343,  23.0219,  27.1385, -15.7887,\n",
      "          61.7124,  42.1585,  20.3453,  24.3167,  -4.8190,  43.8532,  45.2633,\n",
      "          13.3825,  64.5126,   0.7540,  17.9066,  45.4248,  -8.3953,  60.9557,\n",
      "          51.1121,  22.9783,  49.9606,   8.7290,   3.0979,  55.1753,  -3.8223,\n",
      "          64.8611,  28.4904,  43.0782,  48.9762,  12.0101,  67.0276,  12.0111,\n",
      "          23.9232,  59.5696,  21.2108,  39.0073,  46.0813,  14.7475,  61.6706,\n",
      "          39.2160,  29.3636,  35.8707]], device='cuda:0',\n",
      "       grad_fn=<AddBackward0>)\n",
      "tensor([[ 63.6283,  55.3608,  66.8185,  61.1888,  66.2913,  66.0564,  51.9236,\n",
      "          59.3875,  59.3944,  63.5277,  53.6934,  48.2030,  63.8540,  58.4446,\n",
      "          63.3026,  58.4384,  57.4725,  62.1727,  37.2078,  49.2459,  56.9622,\n",
      "          60.5168,  62.6494,  35.4438,  22.5426,  62.1371,  62.0415,  65.8335,\n",
      "          57.5910,  46.8625,  60.4251,  26.2690,  36.7441,  63.1429,  35.5379,\n",
      "          64.3739,  12.9968,  41.9775,  61.7111,  33.1583,  29.6506,  61.3467,\n",
      "          15.9077,  56.4057,  30.3011,  13.3768,  56.7660,  14.4481,  40.0194,\n",
      "          63.0712,  27.3223,  26.0509,  11.5913,  33.8582,  10.7094,  15.7474,\n",
      "          31.1777,  20.3366,  38.5003,  -7.2658,  26.0212,  29.5287, -11.0445,\n",
      "          66.1286,  46.5212,  23.9947,  28.5018,   0.2056,  49.2398,  46.6589,\n",
      "          17.8200,  68.1692,   5.3408,  20.7294,  46.7196,  -2.4405,  65.7757,\n",
      "          53.7897,  25.3095,  52.4488,  13.9321,   5.8551,  57.1451,   0.3461,\n",
      "          71.6645,  32.7234,  46.6471,  51.2306,  16.3589,  71.9192,  16.1005,\n",
      "          27.7186,  63.3874,  24.3338,  41.3170,  49.6902,  19.2401,  71.4144,\n",
      "          42.2975,  31.2736,  38.9589]], device='cuda:0',\n",
      "       grad_fn=<AddBackward0>)\n",
      "<dfibert.envs._state.TractographyState object at 0x2aaab54c11c0> 0.9 False\n",
      "tensor([[ 61.8814,  53.5273,  65.1122,  59.5295,  63.2473,  63.3582,  49.6618,\n",
      "          57.5226,  56.9831,  61.0424,  49.2360,  45.0796,  60.3465,  55.7477,\n",
      "          60.6391,  54.9909,  55.8694,  60.2220,  35.0820,  47.0737,  53.0218,\n",
      "          56.9755,  60.0529,  32.3047,  20.4098,  58.4533,  59.7584,  63.0841,\n",
      "          54.4836,  43.6310,  57.3373,  22.6192,  32.9992,  61.3936,  32.4899,\n",
      "          60.6012,   8.0376,  39.1546,  58.7364,  28.7151,  25.3395,  59.5876,\n",
      "          13.1139,  54.3735,  25.8479,  10.7677,  54.2027,  11.2558,  38.6437,\n",
      "          60.1825,  22.2333,  24.1235,   8.7726,  27.5614,   2.9120,  12.3545,\n",
      "          26.7937,  17.6043,  34.9672, -12.4343,  23.0219,  27.1385, -15.7887,\n",
      "          61.7124,  42.1585,  20.3453,  24.3167,  -4.8190,  43.8532,  45.2633,\n",
      "          13.3825,  64.5126,   0.7540,  17.9066,  45.4248,  -8.3953,  60.9557,\n",
      "          51.1121,  22.9783,  49.9606,   8.7290,   3.0979,  55.1753,  -3.8223,\n",
      "          64.8611,  28.4904,  43.0782,  48.9762,  12.0101,  67.0276,  12.0111,\n",
      "          23.9232,  59.5696,  21.2108,  39.0073,  46.0813,  14.7475,  61.6706,\n",
      "          39.2160,  29.3636,  35.8707]], device='cuda:0',\n",
      "       grad_fn=<AddBackward0>)\n",
      "tensor([53.5273], device='cuda:0', grad_fn=<IndexBackward>)\n",
      "Argmax actions:  tensor([2], device='cuda:0')\n",
      "tensor([54.0936], device='cuda:0', grad_fn=<IndexBackward>)\n",
      "tensor([54.0936], device='cuda:0', grad_fn=<IndexPutBackward>)\n",
      "tensor([54.4527], device='cuda:0')\n",
      "tensor(0.4282, device='cuda:0', grad_fn=<SmoothL1LossBackward>)\n",
      "tensor([[69.8217, 62.7116, 72.9487, 67.3711, 70.8939, 71.1167, 57.6730, 65.5343,\n",
      "         64.8148, 68.7852, 56.6590, 52.5855, 67.8952, 63.3010, 68.3314, 62.3348,\n",
      "         63.6183, 67.6165, 42.4274, 54.9824, 60.3265, 64.3770, 67.3753, 39.9209,\n",
      "         28.0862, 65.7306, 67.4345, 70.9891, 61.7090, 51.1367, 64.6862, 29.8620,\n",
      "         40.6824, 68.7255, 39.7542, 67.9210, 15.2490, 46.6965, 66.0314, 35.6698,\n",
      "         32.9140, 66.8376, 20.4195, 61.6589, 32.8767, 18.2042, 61.3629, 18.4511,\n",
      "         46.3521, 67.3684, 28.9866, 31.0500, 15.8538, 34.3417,  9.6600, 19.4795,\n",
      "         33.3326, 25.0639, 42.1582, -5.5555, 30.0898, 34.0673, -8.8221, 68.8530,\n",
      "         49.1213, 27.6719, 31.1747,  2.1985, 50.7622, 52.4861, 20.5302, 71.4381,\n",
      "          7.7528, 25.3170, 52.6153, -1.3586, 68.0895, 58.1571, 30.3286, 57.2420,\n",
      "         15.6469, 10.5821, 62.2527,  3.3277, 71.8068, 35.5090, 50.3183, 56.1360,\n",
      "         19.3133, 73.9992, 18.8239, 31.1360, 66.8728, 28.4109, 46.6219, 53.2537,\n",
      "         22.0076, 67.9159, 46.1737, 36.9736, 43.1922]], device='cuda:0',\n",
      "       grad_fn=<AddBackward0>)\n",
      "tensor([[ 63.6283,  55.3608,  66.8185,  61.1888,  66.2913,  66.0564,  51.9236,\n",
      "          59.3875,  59.3944,  63.5277,  53.6934,  48.2030,  63.8540,  58.4446,\n",
      "          63.3026,  58.4384,  57.4725,  62.1727,  37.2078,  49.2459,  56.9622,\n",
      "          60.5168,  62.6494,  35.4438,  22.5426,  62.1371,  62.0415,  65.8335,\n",
      "          57.5910,  46.8625,  60.4251,  26.2690,  36.7441,  63.1429,  35.5379,\n",
      "          64.3739,  12.9968,  41.9775,  61.7111,  33.1583,  29.6506,  61.3467,\n",
      "          15.9077,  56.4057,  30.3011,  13.3768,  56.7660,  14.4481,  40.0194,\n",
      "          63.0712,  27.3223,  26.0509,  11.5913,  33.8582,  10.7094,  15.7474,\n",
      "          31.1777,  20.3366,  38.5003,  -7.2658,  26.0212,  29.5287, -11.0445,\n",
      "          66.1286,  46.5212,  23.9947,  28.5018,   0.2056,  49.2398,  46.6589,\n",
      "          17.8200,  68.1692,   5.3408,  20.7294,  46.7196,  -2.4405,  65.7757,\n",
      "          53.7897,  25.3095,  52.4488,  13.9321,   5.8551,  57.1451,   0.3461,\n",
      "          71.6645,  32.7234,  46.6471,  51.2306,  16.3589,  71.9192,  16.1005,\n",
      "          27.7186,  63.3874,  24.3338,  41.3170,  49.6902,  19.2401,  71.4144,\n",
      "          42.2975,  31.2736,  38.9589]], device='cuda:0',\n",
      "       grad_fn=<AddBackward0>)\n"
     ]
    }
   ],
   "source": [
    "# Debugging the optimization of the agent\n",
    "\n",
    "#state = env.reset()\n",
    "#state = torch.tensor([state]).to(device).float()\n",
    "transition = init_transition()\n",
    "state = torch.FloatTensor([np.array(transition)]).to(device)\n",
    "print(state.shape)\n",
    "print(agent.main_dqn(state))\n",
    "print(agent.target_dqn(state))\n",
    "\n",
    "action = 1\n",
    "\n",
    "next_state, reward, done = env.step(action)\n",
    "print(next_state, reward, done)\n",
    "\n",
    "action = torch.tensor([action]).to(device)\n",
    "#next_state = torch.tensor([next_state]).float().to(device)\n",
    "next_state = add_to_transition(next_state, transition)\n",
    "next_state = torch.FloatTensor([np.array(next_state)]).to(device)\n",
    "reward = torch.tensor([reward]).float().to(device)\n",
    "done = torch.BoolTensor([done]).to(device)\n",
    "state_action_values = agent.main_dqn(state)\n",
    "print(state_action_values)\n",
    "state_action_values = state_action_values[0][action]\n",
    "print(state_action_values)\n",
    "\n",
    "next_state_actions = agent.main_dqn(next_state).max(1)[1]\n",
    "print(\"Argmax actions: \", next_state_actions)\n",
    "next_state_values = agent.target_dqn(next_state)[0][next_state_actions]\n",
    "print(next_state_values)\n",
    "next_state_values[done] = 0.0\n",
    "print(next_state_values)\n",
    "expected_state_action_values = next_state_values.detach() * 0.99 + reward\n",
    "print(expected_state_action_values)\n",
    "\n",
    "agent.optimizer.zero_grad()\n",
    "loss = torch.nn.SmoothL1Loss()(state_action_values, expected_state_action_values)\n",
    "print(loss)\n",
    "loss.backward()\n",
    "agent.optimizer.step()\n",
    "\n",
    "print(agent.main_dqn(state))\n",
    "print(agent.target_dqn(state))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "cos = torch.nn.CosineSimilarity(dim=0)\n",
    "\n",
    "def get_random_good_action(state):\n",
    "    best_actions = []\n",
    "    #path_vectors = []\n",
    "    #reference_vectors = []\n",
    "    #cosine_sims = []\n",
    "    #distances = []\n",
    "    rewards = []\n",
    "    for i in range(n_actions):\n",
    "        #print(state.getCoordinate(), env.state.getCoordinate())\n",
    "        #print(env.stepCounter)\n",
    "        next_state, _,_ = env.step(i)\n",
    "        #print(env.stepCounter)\n",
    "        current_index = np.min([env.stepCounter,len(env.referenceStreamline_ijk)-1])\n",
    "        #print(current_index)\n",
    "        path_vector = next_state.getCoordinate() - state.getCoordinate().squeeze(0)\n",
    "        #print(path_vector)\n",
    "        #path_vectors.append(path_vector.numpy())\n",
    "        reference_vector = env.referenceStreamline_ijk[current_index]-env.referenceStreamline_ijk[current_index-1]\n",
    "        #print(reference_vector)\n",
    "        #reference_vectors.append(reference_vector.numpy())\n",
    "        cosine_sim = cos(path_vector, reference_vector)\n",
    "        #cosine_sims.append(cosine_sim.item())\n",
    "        #print(cosine_sim)\n",
    "        dist = torch.sum((env.referenceStreamline_ijk[current_index] - next_state.getCoordinate())**2) *10\n",
    "        #print(dist)\n",
    "        #distances.append(dist.item())\n",
    "\n",
    "        reward = cosine_sim - dist\n",
    "        rewards.append(reward.item())\n",
    "        #print(reward)\n",
    "        best_actions.append(reward)\n",
    "        env.state = state\n",
    "        env.stepCounter -= 1\n",
    "\n",
    "    #best_actions = torch.topk(torch.tensor(best_actions), k=0)[1].numpy()\n",
    "    #random_action = np.random.choice(best_actions, size=1)\n",
    "    best_action= torch.argmax(torch.tensor(best_actions))\n",
    "    return best_action, rewards[best_action]#random_action"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "87 0.9982823428316672 10.27874900892709 tensor(1., dtype=torch.float64)\n",
      "74 0.9960135754225334 10.27874900892709 tensor(1., dtype=torch.float64)\n",
      "74 0.9960133527053007 10.27874900892709 tensor(1., dtype=torch.float64)\n",
      "95 0.9862988869063978 10.27874900892709 tensor(1., dtype=torch.float64)\n",
      "95 0.9815302241747416 10.27874900892709 tensor(1., dtype=torch.float64)\n",
      "82 0.9903408242500866 10.27874900892709 tensor(1., dtype=torch.float64)\n",
      "74 0.9932573083211094 10.27874900892709 tensor(1., dtype=torch.float64)\n",
      "74 0.9860534001977396 10.27874900892709 tensor(1., dtype=torch.float64)\n",
      "74 0.9860525330136785 10.27874900892709 tensor(1., dtype=torch.float64)\n",
      "61 0.994611773473146 10.27874900892709 tensor(1., dtype=torch.float64)\n",
      "82 0.9793927288302502 10.27874900892709 tensor(1., dtype=torch.float64)\n",
      "82 0.9793935505914712 10.27874900892709 tensor(1., dtype=torch.float64)\n",
      "82 0.9793939583660654 10.27874900892709 tensor(1., dtype=torch.float64)\n",
      "69 0.9942969038367179 10.27874900892709 tensor(1., dtype=torch.float64)\n",
      "69 0.9942964118489737 10.27874900892709 tensor(1., dtype=torch.float64)\n",
      "69 0.9938682203537123 10.27874900892709 tensor(1., dtype=torch.float64)\n",
      "69 0.993868059150523 10.27874900892709 tensor(1., dtype=torch.float64)\n",
      "77 0.9781315284495549 10.27874900892709 tensor(1., dtype=torch.float64)\n",
      "77 0.9781325546008613 10.27874900892709 tensor(1., dtype=torch.float64)\n",
      "77 0.9781315749936996 10.27874900892709 tensor(1., dtype=torch.float64)\n",
      "77 0.9912687781515284 10.27874900892709 tensor(1., dtype=torch.float64)\n",
      "90 0.9936866470638962 10.27874900892709 tensor(1., dtype=torch.float64)\n",
      "98 0.9821652814476723 10.27874900892709 tensor(1., dtype=torch.float64)\n",
      "98 0.9821646128958393 10.27874900892709 tensor(1., dtype=torch.float64)\n",
      "98 0.9959340345958659 10.27874900892709 tensor(1., dtype=torch.float64)\n",
      "98 0.9959340345958659 10.27874900892709 tensor(1., dtype=torch.float64)\n",
      "98 0.9985589075230221 10.27874900892709 tensor(1., dtype=torch.float64)\n",
      "31 0.9840124495921336 10.27874900892709 tensor(1., dtype=torch.float64)\n",
      "31 0.9879459423682874 10.27874900892709 tensor(1., dtype=torch.float64)\n",
      "31 0.9879461404456911 10.27874900892709 tensor(1., dtype=torch.float64)\n",
      "31 0.992086300237378 10.27874900892709 tensor(1., dtype=torch.float64)\n",
      "31 0.9920867404973466 10.27874900892709 tensor(1., dtype=torch.float64)\n",
      "26 0.9789500668185752 10.27874900892709 tensor(1., dtype=torch.float64)\n",
      "18 0.9873132640276205 10.27874900892709 tensor(1., dtype=torch.float64)\n",
      "18 0.9863780428247012 10.27874900892709 tensor(1., dtype=torch.float64)\n",
      "13 0.9954715354665544 10.27874900892709 tensor(1., dtype=torch.float64)\n",
      "13 0.995471925199487 10.27874900892709 tensor(1., dtype=torch.float64)\n",
      "13 0.9992627311742139 10.27874900892709 tensor(1., dtype=torch.float64)\n",
      "13 0.9935568859341793 10.27874900892709 tensor(1., dtype=torch.float64)\n",
      "13 0.9863946657643878 10.27874900892709 tensor(1., dtype=torch.float64)\n",
      "13 0.9863946657643878 10.27874900892709 tensor(1., dtype=torch.float64)\n",
      "13 0.9863947534360401 10.27874900892709 tensor(1., dtype=torch.float64)\n",
      "13 0.9863946657643878 10.27874900892709 tensor(1., dtype=torch.float64)\n",
      "13 0.9863942641050477 10.27874900892709 tensor(1., dtype=torch.float64)\n",
      "13 0.9863946657643878 10.27874900892709 tensor(1., dtype=torch.float64)\n",
      "13 0.9863951550949168 10.27874900892709 tensor(1., dtype=torch.float64)\n",
      "13 0.9863942641050477 10.27874900892709 tensor(1., dtype=torch.float64)\n",
      "13 0.9863946657643878 10.27874900892709 tensor(1., dtype=torch.float64)\n",
      "34 0.9923339427954452 10.27874900892709 tensor(1., dtype=torch.float64)\n",
      "21 0.9924235422172867 10.27874900892709 tensor(1., dtype=torch.float64)\n",
      "21 0.9924242813353932 10.27874900892709 tensor(1., dtype=torch.float64)\n",
      "21 0.992424111619503 10.27874900892709 tensor(1., dtype=torch.float64)\n",
      "13 0.9846539206733895 10.27874900892709 tensor(1., dtype=torch.float64)\n",
      "13 0.984654657966265 10.27874900892709 tensor(1., dtype=torch.float64)\n",
      "13 0.9846538967886698 10.27874900892709 tensor(1., dtype=torch.float64)\n",
      "13 0.9902607086121104 10.27874900892709 tensor(1., dtype=torch.float64)\n",
      "5 0.9867487116434671 10.27874900892709 tensor(1., dtype=torch.float64)\n",
      "5 0.9867487116434671 10.27874900892709 tensor(1., dtype=torch.float64)\n",
      "5 0.9867487116434671 10.27874900892709 tensor(1., dtype=torch.float64)\n",
      "5 0.9867487116434671 10.27874900892709 tensor(1., dtype=torch.float64)\n",
      "5 0.9867487116434671 10.27874900892709 tensor(1., dtype=torch.float64)\n",
      "5 0.9867487116434671 10.27874900892709 tensor(1., dtype=torch.float64)\n",
      "5 0.9867487116434671 10.27874900892709 tensor(1., dtype=torch.float64)\n",
      "5 0.9867487116434671 10.27874900892709 tensor(1., dtype=torch.float64)\n",
      "5 0.9867487116434671 10.27874900892709 tensor(1., dtype=torch.float64)\n",
      "5 0.9867487116434671 10.27874900892709 tensor(1., dtype=torch.float64)\n",
      "5 0.9867487116434671 10.27874900892709 tensor(1., dtype=torch.float64)\n",
      "5 0.9867487116434671 10.27874900892709 tensor(1., dtype=torch.float64)\n",
      "5 0.9867487116434671 10.27874900892709 tensor(1., dtype=torch.float64)\n",
      "5 0.9867487116434671 10.27874900892709 tensor(1., dtype=torch.float64)\n",
      "5 0.9867487116434671 10.27874900892709 tensor(1., dtype=torch.float64)\n",
      "5 0.9867487116434671 10.27874900892709 tensor(1., dtype=torch.float64)\n",
      "5 0.9867487116434671 10.27874900892709 tensor(1., dtype=torch.float64)\n",
      "5 0.9867487116434671 10.27874900892709 tensor(1., dtype=torch.float64)\n",
      "5 0.9867487116434671 10.27874900892709 tensor(1., dtype=torch.float64)\n",
      "5 0.9867487116434671 10.27874900892709 tensor(1., dtype=torch.float64)\n",
      "5 0.9867487116434671 10.27874900892709 tensor(1., dtype=torch.float64)\n",
      "5 0.9867487116434671 10.27874900892709 tensor(1., dtype=torch.float64)\n",
      "5 0.9867487116434671 10.27874900892709 tensor(1., dtype=torch.float64)\n",
      "5 0.9867487116434671 10.27874900892709 tensor(1., dtype=torch.float64)\n",
      "5 0.9867487116434671 10.27874900892709 tensor(1., dtype=torch.float64)\n",
      "5 0.9867487116434671 10.27874900892709 tensor(1., dtype=torch.float64)\n",
      "5 0.9867487116434671 10.27874900892709 tensor(1., dtype=torch.float64)\n",
      "5 0.9867487116434671 10.27874900892709 tensor(1., dtype=torch.float64)\n",
      "5 0.9867487116434671 10.27874900892709 tensor(1., dtype=torch.float64)\n",
      "5 0.9867487116434671 10.27874900892709 tensor(1., dtype=torch.float64)\n",
      "5 0.9867487116434671 10.27874900892709 tensor(1., dtype=torch.float64)\n",
      "5 0.9867487116434671 10.27874900892709 tensor(1., dtype=torch.float64)\n",
      "5 0.9867487116434671 10.27874900892709 tensor(1., dtype=torch.float64)\n",
      "5 0.9867487116434671 10.27874900892709 tensor(1., dtype=torch.float64)\n",
      "5 0.9867487116434671 10.27874900892709 tensor(1., dtype=torch.float64)\n",
      "5 0.0 10.27874900892709 tensor(0.0133, dtype=torch.float64)\n",
      "5 0.9867487116434671 10.27874900892709 tensor(1., dtype=torch.float64)\n",
      "5 0.9867487116434671 10.27874900892709 tensor(1., dtype=torch.float64)\n",
      "5 0.9867487116434671 10.27874900892709 tensor(1., dtype=torch.float64)\n",
      "5 0.9867487116434671 10.27874900892709 tensor(1., dtype=torch.float64)\n",
      "5 0.9867487116434671 10.27874900892709 tensor(1., dtype=torch.float64)\n",
      "13 0.9774042380185793 10.27874900892709 tensor(1., dtype=torch.float64)\n",
      "5 0.9867487116434671 10.27874900892709 tensor(1., dtype=torch.float64)\n",
      "5 0.9867487116434671 10.27874900892709 tensor(1., dtype=torch.float64)\n",
      "5 0.9867487116434671 10.27874900892709 tensor(1., dtype=torch.float64)\n",
      "5 0.9867487116434671 10.27874900892709 tensor(1., dtype=torch.float64)\n",
      "5 0.9867487116434671 10.27874900892709 tensor(1., dtype=torch.float64)\n",
      "5 0.9867487116434671 10.27874900892709 tensor(1., dtype=torch.float64)\n",
      "5 0.9867487116434671 10.27874900892709 tensor(1., dtype=torch.float64)\n",
      "5 0.9867487116434671 10.27874900892709 tensor(1., dtype=torch.float64)\n",
      "13 0.9774042380185793 10.27874900892709 tensor(1., dtype=torch.float64)\n",
      "5 0.9867487116434671 10.27874900892709 tensor(1., dtype=torch.float64)\n",
      "5 0.0 10.27874900892709 tensor(0.0133, dtype=torch.float64)\n",
      "5 0.9867487116434671 10.27874900892709 tensor(1., dtype=torch.float64)\n",
      "5 0.0 10.27874900892709 tensor(0.0133, dtype=torch.float64)\n",
      "5 0.9867487116434671 10.27874900892709 tensor(1., dtype=torch.float64)\n",
      "5 0.9867487116434671 10.27874900892709 tensor(1., dtype=torch.float64)\n",
      "5 0.9867487116434671 10.27874900892709 tensor(1., dtype=torch.float64)\n",
      "5 0.9867487116434671 10.27874900892709 tensor(1., dtype=torch.float64)\n",
      "5 0.9867487116434671 10.27874900892709 tensor(1., dtype=torch.float64)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5 0.9867487116434671 10.27874900892709 tensor(1., dtype=torch.float64)\n",
      "5 0.9867487116434671 10.27874900892709 tensor(1., dtype=torch.float64)\n",
      "5 0.9867487116434671 10.27874900892709 tensor(1., dtype=torch.float64)\n",
      "5 0.9867487116434671 10.27874900892709 tensor(1., dtype=torch.float64)\n",
      "5 0.9867487116434671 10.27874900892709 tensor(1., dtype=torch.float64)\n",
      "5 0.9867487116434671 10.27874900892709 tensor(1., dtype=torch.float64)\n",
      "5 0.9867487116434671 10.27874900892709 tensor(1., dtype=torch.float64)\n",
      "5 0.9867487116434671 10.27874900892709 tensor(1., dtype=torch.float64)\n",
      "5 0.9867487116434671 10.27874900892709 tensor(1., dtype=torch.float64)\n",
      "5 0.9867487116434671 10.27874900892709 tensor(1., dtype=torch.float64)\n",
      "5 0.0 10.27874900892709 tensor(0.0133, dtype=torch.float64)\n",
      "5 0.9867487116434671 10.27874900892709 tensor(1., dtype=torch.float64)\n",
      "5 0.9867487116434671 10.27874900892709 tensor(1., dtype=torch.float64)\n",
      "5 0.9867487116434671 10.27874900892709 tensor(1., dtype=torch.float64)\n",
      "5 0.9867487116434671 10.27874900892709 tensor(1., dtype=torch.float64)\n",
      "5 0.9867487116434671 10.27874900892709 tensor(1., dtype=torch.float64)\n",
      "5 0.9867487116434671 10.27874900892709 tensor(1., dtype=torch.float64)\n",
      "5 0.9867487116434671 10.27874900892709 tensor(1., dtype=torch.float64)\n",
      "5 0.9867487116434671 10.27874900892709 tensor(1., dtype=torch.float64)\n",
      "5 0.9867487116434671 10.27874900892709 tensor(1., dtype=torch.float64)\n",
      "5 0.9867487116434671 10.27874900892709 tensor(1., dtype=torch.float64)\n",
      "5 0.9867487116434671 10.27874900892709 tensor(1., dtype=torch.float64)\n",
      "5 0.9867487116434671 10.27874900892709 tensor(1., dtype=torch.float64)\n",
      "5 0.9867487116434671 10.27874900892709 tensor(1., dtype=torch.float64)\n",
      "5 0.9867487116434671 10.27874900892709 tensor(1., dtype=torch.float64)\n",
      "5 0.9867487116434671 10.27874900892709 tensor(1., dtype=torch.float64)\n",
      "13 0.9774042380185793 10.27874900892709 tensor(1., dtype=torch.float64)\n",
      "5 0.9867487116434671 10.27874900892709 tensor(1., dtype=torch.float64)\n",
      "5 0.9867487116434671 10.27874900892709 tensor(1., dtype=torch.float64)\n",
      "5 0.9867487116434671 10.27874900892709 tensor(1., dtype=torch.float64)\n",
      "5 0.0 10.27874900892709 tensor(0.0133, dtype=torch.float64)\n",
      "5 0.9867487116434668 10.27874900892709 tensor(1., dtype=torch.float64)\n",
      "5 0.9867487116434668 10.27874900892709 tensor(1., dtype=torch.float64)\n",
      "13 0.9774042380185793 10.27874900892709 tensor(1., dtype=torch.float64)\n",
      "5 0.0 10.27874900892709 tensor(0.0133, dtype=torch.float64)\n",
      "5 0.9867487116434668 10.27874900892709 tensor(1., dtype=torch.float64)\n",
      "5 0.9867487116434668 10.27874900892709 tensor(1., dtype=torch.float64)\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-56-146919d457d5>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0;32mwhile\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mterminal\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 7\u001b[0;31m     \u001b[0maction\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moptimal_reward\u001b[0m  \u001b[0;34m=\u001b[0m \u001b[0mget_random_good_action\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstate\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      8\u001b[0m \u001b[0;31m#print(\"Action:\", action)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      9\u001b[0m     \u001b[0mnext_state\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0m_\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0menv\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0maction\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-55-21e6cd4bfa6c>\u001b[0m in \u001b[0;36mget_random_good_action\u001b[0;34m(state)\u001b[0m\n\u001b[1;32m     11\u001b[0m         \u001b[0;31m#ic(state.getCoordinate(), env.state.getCoordinate())\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     12\u001b[0m         \u001b[0;31m#ic(env.stepCounter)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 13\u001b[0;31m         \u001b[0mnext_state\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0m_\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0menv\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     14\u001b[0m         \u001b[0;31m#ic(env.stepCounter)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     15\u001b[0m         \u001b[0mcurrent_index\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0menv\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstepCounter\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0menv\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreferenceStreamline_ijk\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/fibre_tracking/deepFibreTracking/dfibert/envs/RLtractEnvironment.py\u001b[0m in \u001b[0;36mstep\u001b[0;34m(self, action)\u001b[0m\n\u001b[1;32m     78\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     79\u001b[0m             \u001b[0;31m## apply step by step length and update state accordingly\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 80\u001b[0;31m             \u001b[0mpositionNextState\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstate\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgetCoordinate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstepWidth\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0maction_vector\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     81\u001b[0m             \u001b[0mnextState\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mTractographyState\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpositionNextState\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minterpolateDWIatState\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     82\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mnextState\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgetValue\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.conda/envs/atari/lib/python3.8/site-packages/torch/tensor.py\u001b[0m in \u001b[0;36m__array__\u001b[0;34m(self, dtype)\u001b[0m\n\u001b[1;32m    622\u001b[0m     \u001b[0m__array_priority__\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m1000\u001b[0m    \u001b[0;31m# prefer Tensor ops over numpy ones\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    623\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 624\u001b[0;31m     \u001b[0;32mdef\u001b[0m \u001b[0m__array__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    625\u001b[0m         \u001b[0mrelevant_args\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    626\u001b[0m         \u001b[0;32mfrom\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moverrides\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mhas_torch_function\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhandle_torch_function\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "state = env.reset()\n",
    "terminal = False\n",
    "all_states = []\n",
    "all_states.append(state.getCoordinate())\n",
    "\n",
    "while not terminal:\n",
    "    action, optimal_reward  = get_random_good_action(state)\n",
    "    #print(\"Action:\", action)\n",
    "    next_state, _,_ = env.step(action)\n",
    "    #print(\"Step counter: \", env.stepCounter)\n",
    "    current_index = np.min([env.stepCounter,len(env.referenceStreamline_ijk)-1])\n",
    "    #print(\"Current index: \", current_index)\n",
    "    #print(\"state.getCoordinate(): \", state.getCoordinate().numpy())\n",
    "    #print(\"env.state.getCoordinate(): \", env.state.getCoordinate().numpy())\n",
    "    #print(\"next_state.getCoordinate(): \", next_state.getCoordinate().numpy())\n",
    "    path_vector = next_state.getCoordinate() - state.getCoordinate().squeeze(0)\n",
    "    #print(\"path vector: \", path_vector)\n",
    "    reference_vector = env.referenceStreamline_ijk[current_index]-env.referenceStreamline_ijk[current_index-1]\n",
    "    #print(\"reference_vector: \", reference_vector)\n",
    "    cosine_sim = cos(path_vector, reference_vector)\n",
    "    #print(\"cosine_sim: \", cosine_sim)\n",
    "    dist = torch.sum((env.referenceStreamline_ijk[current_index] - next_state.getCoordinate())**2) *10\n",
    "    \n",
    "    #print(\"distance: \", dist)\n",
    "    all_states.append(next_state.getCoordinate())\n",
    "    state = next_state\n",
    "    print(action.item(), cosine_sim.item(), dist.item(), 1-(optimal_reward-(cosine_sim-dist)))\n",
    "    if action == 100:\n",
    "        terminal = True\n",
    "    else:\n",
    "        terminal = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Start training...\n",
      "Hey, hey, hey we finally stopped at the terminal state! :D\n",
      "Hey, hey, hey we finally stopped at the terminal state! :D\n",
      "Hey, hey, hey we finally stopped at the terminal state! :D\n",
      "Hey, hey, hey we finally stopped at the terminal state! :D\n",
      "Hey, hey, hey we finally stopped at the terminal state! :D\n",
      "Hey, hey, hey we finally stopped at the terminal state! :D\n",
      "Hey, hey, hey we finally stopped at the terminal state! :D\n",
      "Hey, hey, hey we finally stopped at the terminal state! :D\n",
      "784, done 10 episodes, 78.4, current eps 1 78.4\n",
      "Hey, hey, hey we finally stopped at the terminal state! :D\n",
      "Hey, hey, hey we finally stopped at the terminal state! :D\n",
      "Hey, hey, hey we finally stopped at the terminal state! :D\n",
      "Hey, hey, hey we finally stopped at the terminal state! :D\n",
      "Hey, hey, hey we finally stopped at the terminal state! :D\n",
      "Hey, hey, hey we finally stopped at the terminal state! :D\n",
      "Hey, hey, hey we finally stopped at the terminal state! :D\n",
      "Hey, hey, hey we finally stopped at the terminal state! :D\n",
      "Hey, hey, hey we finally stopped at the terminal state! :D\n",
      "Hey, hey, hey we finally stopped at the terminal state! :D\n",
      "Hey, hey, hey we finally stopped at the terminal state! :D\n",
      "Hey, hey, hey we finally stopped at the terminal state! :D\n",
      "Hey, hey, hey we finally stopped at the terminal state! :D\n",
      "Hey, hey, hey we finally stopped at the terminal state! :D\n",
      "1639, done 20 episodes, 81.95, current eps 1 81.95\n",
      "Hey, hey, hey we finally stopped at the terminal state! :D\n",
      "Hey, hey, hey we finally stopped at the terminal state! :D\n",
      "Hey, hey, hey we finally stopped at the terminal state! :D\n",
      "Hey, hey, hey we finally stopped at the terminal state! :D\n",
      "Hey, hey, hey we finally stopped at the terminal state! :D\n",
      "Hey, hey, hey we finally stopped at the terminal state! :D\n",
      "Hey, hey, hey we finally stopped at the terminal state! :D\n",
      "Hey, hey, hey we finally stopped at the terminal state! :D\n",
      "Hey, hey, hey we finally stopped at the terminal state! :D\n",
      "Hey, hey, hey we finally stopped at the terminal state! :D\n",
      "Hey, hey, hey we finally stopped at the terminal state! :D\n",
      "Hey, hey, hey we finally stopped at the terminal state! :D\n",
      "Hey, hey, hey we finally stopped at the terminal state! :D\n",
      "Hey, hey, hey we finally stopped at the terminal state! :D\n",
      "2390, done 30 episodes, 61.953837385562814, current eps 0.93776 79.66666666666667\n",
      "Hey, hey, hey we finally stopped at the terminal state! :D\n",
      "Hey, hey, hey we finally stopped at the terminal state! :D\n",
      "Hey, hey, hey we finally stopped at the terminal state! :D\n",
      "Hey, hey, hey we finally stopped at the terminal state! :D\n",
      "Hey, hey, hey we finally stopped at the terminal state! :D\n",
      "Hey, hey, hey we finally stopped at the terminal state! :D\n",
      "Hey, hey, hey we finally stopped at the terminal state! :D\n",
      "Hey, hey, hey we finally stopped at the terminal state! :D\n",
      "Hey, hey, hey we finally stopped at the terminal state! :D\n",
      "Hey, hey, hey we finally stopped at the terminal state! :D\n",
      "Hey, hey, hey we finally stopped at the terminal state! :D\n",
      "Hey, hey, hey we finally stopped at the terminal state! :D\n",
      "Hey, hey, hey we finally stopped at the terminal state! :D\n",
      "Hey, hey, hey we finally stopped at the terminal state! :D\n",
      "Hey, hey, hey we finally stopped at the terminal state! :D\n",
      "Hey, hey, hey we finally stopped at the terminal state! :D\n",
      "Hey, hey, hey we finally stopped at the terminal state! :D\n",
      "Hey, hey, hey we finally stopped at the terminal state! :D\n",
      "Hey, hey, hey we finally stopped at the terminal state! :D\n",
      "3428, done 40 episodes, -229.05701050661906, current eps 0.77168 85.7\n",
      "Hey, hey, hey we finally stopped at the terminal state! :D\n",
      "Hey, hey, hey we finally stopped at the terminal state! :D\n",
      "Hey, hey, hey we finally stopped at the terminal state! :D\n",
      "Hey, hey, hey we finally stopped at the terminal state! :D\n",
      "Hey, hey, hey we finally stopped at the terminal state! :D\n",
      "Hey, hey, hey we finally stopped at the terminal state! :D\n",
      "Hey, hey, hey we finally stopped at the terminal state! :D\n",
      "Hey, hey, hey we finally stopped at the terminal state! :D\n",
      "Hey, hey, hey we finally stopped at the terminal state! :D\n",
      "Hey, hey, hey we finally stopped at the terminal state! :D\n",
      "Hey, hey, hey we finally stopped at the terminal state! :D\n",
      "Hey, hey, hey we finally stopped at the terminal state! :D\n",
      "Hey, hey, hey we finally stopped at the terminal state! :D\n",
      "Hey, hey, hey we finally stopped at the terminal state! :D\n",
      "4585, done 50 episodes, -929.5423451476032, current eps 0.58656 91.7\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-53-822678f15f04>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m    100\u001b[0m                 \u001b[0;31m#if reward > 0.:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    101\u001b[0m                 \u001b[0;31m#    print(\"reward was positive: \", reward)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 102\u001b[0;31m                 \u001b[0mloss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0magent\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moptimize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    103\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    104\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/fibre_tracking/deepFibreTracking/dfibert/tracker/nn/rl.py\u001b[0m in \u001b[0;36moptimize\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    182\u001b[0m         \u001b[0mstate_action_values\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmain_dqn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstates\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgather\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mactions\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0munsqueeze\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msqueeze\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    183\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 184\u001b[0;31m         \u001b[0mnext_state_actions\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmain_dqn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnext_states\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmax\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    185\u001b[0m         \u001b[0mnext_state_values\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtarget_dqn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnext_states\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgather\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnext_state_actions\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0munsqueeze\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msqueeze\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    186\u001b[0m         \u001b[0mnext_state_values\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mterminal_flags\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m0.0\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.conda/envs/atari/lib/python3.8/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m    725\u001b[0m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    726\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 727\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    728\u001b[0m         for hook in itertools.chain(\n\u001b[1;32m    729\u001b[0m                 \u001b[0m_global_forward_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/fibre_tracking/deepFibreTracking/dfibert/tracker/nn/rl.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, x)\u001b[0m\n\u001b[1;32m    116\u001b[0m         \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreshape\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    117\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlinear_layers\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 118\u001b[0;31m             \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlinear_layers\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    119\u001b[0m             \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mactivation\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    120\u001b[0m         \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlinear_layers\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.conda/envs/atari/lib/python3.8/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m    725\u001b[0m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    726\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 727\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    728\u001b[0m         for hook in itertools.chain(\n\u001b[1;32m    729\u001b[0m                 \u001b[0m_global_forward_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.conda/envs/atari/lib/python3.8/site-packages/torch/nn/modules/linear.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m     91\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     92\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mTensor\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0mTensor\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 93\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mF\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlinear\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mweight\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbias\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     94\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     95\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mextra_repr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0mstr\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.conda/envs/atari/lib/python3.8/site-packages/torch/nn/functional.py\u001b[0m in \u001b[0;36mlinear\u001b[0;34m(input, weight, bias)\u001b[0m\n\u001b[1;32m   1688\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdim\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m2\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mbias\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1689\u001b[0m         \u001b[0;31m# fused op is marginally faster\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1690\u001b[0;31m         \u001b[0mret\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0maddmm\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbias\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mweight\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mt\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1691\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1692\u001b[0m         \u001b[0moutput\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmatmul\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mweight\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mt\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "state = env.reset().getValue()\n",
    "agent = Agent(n_actions=n_actions, inp_size=state.shape, device=device, hidden=10, gamma=0.9, agent_history_length=agent_history_length, memory_size=replay_memory_size, batch_size=32, learning_rate=learning_rate)\n",
    "\n",
    "#transition = init_transition()\n",
    "#agent = Agent(n_actions=n_actions, inp_size=np.array(transition).shape, device=device, hidden=10, agent_history_length=agent_history_length, memory_size=replay_memory_size, batch_size=batch_size, learning_rate=learning_rate)\n",
    "action_scheduler = Action_Scheduler(num_actions=n_actions, max_steps=max_steps, eps_annealing_steps=5000, eps_final=0.2, eps_final_step=0.02, replay_memory_start_size=start_learning, model=agent.main_dqn)\n",
    "\n",
    "step_counter = 0\n",
    "\n",
    "eps_rewards = []\n",
    "\n",
    "episode_lengths = []\n",
    "\n",
    "cos = torch.nn.CosineSimilarity(dim=0)\n",
    "\n",
    "print(\"Start training...\")\n",
    "while step_counter < 5000:\n",
    "    epoch_step = 0\n",
    "    #agent.main_dqn.train()\n",
    "######## fill memory begins here\n",
    "    while (epoch_step < evaluate_every) or (step_counter < start_learning):\n",
    "        state = env.reset()\n",
    "        #transition = init_transition()\n",
    "        #referenceLine = env.referenceStreamline_ijk\n",
    "        episode_reward_sum = 0\n",
    "        terminal = False\n",
    "        #fill replay memory while interacting with env\n",
    "        #for episode_counter in range(max_episode_length):\n",
    "        episode_step_counter = 0\n",
    "        positive_run = 0\n",
    "        \n",
    "        dist = 0\n",
    "        while not terminal:\n",
    "            # get action with epsilon-greedy strategy\n",
    "            #if dist < 0.1:\n",
    "            influential_action, optimal_reward = get_random_good_action(state)\n",
    "                #print(influential_action)\n",
    "            #else:\n",
    "            #    influential_action = None\n",
    "            action = action_scheduler.get_action(step_counter, torch.FloatTensor(state.getValue()).unsqueeze(0).to(device), influential_action=influential_action)\n",
    "            #action = action_scheduler.get_action(step_counter, torch.FloatTensor([np.array(transition)]).to(device))\n",
    "            \n",
    "            \n",
    "            next_state, reward, terminal = env.step(action)\n",
    "            #print(reward)\n",
    "            episode_step_counter += 1\n",
    "            \n",
    "            terminal = False\n",
    "\n",
    "            current_index = np.min([env.stepCounter,len(env.referenceStreamline_ijk)-1])\n",
    "            path_vector = (next_state.getCoordinate() - state.getCoordinate()).squeeze(0)\n",
    "            reference_vector = env.referenceStreamline_ijk[current_index]-env.referenceStreamline_ijk[current_index-1]\n",
    "            #    #print(path_vector, reference_vector)\n",
    "            cosine_sim = cos(path_vector, reference_vector)\n",
    "            dist = torch.sum((env.referenceStreamline_ijk[current_index] - next_state.getCoordinate())**2) * 10\n",
    "            reward = cosine_sim - dist\n",
    "            reward = 1 - (optimal_reward - reward)\n",
    "            if action == 100 and reward == 1:\n",
    "                terminal = True\n",
    "\n",
    "            if episode_step_counter == 200:\n",
    "                terminal = True\n",
    "                \n",
    "            #print(reward)\n",
    "            #if dist > 0.7: # cosine_sim < 0.4 or\n",
    "            #    terminal = True\n",
    "            #next_state = next_state[:2]\n",
    "            #next_transition = add_to_transition(next_state, transition)\n",
    "            \n",
    "            step_counter += 1\n",
    "            epoch_step += 1\n",
    "\n",
    "            # accumulate reward for current episode\n",
    "            episode_reward_sum += reward\n",
    "\n",
    "\n",
    "            agent.replay_memory.add_experience(action=action,\n",
    "                                #state=np.array(transition),\n",
    "                                state = state.getValue(),\n",
    "                                reward=reward,\n",
    "                                #new_state=np.array(next_transition),\n",
    "                                new_state = next_state.getValue(),\n",
    "                                terminal=terminal)\n",
    "\n",
    "\n",
    "            state = next_state\n",
    "            #transition = next_transition\n",
    "\n",
    "\n",
    "\n",
    "            ####### optimization is happening here\n",
    "            if step_counter > start_learning:\n",
    "                #if reward > 0.:\n",
    "                #    print(\"reward was positive: \", reward)\n",
    "                loss = agent.optimize()\n",
    "\n",
    "\n",
    "            ####### target network update\n",
    "            if step_counter > start_learning and step_counter % network_update_every == 0:\n",
    "                #print(\"Update net\")\n",
    "                #print(agent.main_dqn(torch.tensor(state).to(device).unsqueeze(0)))\n",
    "                #print(agent.target_dqn(torch.tensor(state).to(device).unsqueeze(0)))\n",
    "                agent.target_dqn.load_state_dict(agent.main_dqn.state_dict())\n",
    "\n",
    "            # if episode ended before maximum step\n",
    "            if terminal:\n",
    "                terminal = False\n",
    "                episode_lengths.append(episode_step_counter)\n",
    "                #state = env.reset()[:2]\n",
    "                #transition = init_transition()\n",
    "                break\n",
    "\n",
    "        eps_rewards.append(episode_reward_sum)\n",
    "\n",
    "        if len(eps_rewards) % 10 == 0:\n",
    "            #with open(path+'/logs/rewards.dat', 'a') as reward_file:\n",
    "                #print(\"[{}] {}, {}\".format(len(eps_rewards), step_counter, np.mean(eps_rewards[-100:])), file=reward_file)\n",
    "            print(\"{}, done {} episodes, {}, current eps {}\".format(step_counter, len(eps_rewards), np.mean(eps_rewards[-100:]), action_scheduler.eps_current), np.mean(episode_lengths[-100:]))\n",
    "    #torch.save(agent.main_dqn.state_dict(), path+'/checkpoints/fibre_agent_{}_reward_{:.2f}.pth'.format(step_counter, np.mean(eps_rewards[-100:])))\n",
    "\n",
    "########## evaluation starting here\n",
    "    eval_rewards = []\n",
    "    episode_final = 0\n",
    "    #agent.main_dqn.eval()\n",
    "    for _ in range(eval_runs):\n",
    "        eval_steps = 0\n",
    "        state = env.reset()\n",
    "        #transition = init_transition()\n",
    "        #env.state = TractographyState(env.referenceStreamline_ijk[0], env.interpolateDWIatState)\n",
    "        #env.stepCounter = 0\n",
    "        \n",
    "        eval_episode_reward = 0\n",
    "        while eval_steps < max_episode_length:\n",
    "            action = action_scheduler.get_action(step_counter, torch.FloatTensor(state.getValue()).unsqueeze(0).to(device), evaluation=True)\n",
    "            #action = action_scheduler.get_action(step_counter, torch.FloatTensor([np.array(transition)]).to(device), evaluation=True)\n",
    "            next_state, reward, terminal = env.step(action)\n",
    "            \n",
    "            eval_steps += 1\n",
    "            \n",
    "            terminal = False\n",
    "            current_index = np.min([env.stepCounter,len(env.referenceStreamline_ijk)-1])\n",
    "            path_vector = (next_state.getCoordinate() - state.getCoordinate()).squeeze(0)\n",
    "            reference_vector = env.referenceStreamline_ijk[current_index]-env.referenceStreamline_ijk[current_index-1]\n",
    "            #    #print(path_vector, reference_vector)\n",
    "            cosine_sim = cos(path_vector, reference_vector)\n",
    "            dist = torch.sum((env.referenceStreamline_ijk[current_index] - next_state.getCoordinate())**2) * 10\n",
    "            reward = cosine_sim - dist\n",
    "            reward = 1 - (optimal_reward - reward)\n",
    "            if action == 100 and reward == 1:\n",
    "                terminal = True\n",
    "\n",
    "            if episode_step_counter == 200:\n",
    "                terminal = True\n",
    "            \n",
    "            #if cosine_sim < 0.9:\n",
    "            #    terminal = True\n",
    "            \n",
    "            eval_episode_reward += reward\n",
    "            state = next_state\n",
    "            #transition = next_transition\n",
    "            if terminal:\n",
    "                terminal = False\n",
    "                if reward == 50.:\n",
    "                    print(reward)\n",
    "                    episode_final += 1\n",
    "                break\n",
    "\n",
    "        eval_rewards.append(eval_episode_reward)\n",
    "\n",
    "    print(\"Evaluation score:\", np.mean(eval_rewards))\n",
    "    print(\"{} of {} episodes ended close to / at the final state.\".format(episode_final, eval_runs))\n",
    "    #if np.mean(eval_rewards) > 500.:\n",
    "    #    torch.save(agent.main_dqn.state_dict(), 'trained_agents/multiple/fibre_agent_{}_reward_{:.2f}.pth'.format(step_counter, np.mean(eval_rewards))+)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(path_vector.shape)\n",
    "print(reference_vector.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(-3.5291, device='cuda:0', grad_fn=<SelectBackward>)\n"
     ]
    }
   ],
   "source": [
    "state = env.reset()\n",
    "\n",
    "q_vals = agent.main_dqn(torch.FloatTensor(state.getValue()).unsqueeze(0).to(device))\n",
    "print(q_vals[0][80])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 71 [47.23210531 74.69056928 26.15401777] [47.870224 74.80299  26.640089] tensor(872.6880, dtype=torch.float64)\n",
      "1 87 [46.61343782 74.19015468 26.00257219] [47.286892 74.28585  26.460402] tensor(871.8432, dtype=torch.float64)\n",
      "2 87 [45.99477033 73.68974008 25.85112661] [46.873352 73.67236  26.15608 ] tensor(869.2929, dtype=torch.float64)\n",
      "3 87 [45.37610284 73.18932548 25.69968103] [46.459812 73.05887  25.851759] tensor(865.1723, dtype=torch.float64)\n",
      "Evaluation score: 3478.9964573757925\n"
     ]
    }
   ],
   "source": [
    "eval_rewards = []\n",
    "all_distances = []\n",
    "all_states = []\n",
    "#agent.main_dqn.eval()\n",
    "for _ in range(1):\n",
    "    eval_steps = 0\n",
    "    state = env.reset()    \n",
    "    #state = env.reset()\n",
    "    #print(state.getCoordinate())\n",
    "    all_states.append(state.getCoordinate())\n",
    "    #transition = init_transition()\n",
    "    #all_states.append(torch.tensor(list(transition)[:3]))\n",
    "    eval_episode_reward = 0\n",
    "    episode_final = 0\n",
    "    #print(env.referenceStreamline_ijk[:6])\n",
    "    \n",
    "    while eval_steps < max_episode_length:\n",
    "        action = action_scheduler.get_action(step_counter, torch.FloatTensor(state.getValue()).unsqueeze(0).to(device), evaluation=True)\n",
    "        #action = action_scheduler.get_action(step_counter, torch.FloatTensor([np.array(transition)]).to(device), evaluation=True)\n",
    "        #action = torch.argmax(agent(torch.FloatTensor([np.array(transition)]).to(device)))\n",
    "        next_state, reward, terminal = env.step(action)\n",
    "\n",
    "        current_index = np.min([env.stepCounter,len(env.referenceStreamline_ijk)-1])\n",
    "        path_vector = (next_state.getCoordinate() - state.getCoordinate()).squeeze(0)\n",
    "        reference_vector = env.referenceStreamline_ijk[current_index]-env.referenceStreamline_ijk[current_index-1]\n",
    "        #    #print(path_vector, reference_vector)\n",
    "        cosine_sim = cos(path_vector, reference_vector)\n",
    "        dist = torch.sum((env.referenceStreamline_ijk[current_index] - next_state.getCoordinate())**2) * 10\n",
    "        reward = cosine_sim - dist\n",
    "        reward = 1 - (optimal_reward - reward)\n",
    "        \n",
    "        if action == 100 and reward == 1:\n",
    "            terminal = False\n",
    "            \n",
    "        #if cosine_sim < 0.7:\n",
    "        #    terminal = True\n",
    "        #next_state = next_state\n",
    "        #next_transition = add_to_transition(next_state, transition)\n",
    "        #reward = 1 + (1+(reward/10))\n",
    "        #if reward > 1:\n",
    "        #    reward = 1\n",
    "        #elif reward > 0.:\n",
    "        #    reward = 0\n",
    "        #else:\n",
    "        #    reward = -1\n",
    "        eval_episode_reward += reward\n",
    "        print(eval_steps, action, next_state.getCoordinate().numpy(), env.referenceStreamline_ijk[np.min([eval_steps,len(env.referenceStreamline_ijk)-1])].numpy(), reward)\n",
    "        #print(eval_steps, action, next_state, env.referenceStreamline_ijk[np.min([eval_steps,len(env.referenceStreamline_ijk)-1])].numpy(), reward)\n",
    "        eval_steps += 1\n",
    "        if eval_steps == 200:\n",
    "            terminal = True\n",
    "        all_distances.append(reward)\n",
    "        all_states.append(next_state.getCoordinate())\n",
    "        #all_states.append(next_state)\n",
    "        \n",
    "        state = next_state\n",
    "        #transition = next_transition\n",
    "        if terminal:\n",
    "            terminal = False\n",
    "            #if reward > 0.9:\n",
    "            #    episode_final += 1\n",
    "            break\n",
    "\n",
    "    eval_rewards.append(eval_episode_reward)\n",
    "\n",
    "print(\"Evaluation score:\", np.min(eval_rewards))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "False\n"
     ]
    }
   ],
   "source": [
    "states, actions, rewards, new_states, terminal_flags = agent.replay_memory.get_minibatch()\n",
    "print(np.array_equal(states[0], new_states[0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sphere_dist(nextState):\n",
    "    current_index = np.min([env.stepCounter,len(env.referenceStreamline_ijk)-1])\n",
    "    x_dist = (nextState.getCoordinate()[0] - env.referenceStreamline_ijk[current_index][0]) **2\n",
    "    y_dist = (nextState.getCoordinate()[1] - env.referenceStreamline_ijk[current_index][1]) **2\n",
    "    z_dist = (nextState.getCoordinate()[2] - env.referenceStreamline_ijk[current_index][2]) **2\n",
    "    return x_dist + y_dist + z_dist"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.99\n"
     ]
    }
   ],
   "source": [
    "print(agent.gamma)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "47 11.394252873563218 tensor(0.1970, dtype=torch.float64) tensor(0.1970, dtype=torch.float64)\n",
      "67 11.394252873563218 tensor(0.2640, dtype=torch.float64) tensor(0.2640, dtype=torch.float64)\n",
      "72 11.394252873563218 tensor(0.2650, dtype=torch.float64) tensor(0.2650, dtype=torch.float64)\n",
      "75 11.394252873563218 tensor(0.1352, dtype=torch.float64) tensor(0.1352, dtype=torch.float64)\n",
      "80 11.394252873563218 tensor(0.0623, dtype=torch.float64) tensor(0.0623, dtype=torch.float64)\n",
      "88 11.394252873563218 tensor(0.0726, dtype=torch.float64) tensor(0.0726, dtype=torch.float64)\n",
      "93 11.394252873563218 tensor(0.1499, dtype=torch.float64) tensor(0.1499, dtype=torch.float64)\n",
      "96 11.394252873563218 tensor(0.1986, dtype=torch.float64) tensor(0.1986, dtype=torch.float64)\n"
     ]
    }
   ],
   "source": [
    "for i in range(n_actions):\n",
    "    state = env.reset()\n",
    "    next_state, reward, done = env.step(i)\n",
    "    s_dist = sphere_dist(next_state)\n",
    "    old_dist = torch.sum((env.referenceStreamline_ijk[env.stepCounter] - next_state.getCoordinate())**2)\n",
    "    if s_dist <= 0.52**2:\n",
    "        print(i, reward, s_dist, old_dist)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 77.07567091 108.90497243  91.49815967] -100\n"
     ]
    }
   ],
   "source": [
    "next_state, reward, done = env.step(75)\n",
    "print(next_state.getCoordinate(), reward)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[30.283401924575482, 102.46417647849394, 66.32755479299973]\n"
     ]
    }
   ],
   "source": [
    "print(list(transition)[:3])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([ 24.1166, 103.8659,  64.9889])\n"
     ]
    }
   ],
   "source": [
    "state = env.reset()\n",
    "#referenceLine = env.referenceStreamline_ijk\n",
    "print(state.getCoordinate())\n",
    "#print(referenceLine[:10])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 23.13776944 102.38550419  64.06677327] [ 30.125023 102.08756   66.46997 ] -100\n"
     ]
    }
   ],
   "source": [
    "next_state, reward, done = env.step(74)\n",
    "print(next_state.getCoordinate().numpy(), env.referenceStreamline_ijk[np.min([env.stepCounter, len(referenceLine)])].numpy(), reward)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "71\n"
     ]
    }
   ],
   "source": [
    "optimal_steps =  [80, 88, 54, 96, 100, 67, 83, 75, 83, 75, 100, 83, 70, 67, 59, 100, 67, 59, 59, 59, 51, 100, 59, 56, 51, 61, 100, 66, 71, 66, 71, 71, 100, 71, 71, 71, 71, 100, 92, 84, 84, 38, 100, 97, 97, 97, 38, 100, 97, 30, 43, 43, 48, 100, 94, 81, 94, 35, 97, 100, 35, 22, 35, 35, 6, 100, 19, 3, 16, 3, 21, 100, 21, 16, 34, 21, 98, 34, 100, 39, 93, 39, 72, 72, 100, 69, 100]\n",
    "transition = init_transition()\n",
    "referenceLine = env.referenceStreamline_ijk\n",
    "print(len(referenceLine))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "80 -0.09999999999999964\n"
     ]
    }
   ],
   "source": [
    "#action = action_scheduler.get_action(step_counter, torch.FloatTensor([np.array(transition)]).to(device), evaluation=True)\n",
    "next_state, reward, terminal = env.step(88)\n",
    "next_transition = add_to_transition(next_state, transition)\n",
    "print(action, reward)\n",
    "transition = next_transition"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "State:  [ 73.651344 107.88106   93.29415 ]\n",
      "Next State:  [ 74.56195007 107.80595503  92.88775652]\n",
      "7.450580596923828e-09\n"
     ]
    }
   ],
   "source": [
    "# Debugging the reward function\n",
    "referenceLine = env.referenceStreamline_ijk\n",
    "stepCounter = 0\n",
    "maxSteps=200\n",
    "state = env.reset()\n",
    "print(\"State: \", state.getCoordinate().numpy())\n",
    "next_state, _, terminal = env.step(80)\n",
    "print(\"Next State: \", next_state.getCoordinate().numpy())\n",
    "\n",
    "def lineseg_dist(p, a, b):\n",
    "\n",
    "    # normalized tangent vector\n",
    "    d = np.divide(b - a, np.linalg.norm(b - a))\n",
    "\n",
    "    # signed parallel distance components\n",
    "    s = np.dot(a - p, d)\n",
    "    t = np.dot(p - b, d)\n",
    "\n",
    "    # clamped parallel distance\n",
    "    h = np.maximum.reduce([s, t, 0])\n",
    "\n",
    "    # perpendicular distance component\n",
    "    c = np.cross(p - a, d)\n",
    "\n",
    "    return np.hypot(h, np.linalg.norm(c))\n",
    "\n",
    "distance = lineseg_dist(referenceLine[86].numpy(), referenceLine[85].numpy(), referenceLine[86].numpy())\n",
    "print(distance)\n",
    "\n",
    "#print(\"Diff: \", next_state.getCoordinate().numpy()-state.getCoordinate().numpy())\n",
    "#qry_pt = next_state.getCoordinate().view(-1,3)\n",
    "#print(\"Reference next state: \", referenceLine[stepCounter+1])\n",
    "#print(\"Diff to reference state: \", referenceLine[stepCounter+1]-next_state.getCoordinate().numpy())\n",
    "#distance = torch.min(torch.sum((referenceLine[np.min([stepCounter+1, maxSteps-1])] - qry_pt)**2, dim=1))\n",
    "#print(distance)\n",
    "#reward = torch.tanh(-distance+5.3)\n",
    "\n",
    "#if distance == -1:\n",
    "#    reward = 0.5\n",
    "#elif distance < 0.8:\n",
    "#    reward = 1+ (1-distance)\n",
    "#else:\n",
    "#    reward = np.max([1 - distance, -1])\n",
    "#print(reward)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.19954145509142476\n",
      "0.03981679230000309\n",
      "0.07041062249999892\n",
      "True\n"
     ]
    }
   ],
   "source": [
    "state = np.array([ 75.6, 107.95,  92.22])\n",
    "line = np.array([ 75.78847, 107.96255,  92.28433])\n",
    "\n",
    "print(np.linalg.norm(line - state, 2))\n",
    "\n",
    "sphere_dist = ((state[0] - line[0])**2 + (state[1]-line[1])**2 + (state[2]-line[2])**2)\n",
    "print(sphere_dist)\n",
    "normal_diff = np.sum(state-line)**2\n",
    "print(normal_diff)\n",
    "if sphere_dist < 0.2**2:\n",
    "    print(True)\n",
    "else:\n",
    "    print(False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Action:  100 Reward:  -0.6400096416473389\n",
      "Action:  80 Reward:  -0.3780286503520091\n",
      "Action:  75 Reward:  -0.17094774926353554\n",
      "Action:  80 Reward:  -0.06020208127816557\n",
      "Action:  75 Reward:  -0.023724592605490286\n",
      "Action:  100 Reward:  -0.023724592605490286\n",
      "Action:  62 Reward:  -0.031680450691759385\n",
      "Action:  75 Reward:  -0.10966306950569177\n",
      "Action:  83 Reward:  -0.2621558822401104\n",
      "Action:  75 Reward:  -0.4853828474102172\n",
      "Action:  83 Reward:  -0.7713330234194417\n",
      "Action:  100 Reward:  -0.7713330234194417\n",
      "Action:  83 Reward:  -1.158927472394806\n",
      "Action:  62 Reward:  -1.6468544226974164\n",
      "Action:  67 Reward:  -2.2078664481054533\n",
      "Action:  51 Reward:  -2.459970885856384\n",
      "Action:  67 Reward:  -3.0430611441644246\n",
      "Action:  100 Reward:  -3.0430611441644246\n",
      "Action:  59 Reward:  -3.7319386628026487\n",
      "Action:  59 Reward:  -4.531517914723884\n",
      "Action:  59 Reward:  -5.427621034792285\n",
      "Action:  100 Reward:  -5.427621034792285\n",
      "Action:  59 Reward:  -6.420164664306009\n",
      "Action:  56 Reward:  -7.21012573500936\n",
      "Action:  51 Reward:  -8.185668593823168\n",
      "Action:  56 Reward:  -9.264514952082235\n",
      "Action:  66 Reward:  -9.504376152250732\n",
      "Action:  100 Reward:  -9.504376152250732\n",
      "Action:  66 Reward:  -10.878316642589324\n",
      "Action:  71 Reward:  -11.684246290994608\n",
      "Action:  71 Reward:  -13.482882171224585\n",
      "Action:  79 Reward:  -15.013766894750662\n",
      "Action:  58 Reward:  -16.29778288166172\n",
      "Action:  100 Reward:  -16.29778288166172\n",
      "Action:  71 Reward:  -17.927867464472456\n",
      "Action:  71 Reward:  -19.616943063578457\n",
      "Action:  84 Reward:  -20.74882253322799\n",
      "Action:  71 Reward:  -22.68542229369059\n",
      "Action:  100 Reward:  -22.68542229369059\n",
      "Action:  92 Reward:  -24.094491148196\n",
      "Action:  84 Reward:  -26.036910111309087\n",
      "Action:  92 Reward:  -27.894909786068872\n",
      "Action:  97 Reward:  -29.22946434143986\n",
      "Action:  100 Reward:  -29.22946434143986\n",
      "Action:  97 Reward:  -30.93770942329201\n",
      "Action:  38 Reward:  -33.06379059780991\n",
      "Action:  97 Reward:  -35.48076469151409\n",
      "Action:  43 Reward:  -37.24656758094286\n",
      "Action:  38 Reward:  -39.87506653295411\n",
      "Action:  100 Reward:  -39.87506653295411\n",
      "Action:  43 Reward:  -42.07728895704025\n",
      "Action:  43 Reward:  -44.59950388329224\n",
      "Action:  89 Reward:  -46.525702788416744\n",
      "Action:  48 Reward:  -46.51577793318299\n",
      "Action:  100 Reward:  -46.51577793318299\n",
      "Action:  94 Reward:  -44.74553361569235\n",
      "Action:  81 Reward:  -46.71395822922152\n",
      "Action:  48 Reward:  -50.26025222152221\n",
      "Action:  43 Reward:  -53.83576866536265\n",
      "Action:  100 Reward:  -53.83576866536265\n",
      "Action:  35 Reward:  -57.7679173101252\n",
      "Action:  43 Reward:  -61.07110670119785\n",
      "Action:  35 Reward:  -64.29611023518841\n",
      "Action:  22 Reward:  -64.69258594426614\n",
      "Action:  27 Reward:  -67.94753644296517\n",
      "Action:  100 Reward:  -67.94753644296517\n",
      "Action:  6 Reward:  -68.60859514506335\n",
      "Action:  11 Reward:  -70.03265506052335\n",
      "Action:  3 Reward:  -69.6074991211795\n",
      "Action:  16 Reward:  -66.45768588248448\n",
      "Action:  100 Reward:  -66.45768588248448\n",
      "Action:  8 Reward:  -63.980960033928525\n",
      "Action:  29 Reward:  -63.97912872209463\n",
      "Action:  21 Reward:  -65.2877329760679\n",
      "Action:  21 Reward:  -71.00622766156863\n",
      "Action:  100 Reward:  -71.00622766156863\n",
      "Action:  34 Reward:  -75.30646175774287\n",
      "Action:  26 Reward:  -79.7251625711022\n",
      "Action:  26 Reward:  -85.7736700190284\n",
      "Action:  93 Reward:  -86.29779314738443\n",
      "Action:  39 Reward:  -89.76066176762737\n",
      "Action:  100 Reward:  -89.76066176762737\n",
      "Action:  93 Reward:  -92.76729682665923\n",
      "Action:  72 Reward:  -91.66762326274807\n",
      "Action:  77 Reward:  -91.52645978577566\n",
      "Action:  77 Reward:  -94.77110103827272\n",
      "Action:  100 Reward:  -94.77110103827272\n",
      "-3134.679829616308\n"
     ]
    }
   ],
   "source": [
    "#optimal_steps = [80, 75, 80, 75, 62, 75, 83, 96, 51, 24, 62, 62, 62, 77, 65, 64, 67, 59, 56, 83, 82, 54, 56, 53, 56, 38, 56, 84, 66, 71, 71, 64, 97, 84, 71, 71, 38, 51, 30, 92, 97, 84, 43, 79, 27, 46, 89, 25, 81, 25, 48, 43, 86, 48, 57, 14, 89, 43, 43, 19, 92, 14, 27, 9, 78, 4, 16, 3, 29, 3, 47, 6, 42, 21, 39, 5, 72, 34, 98, 88, 90, 75, 77, 59, 49, 32, 82, 100]\n",
    "eps_reward = 0\n",
    "state = env.reset()\n",
    "for i in optimal_steps:\n",
    "    next_state, reward, terminal = env.step(i)\n",
    "    state = next_state\n",
    "    eps_reward += reward.item()\n",
    "    print(\"Action: \", i, \"Reward: \", reward.item())\n",
    "print(eps_reward)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Init environment..\n",
      "Loading precomputed streamlines (data/HCP307200_DTI_smallSet.vtk) for ID 100307\n",
      "..done!\n"
     ]
    }
   ],
   "source": [
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "print(\"Init environment..\")\n",
    "env = RLTe.RLtractEnvironment(device = 'cpu')\n",
    "print(\"..done!\")\n",
    "n_actions = env.action_space.n\n",
    "#print(n_actions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([87, 3])\n"
     ]
    }
   ],
   "source": [
    "referenceLine = env.referenceStreamline_ijk\n",
    "print(referenceLine.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([47.8702, 74.8030, 26.6401])\n",
      "tensor([47.8702, 74.8030, 26.6401])\n"
     ]
    }
   ],
   "source": [
    "print(referenceLine[0])\n",
    "state = TractographyState(referenceLine[0], env.interpolateDWIatState)\n",
    "print(state.getCoordinate())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Step:  0 Action:  41 Distance:  tensor(1.3545, dtype=torch.float64)\n",
      "Step:  0 Action:  66 Distance:  tensor(1.2187, dtype=torch.float64)\n",
      "Step:  0 Action:  74 Distance:  tensor(1.5895, dtype=torch.float64)\n",
      "Step:  0 Action:  79 Distance:  tensor(1.4856, dtype=torch.float64)\n",
      "Step:  0 Action:  82 Distance:  tensor(1.2496, dtype=torch.float64)\n",
      "Step:  0 Action:  87 Distance:  tensor(1.5944, dtype=torch.float64)\n",
      "Step:  0 Action:  95 Distance:  tensor(1.5184, dtype=torch.float64)\n",
      "0 []\n",
      "Step:  1 Action:  61 Distance:  tensor(1.3162, dtype=torch.float64)\n",
      "Step:  1 Action:  66 Distance:  tensor(1.2710, dtype=torch.float64)\n",
      "Step:  1 Action:  74 Distance:  tensor(1.6272, dtype=torch.float64)\n",
      "Step:  1 Action:  79 Distance:  tensor(1.3920, dtype=torch.float64)\n",
      "Step:  1 Action:  82 Distance:  tensor(1.4070, dtype=torch.float64)\n",
      "Step:  1 Action:  87 Distance:  tensor(1.4471, dtype=torch.float64)\n",
      "Step:  1 Action:  95 Distance:  tensor(1.5094, dtype=torch.float64)\n",
      "1 []\n",
      "Step:  2 Action:  41 Distance:  tensor(1.2821, dtype=torch.float64)\n",
      "Step:  2 Action:  61 Distance:  tensor(1.2315, dtype=torch.float64)\n",
      "Step:  2 Action:  74 Distance:  tensor(1.6046, dtype=torch.float64)\n",
      "Step:  2 Action:  79 Distance:  tensor(1.3549, dtype=torch.float64)\n",
      "Step:  2 Action:  82 Distance:  tensor(1.4040, dtype=torch.float64)\n",
      "Step:  2 Action:  87 Distance:  tensor(1.4843, dtype=torch.float64)\n",
      "Step:  2 Action:  95 Distance:  tensor(1.5651, dtype=torch.float64)\n",
      "2 []\n",
      "Step:  3 Action:  41 Distance:  tensor(1.2908, dtype=torch.float64)\n",
      "Step:  3 Action:  49 Distance:  tensor(1.2627, dtype=torch.float64)\n",
      "Step:  3 Action:  61 Distance:  tensor(1.2172, dtype=torch.float64)\n",
      "Step:  3 Action:  74 Distance:  tensor(1.5797, dtype=torch.float64)\n",
      "Step:  3 Action:  79 Distance:  tensor(1.2516, dtype=torch.float64)\n",
      "Step:  3 Action:  82 Distance:  tensor(1.4621, dtype=torch.float64)\n",
      "Step:  3 Action:  87 Distance:  tensor(1.4322, dtype=torch.float64)\n",
      "Step:  3 Action:  95 Distance:  tensor(1.6009, dtype=torch.float64)\n",
      "3 []\n",
      "Step:  4 Action:  49 Distance:  tensor(1.3226, dtype=torch.float64)\n",
      "Step:  4 Action:  61 Distance:  tensor(1.3563, dtype=torch.float64)\n",
      "Step:  4 Action:  74 Distance:  tensor(1.5702, dtype=torch.float64)\n",
      "Step:  4 Action:  82 Distance:  tensor(1.5784, dtype=torch.float64)\n",
      "Step:  4 Action:  87 Distance:  tensor(1.2502, dtype=torch.float64)\n",
      "Step:  4 Action:  95 Distance:  tensor(1.5545, dtype=torch.float64)\n",
      "4 []\n",
      "Step:  5 Action:  49 Distance:  tensor(1.2380, dtype=torch.float64)\n",
      "Step:  5 Action:  61 Distance:  tensor(1.4426, dtype=torch.float64)\n",
      "Step:  5 Action:  69 Distance:  tensor(1.2523, dtype=torch.float64)\n",
      "Step:  5 Action:  74 Distance:  tensor(1.5910, dtype=torch.float64)\n",
      "Step:  5 Action:  82 Distance:  tensor(1.5806, dtype=torch.float64)\n",
      "Step:  5 Action:  87 Distance:  tensor(1.2100, dtype=torch.float64)\n",
      "Step:  5 Action:  95 Distance:  tensor(1.4956, dtype=torch.float64)\n",
      "5 []\n",
      "Step:  6 Action:  61 Distance:  tensor(1.5273, dtype=torch.float64)\n",
      "Step:  6 Action:  66 Distance:  tensor(1.3657, dtype=torch.float64)\n",
      "Step:  6 Action:  69 Distance:  tensor(1.2500, dtype=torch.float64)\n",
      "Step:  6 Action:  74 Distance:  tensor(1.6194, dtype=torch.float64)\n",
      "Step:  6 Action:  79 Distance:  tensor(1.2759, dtype=torch.float64)\n",
      "Step:  6 Action:  82 Distance:  tensor(1.5115, dtype=torch.float64)\n",
      "Step:  6 Action:  87 Distance:  tensor(1.2051, dtype=torch.float64)\n",
      "Step:  6 Action:  95 Distance:  tensor(1.3869, dtype=torch.float64)\n",
      "6 []\n",
      "Step:  7 Action:  61 Distance:  tensor(1.5700, dtype=torch.float64)\n",
      "Step:  7 Action:  66 Distance:  tensor(1.4237, dtype=torch.float64)\n",
      "Step:  7 Action:  69 Distance:  tensor(1.2798, dtype=torch.float64)\n",
      "Step:  7 Action:  74 Distance:  tensor(1.5954, dtype=torch.float64)\n",
      "Step:  7 Action:  79 Distance:  tensor(1.2693, dtype=torch.float64)\n",
      "Step:  7 Action:  82 Distance:  tensor(1.4712, dtype=torch.float64)\n",
      "Step:  7 Action:  95 Distance:  tensor(1.2862, dtype=torch.float64)\n",
      "7 []\n",
      "Step:  8 Action:  53 Distance:  tensor(1.2474, dtype=torch.float64)\n",
      "Step:  8 Action:  61 Distance:  tensor(1.6099, dtype=torch.float64)\n",
      "Step:  8 Action:  66 Distance:  tensor(1.4011, dtype=torch.float64)\n",
      "Step:  8 Action:  69 Distance:  tensor(1.3809, dtype=torch.float64)\n",
      "Step:  8 Action:  74 Distance:  tensor(1.5549, dtype=torch.float64)\n",
      "Step:  8 Action:  82 Distance:  tensor(1.4958, dtype=torch.float64)\n",
      "Step:  8 Action:  95 Distance:  tensor(1.2269, dtype=torch.float64)\n",
      "8 []\n",
      "Step:  9 Action:  53 Distance:  tensor(1.2052, dtype=torch.float64)\n",
      "Step:  9 Action:  56 Distance:  tensor(1.2501, dtype=torch.float64)\n",
      "Step:  9 Action:  61 Distance:  tensor(1.6062, dtype=torch.float64)\n",
      "Step:  9 Action:  66 Distance:  tensor(1.2593, dtype=torch.float64)\n",
      "Step:  9 Action:  69 Distance:  tensor(1.5104, dtype=torch.float64)\n",
      "Step:  9 Action:  74 Distance:  tensor(1.4608, dtype=torch.float64)\n",
      "Step:  9 Action:  82 Distance:  tensor(1.5458, dtype=torch.float64)\n",
      "9 []\n",
      "Step:  10 Action:  56 Distance:  tensor(1.2257, dtype=torch.float64)\n",
      "Step:  10 Action:  61 Distance:  tensor(1.5655, dtype=torch.float64)\n",
      "Step:  10 Action:  69 Distance:  tensor(1.5418, dtype=torch.float64)\n",
      "Step:  10 Action:  74 Distance:  tensor(1.4100, dtype=torch.float64)\n",
      "Step:  10 Action:  82 Distance:  tensor(1.5741, dtype=torch.float64)\n",
      "Step:  10 Action:  90 Distance:  tensor(1.2631, dtype=torch.float64)\n",
      "10 []\n",
      "Step:  11 Action:  56 Distance:  tensor(1.2257, dtype=torch.float64)\n",
      "Step:  11 Action:  61 Distance:  tensor(1.5655, dtype=torch.float64)\n",
      "Step:  11 Action:  69 Distance:  tensor(1.5418, dtype=torch.float64)\n",
      "Step:  11 Action:  74 Distance:  tensor(1.4100, dtype=torch.float64)\n",
      "Step:  11 Action:  82 Distance:  tensor(1.5741, dtype=torch.float64)\n",
      "Step:  11 Action:  90 Distance:  tensor(1.2631, dtype=torch.float64)\n",
      "11 []\n",
      "Step:  12 Action:  56 Distance:  tensor(1.3080, dtype=torch.float64)\n",
      "Step:  12 Action:  61 Distance:  tensor(1.5581, dtype=torch.float64)\n",
      "Step:  12 Action:  69 Distance:  tensor(1.5947, dtype=torch.float64)\n",
      "Step:  12 Action:  74 Distance:  tensor(1.3253, dtype=torch.float64)\n",
      "Step:  12 Action:  77 Distance:  tensor(1.2564, dtype=torch.float64)\n",
      "Step:  12 Action:  82 Distance:  tensor(1.5506, dtype=torch.float64)\n",
      "Step:  12 Action:  90 Distance:  tensor(1.2967, dtype=torch.float64)\n",
      "12 []\n",
      "Step:  13 Action:  56 Distance:  tensor(1.3643, dtype=torch.float64)\n",
      "Step:  13 Action:  61 Distance:  tensor(1.5247, dtype=torch.float64)\n",
      "Step:  13 Action:  64 Distance:  tensor(1.2298, dtype=torch.float64)\n",
      "Step:  13 Action:  69 Distance:  tensor(1.6218, dtype=torch.float64)\n",
      "Step:  13 Action:  74 Distance:  tensor(1.2146, dtype=torch.float64)\n",
      "Step:  13 Action:  77 Distance:  tensor(1.3332, dtype=torch.float64)\n",
      "Step:  13 Action:  82 Distance:  tensor(1.5012, dtype=torch.float64)\n",
      "Step:  13 Action:  90 Distance:  tensor(1.3043, dtype=torch.float64)\n",
      "13 []\n",
      "Step:  14 Action:  56 Distance:  tensor(1.3236, dtype=torch.float64)\n",
      "Step:  14 Action:  61 Distance:  tensor(1.4642, dtype=torch.float64)\n",
      "Step:  14 Action:  64 Distance:  tensor(1.2667, dtype=torch.float64)\n",
      "Step:  14 Action:  69 Distance:  tensor(1.6333, dtype=torch.float64)\n",
      "Step:  14 Action:  77 Distance:  tensor(1.4185, dtype=torch.float64)\n",
      "Step:  14 Action:  82 Distance:  tensor(1.5103, dtype=torch.float64)\n",
      "Step:  14 Action:  90 Distance:  tensor(1.3923, dtype=torch.float64)\n",
      "14 []\n",
      "Step:  15 Action:  56 Distance:  tensor(1.2585, dtype=torch.float64)\n",
      "Step:  15 Action:  61 Distance:  tensor(1.3793, dtype=torch.float64)\n",
      "Step:  15 Action:  64 Distance:  tensor(1.2792, dtype=torch.float64)\n",
      "Step:  15 Action:  69 Distance:  tensor(1.6204, dtype=torch.float64)\n",
      "Step:  15 Action:  77 Distance:  tensor(1.4794, dtype=torch.float64)\n",
      "Step:  15 Action:  82 Distance:  tensor(1.4951, dtype=torch.float64)\n",
      "Step:  15 Action:  90 Distance:  tensor(1.4558, dtype=torch.float64)\n",
      "15 []\n",
      "Step:  16 Action:  61 Distance:  tensor(1.2885, dtype=torch.float64)\n",
      "Step:  16 Action:  64 Distance:  tensor(1.2906, dtype=torch.float64)\n",
      "Step:  16 Action:  69 Distance:  tensor(1.6013, dtype=torch.float64)\n",
      "Step:  16 Action:  77 Distance:  tensor(1.5375, dtype=torch.float64)\n",
      "Step:  16 Action:  82 Distance:  tensor(1.4737, dtype=torch.float64)\n",
      "Step:  16 Action:  90 Distance:  tensor(1.5160, dtype=torch.float64)\n",
      "16 []\n",
      "Step:  17 Action:  64 Distance:  tensor(1.2763, dtype=torch.float64)\n",
      "Step:  17 Action:  69 Distance:  tensor(1.5565, dtype=torch.float64)\n",
      "Step:  17 Action:  77 Distance:  tensor(1.5700, dtype=torch.float64)\n",
      "Step:  17 Action:  82 Distance:  tensor(1.4267, dtype=torch.float64)\n",
      "Step:  17 Action:  90 Distance:  tensor(1.5504, dtype=torch.float64)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Step:  17 Action:  98 Distance:  tensor(1.2671, dtype=torch.float64)\n",
      "17 []\n",
      "Step:  18 Action:  64 Distance:  tensor(1.2763, dtype=torch.float64)\n",
      "Step:  18 Action:  69 Distance:  tensor(1.5565, dtype=torch.float64)\n",
      "Step:  18 Action:  77 Distance:  tensor(1.5700, dtype=torch.float64)\n",
      "Step:  18 Action:  82 Distance:  tensor(1.4267, dtype=torch.float64)\n",
      "Step:  18 Action:  90 Distance:  tensor(1.5504, dtype=torch.float64)\n",
      "Step:  18 Action:  98 Distance:  tensor(1.2671, dtype=torch.float64)\n",
      "18 []\n",
      "Step:  19 Action:  64 Distance:  tensor(1.2807, dtype=torch.float64)\n",
      "Step:  19 Action:  69 Distance:  tensor(1.5051, dtype=torch.float64)\n",
      "Step:  19 Action:  77 Distance:  tensor(1.6072, dtype=torch.float64)\n",
      "Step:  19 Action:  82 Distance:  tensor(1.3555, dtype=torch.float64)\n",
      "Step:  19 Action:  85 Distance:  tensor(1.2477, dtype=torch.float64)\n",
      "Step:  19 Action:  90 Distance:  tensor(1.5722, dtype=torch.float64)\n",
      "Step:  19 Action:  98 Distance:  tensor(1.3832, dtype=torch.float64)\n",
      "19 []\n",
      "Step:  20 Action:  44 Distance:  tensor(1.3385, dtype=torch.float64)\n",
      "Step:  20 Action:  49 Distance:  tensor(1.2286, dtype=torch.float64)\n",
      "Step:  20 Action:  69 Distance:  tensor(1.3823, dtype=torch.float64)\n",
      "Step:  20 Action:  77 Distance:  tensor(1.5818, dtype=torch.float64)\n",
      "Step:  20 Action:  82 Distance:  tensor(1.2872, dtype=torch.float64)\n",
      "Step:  20 Action:  85 Distance:  tensor(1.2530, dtype=torch.float64)\n",
      "Step:  20 Action:  90 Distance:  tensor(1.6020, dtype=torch.float64)\n",
      "Step:  20 Action:  98 Distance:  tensor(1.4867, dtype=torch.float64)\n",
      "20 []\n",
      "Step:  21 Action:  44 Distance:  tensor(1.4217, dtype=torch.float64)\n",
      "Step:  21 Action:  49 Distance:  tensor(1.2387, dtype=torch.float64)\n",
      "Step:  21 Action:  69 Distance:  tensor(1.2773, dtype=torch.float64)\n",
      "Step:  21 Action:  77 Distance:  tensor(1.5501, dtype=torch.float64)\n",
      "Step:  21 Action:  82 Distance:  tensor(1.2059, dtype=torch.float64)\n",
      "Step:  21 Action:  85 Distance:  tensor(1.2581, dtype=torch.float64)\n",
      "Step:  21 Action:  90 Distance:  tensor(1.5947, dtype=torch.float64)\n",
      "Step:  21 Action:  98 Distance:  tensor(1.5446, dtype=torch.float64)\n",
      "21 []\n",
      "Step:  22 Action:  44 Distance:  tensor(1.4126, dtype=torch.float64)\n",
      "Step:  22 Action:  69 Distance:  tensor(1.2116, dtype=torch.float64)\n",
      "Step:  22 Action:  77 Distance:  tensor(1.5488, dtype=torch.float64)\n",
      "Step:  22 Action:  85 Distance:  tensor(1.3282, dtype=torch.float64)\n",
      "Step:  22 Action:  90 Distance:  tensor(1.5470, dtype=torch.float64)\n",
      "Step:  22 Action:  98 Distance:  tensor(1.5829, dtype=torch.float64)\n",
      "22 []\n",
      "Step:  23 Action:  31 Distance:  tensor(1.2443, dtype=torch.float64)\n",
      "Step:  23 Action:  39 Distance:  tensor(1.2866, dtype=torch.float64)\n",
      "Step:  23 Action:  44 Distance:  tensor(1.3997, dtype=torch.float64)\n",
      "Step:  23 Action:  77 Distance:  tensor(1.5426, dtype=torch.float64)\n",
      "Step:  23 Action:  85 Distance:  tensor(1.3959, dtype=torch.float64)\n",
      "Step:  23 Action:  90 Distance:  tensor(1.4943, dtype=torch.float64)\n",
      "Step:  23 Action:  98 Distance:  tensor(1.6163, dtype=torch.float64)\n",
      "23 []\n",
      "Step:  24 Action:  31 Distance:  tensor(1.2934, dtype=torch.float64)\n",
      "Step:  24 Action:  39 Distance:  tensor(1.3726, dtype=torch.float64)\n",
      "Step:  24 Action:  44 Distance:  tensor(1.3641, dtype=torch.float64)\n",
      "Step:  24 Action:  77 Distance:  tensor(1.5137, dtype=torch.float64)\n",
      "Step:  24 Action:  85 Distance:  tensor(1.4408, dtype=torch.float64)\n",
      "Step:  24 Action:  90 Distance:  tensor(1.4189, dtype=torch.float64)\n",
      "Step:  24 Action:  98 Distance:  tensor(1.6270, dtype=torch.float64)\n",
      "24 []\n",
      "Step:  25 Action:  31 Distance:  tensor(1.3955, dtype=torch.float64)\n",
      "Step:  25 Action:  39 Distance:  tensor(1.4232, dtype=torch.float64)\n",
      "Step:  25 Action:  44 Distance:  tensor(1.4189, dtype=torch.float64)\n",
      "Step:  25 Action:  77 Distance:  tensor(1.4476, dtype=torch.float64)\n",
      "Step:  25 Action:  85 Distance:  tensor(1.4018, dtype=torch.float64)\n",
      "Step:  25 Action:  90 Distance:  tensor(1.3865, dtype=torch.float64)\n",
      "Step:  25 Action:  98 Distance:  tensor(1.6444, dtype=torch.float64)\n",
      "25 []\n",
      "Step:  26 Action:  23 Distance:  tensor(1.2010, dtype=torch.float64)\n",
      "Step:  26 Action:  31 Distance:  tensor(1.5438, dtype=torch.float64)\n",
      "Step:  26 Action:  39 Distance:  tensor(1.4724, dtype=torch.float64)\n",
      "Step:  26 Action:  44 Distance:  tensor(1.4670, dtype=torch.float64)\n",
      "Step:  26 Action:  77 Distance:  tensor(1.2564, dtype=torch.float64)\n",
      "Step:  26 Action:  85 Distance:  tensor(1.2705, dtype=torch.float64)\n",
      "Step:  26 Action:  90 Distance:  tensor(1.2592, dtype=torch.float64)\n",
      "Step:  26 Action:  98 Distance:  tensor(1.6194, dtype=torch.float64)\n",
      "26 []\n",
      "Step:  27 Action:  23 Distance:  tensor(1.2617, dtype=torch.float64)\n",
      "Step:  27 Action:  26 Distance:  tensor(1.3512, dtype=torch.float64)\n",
      "Step:  27 Action:  31 Distance:  tensor(1.6077, dtype=torch.float64)\n",
      "Step:  27 Action:  39 Distance:  tensor(1.5253, dtype=torch.float64)\n",
      "Step:  27 Action:  44 Distance:  tensor(1.3890, dtype=torch.float64)\n",
      "Step:  27 Action:  98 Distance:  tensor(1.5487, dtype=torch.float64)\n",
      "27 []\n",
      "Step:  28 Action:  18 Distance:  tensor(1.2351, dtype=torch.float64)\n",
      "Step:  28 Action:  23 Distance:  tensor(1.2164, dtype=torch.float64)\n",
      "Step:  28 Action:  26 Distance:  tensor(1.4285, dtype=torch.float64)\n",
      "Step:  28 Action:  31 Distance:  tensor(1.6014, dtype=torch.float64)\n",
      "Step:  28 Action:  39 Distance:  tensor(1.5558, dtype=torch.float64)\n",
      "Step:  28 Action:  44 Distance:  tensor(1.2939, dtype=torch.float64)\n",
      "Step:  28 Action:  98 Distance:  tensor(1.4966, dtype=torch.float64)\n",
      "28 []\n",
      "Step:  29 Action:  18 Distance:  tensor(1.3395, dtype=torch.float64)\n",
      "Step:  29 Action:  23 Distance:  tensor(1.2725, dtype=torch.float64)\n",
      "Step:  29 Action:  26 Distance:  tensor(1.4920, dtype=torch.float64)\n",
      "Step:  29 Action:  31 Distance:  tensor(1.6207, dtype=torch.float64)\n",
      "Step:  29 Action:  39 Distance:  tensor(1.5335, dtype=torch.float64)\n",
      "Step:  29 Action:  44 Distance:  tensor(1.2629, dtype=torch.float64)\n",
      "Step:  29 Action:  98 Distance:  tensor(1.4319, dtype=torch.float64)\n",
      "29 []\n",
      "Step:  30 Action:  18 Distance:  tensor(1.4184, dtype=torch.float64)\n",
      "Step:  30 Action:  23 Distance:  tensor(1.3032, dtype=torch.float64)\n",
      "Step:  30 Action:  26 Distance:  tensor(1.5302, dtype=torch.float64)\n",
      "Step:  30 Action:  31 Distance:  tensor(1.6147, dtype=torch.float64)\n",
      "Step:  30 Action:  39 Distance:  tensor(1.4859, dtype=torch.float64)\n",
      "Step:  30 Action:  44 Distance:  tensor(1.2065, dtype=torch.float64)\n",
      "Step:  30 Action:  98 Distance:  tensor(1.3418, dtype=torch.float64)\n",
      "30 []\n",
      "Step:  31 Action:  13 Distance:  tensor(1.2379, dtype=torch.float64)\n",
      "Step:  31 Action:  18 Distance:  tensor(1.4916, dtype=torch.float64)\n",
      "Step:  31 Action:  23 Distance:  tensor(1.3284, dtype=torch.float64)\n",
      "Step:  31 Action:  26 Distance:  tensor(1.5638, dtype=torch.float64)\n",
      "Step:  31 Action:  31 Distance:  tensor(1.6021, dtype=torch.float64)\n",
      "Step:  31 Action:  39 Distance:  tensor(1.4352, dtype=torch.float64)\n",
      "Step:  31 Action:  98 Distance:  tensor(1.2489, dtype=torch.float64)\n",
      "31 []\n",
      "Step:  32 Action:  0 Distance:  tensor(1.2495, dtype=torch.float64)\n",
      "Step:  32 Action:  13 Distance:  tensor(1.4117, dtype=torch.float64)\n",
      "Step:  32 Action:  18 Distance:  tensor(1.5820, dtype=torch.float64)\n",
      "Step:  32 Action:  23 Distance:  tensor(1.3226, dtype=torch.float64)\n",
      "Step:  32 Action:  26 Distance:  tensor(1.5775, dtype=torch.float64)\n",
      "Step:  32 Action:  31 Distance:  tensor(1.5211, dtype=torch.float64)\n",
      "Step:  32 Action:  39 Distance:  tensor(1.2828, dtype=torch.float64)\n",
      "32 []\n",
      "Step:  33 Action:  0 Distance:  tensor(1.4203, dtype=torch.float64)\n",
      "Step:  33 Action:  5 Distance:  tensor(1.3761, dtype=torch.float64)\n",
      "Step:  33 Action:  10 Distance:  tensor(1.2212, dtype=torch.float64)\n",
      "Step:  33 Action:  13 Distance:  tensor(1.5318, dtype=torch.float64)\n",
      "Step:  33 Action:  18 Distance:  tensor(1.6109, dtype=torch.float64)\n",
      "Step:  33 Action:  23 Distance:  tensor(1.2563, dtype=torch.float64)\n",
      "Step:  33 Action:  26 Distance:  tensor(1.5325, dtype=torch.float64)\n",
      "Step:  33 Action:  31 Distance:  tensor(1.3783, dtype=torch.float64)\n",
      "33 []\n",
      "Step:  34 Action:  0 Distance:  tensor(1.5741, dtype=torch.float64)\n",
      "Step:  34 Action:  5 Distance:  tensor(1.4806, dtype=torch.float64)\n",
      "Step:  34 Action:  8 Distance:  tensor(1.2429, dtype=torch.float64)\n",
      "Step:  34 Action:  10 Distance:  tensor(1.2187, dtype=torch.float64)\n",
      "Step:  34 Action:  13 Distance:  tensor(1.6071, dtype=torch.float64)\n",
      "Step:  34 Action:  18 Distance:  tensor(1.5614, dtype=torch.float64)\n",
      "Step:  34 Action:  21 Distance:  tensor(1.2155, dtype=torch.float64)\n",
      "Step:  34 Action:  26 Distance:  tensor(1.4623, dtype=torch.float64)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Step:  34 Action:  34 Distance:  tensor(1.2363, dtype=torch.float64)\n",
      "34 []\n",
      "Step:  35 Action:  0 Distance:  tensor(1.6504, dtype=torch.float64)\n",
      "Step:  35 Action:  5 Distance:  tensor(1.4896, dtype=torch.float64)\n",
      "Step:  35 Action:  8 Distance:  tensor(1.3297, dtype=torch.float64)\n",
      "Step:  35 Action:  13 Distance:  tensor(1.6255, dtype=torch.float64)\n",
      "Step:  35 Action:  18 Distance:  tensor(1.5023, dtype=torch.float64)\n",
      "Step:  35 Action:  21 Distance:  tensor(1.3069, dtype=torch.float64)\n",
      "Step:  35 Action:  26 Distance:  tensor(1.4191, dtype=torch.float64)\n",
      "Step:  35 Action:  34 Distance:  tensor(1.2754, dtype=torch.float64)\n",
      "35 []\n",
      "Step:  36 Action:  0 Distance:  tensor(1.6504, dtype=torch.float64)\n",
      "Step:  36 Action:  5 Distance:  tensor(1.4574, dtype=torch.float64)\n",
      "Step:  36 Action:  8 Distance:  tensor(1.3736, dtype=torch.float64)\n",
      "Step:  36 Action:  13 Distance:  tensor(1.6424, dtype=torch.float64)\n",
      "Step:  36 Action:  18 Distance:  tensor(1.4433, dtype=torch.float64)\n",
      "Step:  36 Action:  21 Distance:  tensor(1.3961, dtype=torch.float64)\n",
      "Step:  36 Action:  26 Distance:  tensor(1.4171, dtype=torch.float64)\n",
      "Step:  36 Action:  34 Distance:  tensor(1.3541, dtype=torch.float64)\n",
      "36 []\n",
      "Step:  37 Action:  0 Distance:  tensor(1.6297, dtype=torch.float64)\n",
      "Step:  37 Action:  5 Distance:  tensor(1.3586, dtype=torch.float64)\n",
      "Step:  37 Action:  8 Distance:  tensor(1.3157, dtype=torch.float64)\n",
      "Step:  37 Action:  13 Distance:  tensor(1.6391, dtype=torch.float64)\n",
      "Step:  37 Action:  18 Distance:  tensor(1.3957, dtype=torch.float64)\n",
      "Step:  37 Action:  21 Distance:  tensor(1.4311, dtype=torch.float64)\n",
      "Step:  37 Action:  26 Distance:  tensor(1.4701, dtype=torch.float64)\n",
      "Step:  37 Action:  34 Distance:  tensor(1.4513, dtype=torch.float64)\n",
      "37 []\n",
      "Step:  38 Action:  0 Distance:  tensor(1.5064, dtype=torch.float64)\n",
      "Step:  38 Action:  5 Distance:  tensor(1.2675, dtype=torch.float64)\n",
      "Step:  38 Action:  8 Distance:  tensor(1.2816, dtype=torch.float64)\n",
      "Step:  38 Action:  13 Distance:  tensor(1.6227, dtype=torch.float64)\n",
      "Step:  38 Action:  18 Distance:  tensor(1.3224, dtype=torch.float64)\n",
      "Step:  38 Action:  21 Distance:  tensor(1.4697, dtype=torch.float64)\n",
      "Step:  38 Action:  26 Distance:  tensor(1.4794, dtype=torch.float64)\n",
      "Step:  38 Action:  34 Distance:  tensor(1.5213, dtype=torch.float64)\n",
      "Step:  38 Action:  47 Distance:  tensor(1.2133, dtype=torch.float64)\n",
      "38 []\n",
      "Step:  39 Action:  0 Distance:  tensor(1.5209, dtype=torch.float64)\n",
      "Step:  39 Action:  5 Distance:  tensor(1.2129, dtype=torch.float64)\n",
      "Step:  39 Action:  8 Distance:  tensor(1.3191, dtype=torch.float64)\n",
      "Step:  39 Action:  13 Distance:  tensor(1.5965, dtype=torch.float64)\n",
      "Step:  39 Action:  18 Distance:  tensor(1.2075, dtype=torch.float64)\n",
      "Step:  39 Action:  21 Distance:  tensor(1.5323, dtype=torch.float64)\n",
      "Step:  39 Action:  26 Distance:  tensor(1.4036, dtype=torch.float64)\n",
      "Step:  39 Action:  34 Distance:  tensor(1.5428, dtype=torch.float64)\n",
      "39 []\n",
      "Step:  40 Action:  0 Distance:  tensor(1.5209, dtype=torch.float64)\n",
      "Step:  40 Action:  5 Distance:  tensor(1.2129, dtype=torch.float64)\n",
      "Step:  40 Action:  8 Distance:  tensor(1.3191, dtype=torch.float64)\n",
      "Step:  40 Action:  13 Distance:  tensor(1.5965, dtype=torch.float64)\n",
      "Step:  40 Action:  18 Distance:  tensor(1.2075, dtype=torch.float64)\n",
      "Step:  40 Action:  21 Distance:  tensor(1.5323, dtype=torch.float64)\n",
      "Step:  40 Action:  26 Distance:  tensor(1.4036, dtype=torch.float64)\n",
      "Step:  40 Action:  34 Distance:  tensor(1.5428, dtype=torch.float64)\n",
      "40 []\n",
      "Step:  41 Action:  0 Distance:  tensor(1.5209, dtype=torch.float64)\n",
      "Step:  41 Action:  5 Distance:  tensor(1.2129, dtype=torch.float64)\n",
      "Step:  41 Action:  8 Distance:  tensor(1.3191, dtype=torch.float64)\n",
      "Step:  41 Action:  13 Distance:  tensor(1.5965, dtype=torch.float64)\n",
      "Step:  41 Action:  18 Distance:  tensor(1.2075, dtype=torch.float64)\n",
      "Step:  41 Action:  21 Distance:  tensor(1.5323, dtype=torch.float64)\n",
      "Step:  41 Action:  26 Distance:  tensor(1.4036, dtype=torch.float64)\n",
      "Step:  41 Action:  34 Distance:  tensor(1.5428, dtype=torch.float64)\n",
      "41 []\n",
      "Step:  42 Action:  0 Distance:  tensor(1.5209, dtype=torch.float64)\n",
      "Step:  42 Action:  5 Distance:  tensor(1.2129, dtype=torch.float64)\n",
      "Step:  42 Action:  8 Distance:  tensor(1.3191, dtype=torch.float64)\n",
      "Step:  42 Action:  13 Distance:  tensor(1.5965, dtype=torch.float64)\n",
      "Step:  42 Action:  18 Distance:  tensor(1.2075, dtype=torch.float64)\n",
      "Step:  42 Action:  21 Distance:  tensor(1.5323, dtype=torch.float64)\n",
      "Step:  42 Action:  26 Distance:  tensor(1.4036, dtype=torch.float64)\n",
      "Step:  42 Action:  34 Distance:  tensor(1.5428, dtype=torch.float64)\n",
      "42 []\n",
      "Step:  43 Action:  0 Distance:  tensor(1.5209, dtype=torch.float64)\n",
      "Step:  43 Action:  5 Distance:  tensor(1.2129, dtype=torch.float64)\n",
      "Step:  43 Action:  8 Distance:  tensor(1.3191, dtype=torch.float64)\n",
      "Step:  43 Action:  13 Distance:  tensor(1.5965, dtype=torch.float64)\n",
      "Step:  43 Action:  18 Distance:  tensor(1.2075, dtype=torch.float64)\n",
      "Step:  43 Action:  21 Distance:  tensor(1.5323, dtype=torch.float64)\n",
      "Step:  43 Action:  26 Distance:  tensor(1.4036, dtype=torch.float64)\n",
      "Step:  43 Action:  34 Distance:  tensor(1.5428, dtype=torch.float64)\n",
      "43 []\n",
      "Step:  44 Action:  0 Distance:  tensor(1.5209, dtype=torch.float64)\n",
      "Step:  44 Action:  5 Distance:  tensor(1.2129, dtype=torch.float64)\n",
      "Step:  44 Action:  8 Distance:  tensor(1.3191, dtype=torch.float64)\n",
      "Step:  44 Action:  13 Distance:  tensor(1.5965, dtype=torch.float64)\n",
      "Step:  44 Action:  18 Distance:  tensor(1.2075, dtype=torch.float64)\n",
      "Step:  44 Action:  21 Distance:  tensor(1.5323, dtype=torch.float64)\n",
      "Step:  44 Action:  26 Distance:  tensor(1.4036, dtype=torch.float64)\n",
      "Step:  44 Action:  34 Distance:  tensor(1.5428, dtype=torch.float64)\n",
      "44 []\n",
      "Step:  45 Action:  0 Distance:  tensor(1.5209, dtype=torch.float64)\n",
      "Step:  45 Action:  5 Distance:  tensor(1.2129, dtype=torch.float64)\n",
      "Step:  45 Action:  8 Distance:  tensor(1.3191, dtype=torch.float64)\n",
      "Step:  45 Action:  13 Distance:  tensor(1.5965, dtype=torch.float64)\n",
      "Step:  45 Action:  18 Distance:  tensor(1.2075, dtype=torch.float64)\n",
      "Step:  45 Action:  21 Distance:  tensor(1.5323, dtype=torch.float64)\n",
      "Step:  45 Action:  26 Distance:  tensor(1.4036, dtype=torch.float64)\n",
      "Step:  45 Action:  34 Distance:  tensor(1.5428, dtype=torch.float64)\n",
      "45 []\n",
      "Step:  46 Action:  0 Distance:  tensor(1.5209, dtype=torch.float64)\n",
      "Step:  46 Action:  5 Distance:  tensor(1.2129, dtype=torch.float64)\n",
      "Step:  46 Action:  8 Distance:  tensor(1.3191, dtype=torch.float64)\n",
      "Step:  46 Action:  13 Distance:  tensor(1.5965, dtype=torch.float64)\n",
      "Step:  46 Action:  18 Distance:  tensor(1.2075, dtype=torch.float64)\n",
      "Step:  46 Action:  21 Distance:  tensor(1.5323, dtype=torch.float64)\n",
      "Step:  46 Action:  26 Distance:  tensor(1.4036, dtype=torch.float64)\n",
      "Step:  46 Action:  34 Distance:  tensor(1.5428, dtype=torch.float64)\n",
      "46 []\n",
      "Step:  47 Action:  0 Distance:  tensor(1.5209, dtype=torch.float64)\n",
      "Step:  47 Action:  8 Distance:  tensor(1.2639, dtype=torch.float64)\n",
      "Step:  47 Action:  13 Distance:  tensor(1.5583, dtype=torch.float64)\n",
      "Step:  47 Action:  21 Distance:  tensor(1.5480, dtype=torch.float64)\n",
      "Step:  47 Action:  26 Distance:  tensor(1.3944, dtype=torch.float64)\n",
      "Step:  47 Action:  34 Distance:  tensor(1.5913, dtype=torch.float64)\n",
      "Step:  47 Action:  42 Distance:  tensor(1.2956, dtype=torch.float64)\n",
      "Step:  47 Action:  47 Distance:  tensor(1.2660, dtype=torch.float64)\n",
      "47 []\n",
      "Step:  48 Action:  0 Distance:  tensor(1.3885, dtype=torch.float64)\n",
      "Step:  48 Action:  8 Distance:  tensor(1.2964, dtype=torch.float64)\n",
      "Step:  48 Action:  13 Distance:  tensor(1.5198, dtype=torch.float64)\n",
      "Step:  48 Action:  21 Distance:  tensor(1.5907, dtype=torch.float64)\n",
      "Step:  48 Action:  26 Distance:  tensor(1.3027, dtype=torch.float64)\n",
      "Step:  48 Action:  29 Distance:  tensor(1.2582, dtype=torch.float64)\n",
      "Step:  48 Action:  34 Distance:  tensor(1.5862, dtype=torch.float64)\n",
      "Step:  48 Action:  42 Distance:  tensor(1.3674, dtype=torch.float64)\n",
      "Step:  48 Action:  47 Distance:  tensor(1.2157, dtype=torch.float64)\n",
      "48 []\n",
      "Step:  49 Action:  0 Distance:  tensor(1.5321, dtype=torch.float64)\n",
      "Step:  49 Action:  8 Distance:  tensor(1.3821, dtype=torch.float64)\n",
      "Step:  49 Action:  13 Distance:  tensor(1.5176, dtype=torch.float64)\n",
      "Step:  49 Action:  21 Distance:  tensor(1.6158, dtype=torch.float64)\n",
      "Step:  49 Action:  26 Distance:  tensor(1.2182, dtype=torch.float64)\n",
      "Step:  49 Action:  29 Distance:  tensor(1.3106, dtype=torch.float64)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Step:  49 Action:  34 Distance:  tensor(1.5309, dtype=torch.float64)\n",
      "Step:  49 Action:  42 Distance:  tensor(1.3322, dtype=torch.float64)\n",
      "49 []\n",
      "Step:  50 Action:  0 Distance:  tensor(1.5322, dtype=torch.float64)\n",
      "Step:  50 Action:  8 Distance:  tensor(1.3821, dtype=torch.float64)\n",
      "Step:  50 Action:  13 Distance:  tensor(1.5176, dtype=torch.float64)\n",
      "Step:  50 Action:  21 Distance:  tensor(1.6158, dtype=torch.float64)\n",
      "Step:  50 Action:  26 Distance:  tensor(1.2182, dtype=torch.float64)\n",
      "Step:  50 Action:  29 Distance:  tensor(1.3106, dtype=torch.float64)\n",
      "Step:  50 Action:  34 Distance:  tensor(1.5309, dtype=torch.float64)\n",
      "Step:  50 Action:  42 Distance:  tensor(1.3322, dtype=torch.float64)\n",
      "50 []\n",
      "Step:  51 Action:  0 Distance:  tensor(1.5321, dtype=torch.float64)\n",
      "Step:  51 Action:  5 Distance:  tensor(1.2367, dtype=torch.float64)\n",
      "Step:  51 Action:  8 Distance:  tensor(1.4490, dtype=torch.float64)\n",
      "Step:  51 Action:  13 Distance:  tensor(1.5675, dtype=torch.float64)\n",
      "Step:  51 Action:  21 Distance:  tensor(1.6079, dtype=torch.float64)\n",
      "Step:  51 Action:  26 Distance:  tensor(1.2407, dtype=torch.float64)\n",
      "Step:  51 Action:  29 Distance:  tensor(1.2570, dtype=torch.float64)\n",
      "Step:  51 Action:  34 Distance:  tensor(1.4905, dtype=torch.float64)\n",
      "Step:  51 Action:  42 Distance:  tensor(1.2329, dtype=torch.float64)\n",
      "51 []\n",
      "Step:  52 Action:  0 Distance:  tensor(1.6565, dtype=torch.float64)\n",
      "Step:  52 Action:  5 Distance:  tensor(1.3360, dtype=torch.float64)\n",
      "Step:  52 Action:  8 Distance:  tensor(1.4893, dtype=torch.float64)\n",
      "Step:  52 Action:  13 Distance:  tensor(1.5909, dtype=torch.float64)\n",
      "Step:  52 Action:  21 Distance:  tensor(1.5736, dtype=torch.float64)\n",
      "Step:  52 Action:  26 Distance:  tensor(1.2366, dtype=torch.float64)\n",
      "Step:  52 Action:  34 Distance:  tensor(1.4237, dtype=torch.float64)\n",
      "52 []\n",
      "Step:  53 Action:  0 Distance:  tensor(1.6565, dtype=torch.float64)\n",
      "Step:  53 Action:  5 Distance:  tensor(1.3360, dtype=torch.float64)\n",
      "Step:  53 Action:  8 Distance:  tensor(1.4893, dtype=torch.float64)\n",
      "Step:  53 Action:  13 Distance:  tensor(1.5909, dtype=torch.float64)\n",
      "Step:  53 Action:  21 Distance:  tensor(1.5736, dtype=torch.float64)\n",
      "Step:  53 Action:  26 Distance:  tensor(1.2366, dtype=torch.float64)\n",
      "Step:  53 Action:  34 Distance:  tensor(1.4237, dtype=torch.float64)\n",
      "53 []\n",
      "Step:  54 Action:  0 Distance:  tensor(1.6565, dtype=torch.float64)\n",
      "Step:  54 Action:  5 Distance:  tensor(1.4373, dtype=torch.float64)\n",
      "Step:  54 Action:  8 Distance:  tensor(1.5157, dtype=torch.float64)\n",
      "Step:  54 Action:  13 Distance:  tensor(1.6149, dtype=torch.float64)\n",
      "Step:  54 Action:  18 Distance:  tensor(1.2637, dtype=torch.float64)\n",
      "Step:  54 Action:  21 Distance:  tensor(1.5260, dtype=torch.float64)\n",
      "Step:  54 Action:  26 Distance:  tensor(1.2495, dtype=torch.float64)\n",
      "Step:  54 Action:  34 Distance:  tensor(1.3568, dtype=torch.float64)\n",
      "54 []\n",
      "Step:  55 Action:  0 Distance:  tensor(1.7441, dtype=torch.float64)\n",
      "Step:  55 Action:  5 Distance:  tensor(1.5640, dtype=torch.float64)\n",
      "Step:  55 Action:  8 Distance:  tensor(1.5016, dtype=torch.float64)\n",
      "Step:  55 Action:  13 Distance:  tensor(1.5992, dtype=torch.float64)\n",
      "Step:  55 Action:  18 Distance:  tensor(1.3915, dtype=torch.float64)\n",
      "Step:  55 Action:  21 Distance:  tensor(1.3772, dtype=torch.float64)\n",
      "Step:  55 Action:  26 Distance:  tensor(1.2197, dtype=torch.float64)\n",
      "55 []\n",
      "Step:  56 Action:  0 Distance:  tensor(1.7894, dtype=torch.float64)\n"
     ]
    },
    {
     "ename": "IndexError",
     "evalue": "index 58 is out of bounds for dimension 0 with size 58",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mIndexError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-6-a7dce26ea5fa>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      7\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0mz\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mn_actions\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m         \u001b[0menv\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstate\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mTractographyState\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mreferenceLine\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0menv\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minterpolateDWIatState\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 9\u001b[0;31m         \u001b[0mnext_state\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mreward\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0menv\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mz\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     10\u001b[0m         \u001b[0menv\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstepCounter\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mi\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     11\u001b[0m         \u001b[0;31m#if reward == -1:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/fibre_tracking/deepFibreTracking/dfibert/envs/RLtractEnvironment.py\u001b[0m in \u001b[0;36mstep\u001b[0;34m(self, action)\u001b[0m\n\u001b[1;32m    138\u001b[0m         \u001b[0;31m#else:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    139\u001b[0m         \u001b[0;31m#    rewardNextState = rewardDistance\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 140\u001b[0;31m         \u001b[0mrewardNextState\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrewardForState\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnextState\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    141\u001b[0m         \u001b[0;31m#if rewardNextState < 0.:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    142\u001b[0m         \u001b[0;31m#    rewardNextState = -1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/fibre_tracking/deepFibreTracking/dfibert/envs/RLtractEnvironment.py\u001b[0m in \u001b[0;36mrewardForState\u001b[0;34m(self, state)\u001b[0m\n\u001b[1;32m    160\u001b[0m         \u001b[0mqry_pt\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mstate\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgetCoordinate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mview\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m3\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    161\u001b[0m         \u001b[0;31m#distance = torch.min(torch.sum( (self.referenceStreamline_ijk[np.max([self.stepCounter-1-2,0]):np.min([self.stepCounter-1+1,self.maxSteps])] - qry_pt)**2, dim =1 ))\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 162\u001b[0;31m         \u001b[0mdistance\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msum\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreferenceStreamline_ijk\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstepCounter\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m86\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0mqry_pt\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m**\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdim\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    163\u001b[0m         \u001b[0;31m#reward = torch.tanh(-distance+5.3)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    164\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mdistance\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mIndexError\u001b[0m: index 58 is out of bounds for dimension 0 with size 58"
     ]
    }
   ],
   "source": [
    "possible_actions = []\n",
    "past_state = env.reset()\n",
    "all_next_states = []\n",
    "for i in range(len(referenceLine)):\n",
    "    best_actions = []\n",
    "    next_states = []\n",
    "    for z in range(n_actions):\n",
    "        env.state = TractographyState(referenceLine[i], env.interpolateDWIatState)\n",
    "        next_state, reward, _ = env.step(z)\n",
    "        env.stepCounter = i\n",
    "        #if reward == -1:\n",
    "        #    reward = 0\n",
    "        #elif reward < 0.2:\n",
    "        if reward > 1.0:\n",
    "            print(\"Step: \", i, \"Action: \", z, \"Distance: \", reward)\n",
    "        #    reward = 1\n",
    "        #elif reward < 1.:\n",
    "        #    reward = 0\n",
    "        #else:\n",
    "        #    reward = -1\n",
    "        #if reward == 1:\n",
    "        #    best_actions.append(z)\n",
    "            #print(i, z, referenceLine[i].numpy(), next_state.getCoordinate().numpy(), reward)\n",
    "    print(i, best_actions)\n",
    "    #print(i, reward)\n",
    "    #if reward > 0.9:\n",
    "    #    best_actions.append(i)\n",
    "    possible_actions.append(best_actions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "step_distance = []\n",
    "optimal_steps = []#[100, 80, 75, 80, 75, 100, 62, 75, 83, 75, 83, 100, 83, 62, 67, 51, 67, 100, 59, 59, 59, 100, 59, 56, 51, 56, 66, 100, 66, 71, 71, 79, 58, 100, 71, 71, 84, 71, 100, 92, 84, 92, 97, 100, 97, 38, 97, 43, 38, 100, 43, 43, 89, 48]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "87\n"
     ]
    }
   ],
   "source": [
    "last_state = env.reset()\n",
    "print(len(env.referenceStreamline_ijk))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Hey, hey, hey we finally stopped at the terminal state! :D\n",
      "Hey, hey, hey we finally stopped at the terminal state! :D\n",
      "Hey, hey, hey we finally stopped at the terminal state! :D\n",
      "Hey, hey, hey we finally stopped at the terminal state! :D\n",
      "Hey, hey, hey we finally stopped at the terminal state! :D\n",
      "Hey, hey, hey we finally stopped at the terminal state! :D\n",
      "Hey, hey, hey we finally stopped at the terminal state! :D\n",
      "Hey, hey, hey we finally stopped at the terminal state! :D\n",
      "Hey, hey, hey we finally stopped at the terminal state! :D\n",
      "Hey, hey, hey we finally stopped at the terminal state! :D\n",
      "Hey, hey, hey we finally stopped at the terminal state! :D\n",
      "Hey, hey, hey we finally stopped at the terminal state! :D\n",
      "Hey, hey, hey we finally stopped at the terminal state! :D\n",
      "Hey, hey, hey we finally stopped at the terminal state! :D\n",
      "Hey, hey, hey we finally stopped at the terminal state! :D\n",
      "Hey, hey, hey we finally stopped at the terminal state! :D\n",
      "Hey, hey, hey we finally stopped at the terminal state! :D\n",
      "Hey, hey, hey we finally stopped at the terminal state! :D\n",
      "Hey, hey, hey we finally stopped at the terminal state! :D\n",
      "Hey, hey, hey we finally stopped at the terminal state! :D\n",
      "Hey, hey, hey we finally stopped at the terminal state! :D\n",
      "Hey, hey, hey we finally stopped at the terminal state! :D\n",
      "Hey, hey, hey we finally stopped at the terminal state! :D\n",
      "Hey, hey, hey we finally stopped at the terminal state! :D\n",
      "Hey, hey, hey we finally stopped at the terminal state! :D\n",
      "Hey, hey, hey we finally stopped at the terminal state! :D\n",
      "Hey, hey, hey we finally stopped at the terminal state! :D\n",
      "Hey, hey, hey we finally stopped at the terminal state! :D\n",
      "Hey, hey, hey we finally stopped at the terminal state! :D\n",
      "Hey, hey, hey we finally stopped at the terminal state! :D\n",
      "Hey, hey, hey we finally stopped at the terminal state! :D\n",
      "Hey, hey, hey we finally stopped at the terminal state! :D\n",
      "Hey, hey, hey we finally stopped at the terminal state! :D\n",
      "Hey, hey, hey we finally stopped at the terminal state! :D\n",
      "Hey, hey, hey we finally stopped at the terminal state! :D\n",
      "Hey, hey, hey we finally stopped at the terminal state! :D\n",
      "Hey, hey, hey we finally stopped at the terminal state! :D\n",
      "Hey, hey, hey we finally stopped at the terminal state! :D\n",
      "Hey, hey, hey we finally stopped at the terminal state! :D\n",
      "Hey, hey, hey we finally stopped at the terminal state! :D\n",
      "Hey, hey, hey we finally stopped at the terminal state! :D\n",
      "Hey, hey, hey we finally stopped at the terminal state! :D\n",
      "Hey, hey, hey we finally stopped at the terminal state! :D\n",
      "Hey, hey, hey we finally stopped at the terminal state! :D\n",
      "Hey, hey, hey we finally stopped at the terminal state! :D\n",
      "Hey, hey, hey we finally stopped at the terminal state! :D\n",
      "Hey, hey, hey we finally stopped at the terminal state! :D\n",
      "Hey, hey, hey we finally stopped at the terminal state! :D\n",
      "Hey, hey, hey we finally stopped at the terminal state! :D\n",
      "Hey, hey, hey we finally stopped at the terminal state! :D\n",
      "Hey, hey, hey we finally stopped at the terminal state! :D\n",
      "Hey, hey, hey we finally stopped at the terminal state! :D\n",
      "Hey, hey, hey we finally stopped at the terminal state! :D\n",
      "Hey, hey, hey we finally stopped at the terminal state! :D\n",
      "Hey, hey, hey we finally stopped at the terminal state! :D\n",
      "Hey, hey, hey we finally stopped at the terminal state! :D\n",
      "Hey, hey, hey we finally stopped at the terminal state! :D\n",
      "Hey, hey, hey we finally stopped at the terminal state! :D\n",
      "Hey, hey, hey we finally stopped at the terminal state! :D\n",
      "Hey, hey, hey we finally stopped at the terminal state! :D\n",
      "Hey, hey, hey we finally stopped at the terminal state! :D\n",
      "Hey, hey, hey we finally stopped at the terminal state! :D\n",
      "Hey, hey, hey we finally stopped at the terminal state! :D\n",
      "Hey, hey, hey we finally stopped at the terminal state! :D\n",
      "Hey, hey, hey we finally stopped at the terminal state! :D\n",
      "Hey, hey, hey we finally stopped at the terminal state! :D\n",
      "Hey, hey, hey we finally stopped at the terminal state! :D\n",
      "Hey, hey, hey we finally stopped at the terminal state! :D\n",
      "Hey, hey, hey we finally stopped at the terminal state! :D\n",
      "Hey, hey, hey we finally stopped at the terminal state! :D\n",
      "Hey, hey, hey we finally stopped at the terminal state! :D\n",
      "Hey, hey, hey we finally stopped at the terminal state! :D\n",
      "Hey, hey, hey we finally stopped at the terminal state! :D\n",
      "Hey, hey, hey we finally stopped at the terminal state! :D\n",
      "Hey, hey, hey we finally stopped at the terminal state! :D\n",
      "Hey, hey, hey we finally stopped at the terminal state! :D\n",
      "Hey, hey, hey we finally stopped at the terminal state! :D\n",
      "Hey, hey, hey we finally stopped at the terminal state! :D\n",
      "Hey, hey, hey we finally stopped at the terminal state! :D\n",
      "Hey, hey, hey we finally stopped at the terminal state! :D\n",
      "Hey, hey, hey we finally stopped at the terminal state! :D\n",
      "Hey, hey, hey we finally stopped at the terminal state! :D\n",
      "Hey, hey, hey we finally stopped at the terminal state! :D\n",
      "Hey, hey, hey we finally stopped at the terminal state! :D\n",
      "Hey, hey, hey we finally stopped at the terminal state! :D\n",
      "Hey, hey, hey we finally stopped at the terminal state! :D\n",
      "[80, 88, 67, 75, 75, 62, 75, 83, 75, 83, 83, 83, 62, 67, 67, 54, 59, 59, 59, 59, 59, 59, 51, 56, 51, 56, 66, 66, 79, 71, 71, 66, 71, 71, 71, 71, 71, 84, 92, 84, 84, 92, 97, 97, 38, 97, 97, 38, 43, 43, 38, 35, 89, 48, 48, 73, 94, 35, 89, 43, 35, 22, 35, 35, 14, 14, 11, 3, 3, 16, 16, 21, 16, 21, 21, 34, 26, 47, 26, 39, 93, 39, 72, 72, 77, 77, 100]\n"
     ]
    }
   ],
   "source": [
    "steps = 0\n",
    "while len(optimal_steps) < 87:\n",
    "    step_distance = []\n",
    "    for i in range(n_actions):\n",
    "        env.reset()\n",
    "        if len(optimal_steps)>0:\n",
    "            for z in range(len(optimal_steps)):\n",
    "                _,_,_ = env.step(optimal_steps[z])\n",
    "        next_state, _, terminal = env.step(i)\n",
    "        #distance = lineseg_dist(next_state.getCoordinate().numpy(), referenceLine[np.min([len(optimal_steps), 85])].numpy(), referenceLine[np.min([len(optimal_steps)+1, len(referenceLine)-1])].numpy())\n",
    "        #distance = ((next_state.getCoordinate()[0] - env.referenceStreamline_ijk[np.min([env.stepCounter, 58])][0])**2 \\\n",
    "        #              + (next_state.getCoordinate()[1] - env.referenceStreamline_ijk[np.min([env.stepCounter, 58])][1])**2 \\\n",
    "        #              + (next_state.getCoordinate()[2] - env.referenceStreamline_ijk[np.min([env.stepCounter, 58])][2])**2)\n",
    "        current_index = np.min([env.stepCounter, len(env.referenceStreamline_ijk)-1])\n",
    "        qry_pt = next_state.getCoordinate().view(-1,3)\n",
    "        distance = torch.sum((env.referenceStreamline_ijk[current_index] - qry_pt)**2)\n",
    "        \n",
    "        step_distance.append(distance)\n",
    "    optimal_steps.append(np.argmin(step_distance))\n",
    "print(optimal_steps)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Streamline index 0, stepWidth 0.81\n",
    "optimal_steps = [80, 88, 67, 75, 75, 62, 75, 83, 75, 83, 83, 83, 62, 67, 67, 54, 59, 59, 59, 59, 59, 59, 51, 56, 51, 56, 66, 66, 79, 71, 71, 66, 71, 71, 71, 71, 71, 84, 92, 84, 84, 92, 97, 97, 38, 97, 97, 38, 43, 43, 38, 35, 89, 48, 48, 73, 94, 35, 89, 43, 35, 22, 35, 35, 14, 14, 11, 3, 3, 16, 16, 21, 16, 21, 21, 34, 26, 47, 26, 39, 93, 39, 72, 72, 77, 77, 100]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Streamline index 4, stepWidth 0.81\n",
    "optimal_steps = [17, 30, 17, 30, 17, 30, 17, 1, 6, 3, 3, 3, 11, 16, 16, 24, 16, 24, 37, 24, 91, 45, 78, 78, 86, 99, 86, 86, 86, 70, 70, 65, 70, 65, 86, 65, 86, 99, 99, 40, 45, 45, 100]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Streamline index 4, stepWidth 0.79\n",
    "#optimal_steps =[17, 30, 17, 30, 17, 30, 17, 1, 6, 3, 3, 3, 11, 16, 16, 16, 24, 24, 24, 37, 24, 91, 78, 78, 99, 86, 86, 86, 86, 86, 70, 70, 70, 65, 65, 86, 86, 86, 99, 99, 99, 45, 99]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Streamline index 4, stepWidth 0.78\n",
    "#optimal_steps = [17, 30, 17, 30, 17, 30, 17, 1, 6, 1, 3, 11, 3, 16, 16, 24, 16, 24, 24, 37, 37, 45, 78, 78, 99, 86, 86, 78, 86, 86, 78, 70, 65, 65, 65, 86, 86, 86, 99, 99, 99, 45, 78]\n",
    "print(optimal_steps)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[17, 30, 17, 30, 17, 30, 17, 1, 6, 3, 3, 3, 11, 16, 16, 16, 24, 24, 37, 24, 37, 78, 45, 78, 86, 86, 86, 86, 86, 78, 70, 65, 70, 65, 86, 65, 86, 86, 99, 32, 99, 45]\n"
     ]
    }
   ],
   "source": [
    "# Streamline index 4, stepWidth 0.8\n",
    "#optimal_steps = [17, 30, 17, 30, 17, 30, 17, 1, 6, 3, 3, 3, 11, 16, 16, 16, 24, 24, 37, 24, 37, 78, 45, 78, 86, 86, 86, 86, 86, 78, 70, 65, 70, 65, 86, 65, 86, 86, 99, 32, 99, 45]\n",
    "print(optimal_steps)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Streamline index 2\n",
    "optimal_steps = [3, 3, 100, 6, 3, 11, 3, 6, 100, 11, 6, 11, 3, 100, 19, 3, 11, 6, 16, 100, 3, 3, 3, 2, 11, 7, 18, 100, 15, 7, 2, 2, 100, 0, 10, 0, 2, 0, 100, 0, 0, 3, 0, 11, 100, 3, 3, 3, 3, 100, 3, 3, 1, 11, 100, 3, 3, 3, 16, 11, 100, 16, 29, 16, 42, 100, 21, 29, 21, 42, 21, 100, 34, 21, 13, 26, 100, 23, 18, 23, 31, 100, 44, 31, 31, 44, 44, 100, 44, 31, 36, 98, 15, 100, 23, 23, 44, 15, 44, 100, 15, 28, 15, 20, 36, 100, 20, 28, 20, 20, 100, 28, 28, 36, 49, 28, 100, 36, 49, 49, 90, 100, 49, 95, 95, 49, 46, 49, 38, 36, 25, 100, 28, 28, 33, 36, 41, 100, 20, 28, 12, 20, 20, 100, 7, 15, 7, 20, 10, 25, 100]\n",
    "#print(optimal_steps)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# For Streamline with len 44 (index 4)\n",
    "#print(optimal_steps)\n",
    "optimal_steps = [17, 30, 100, 17, 30, 17, 17, 6, 0, 17, 37, 0, 0, 78, 24, 16, 24, 24, 100, 37, 45, 45, 70, 100, 99, 86, 86, 78, 94, 62, 100, 65, 70, 86, 65, 100, 86, 94, 99, 45, 99, 100, 100]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# with line distance\n",
    "#optimal_steps = [80, 88, 54, 96, 46, 75, 75, 75, 83, 75, 83, 83, 62, 54, 1, 59, 54, 59, 59, 67, 56, 59, 51, 59, 61, 11, 53, 61, 66, 71, 71, 79, 58, 71, 71, 71, 21, 71, 84, 92, 84, 92, 97, 84, 43, 84, 30, 97, 47, 97, 43, 30, 89, 35, 94, 73, 48, 89, 22, 72, 43, 35, 22, 35, 35, 6, 19, 3, 16, 16, 66, 16, 8, 21, 29, 21, 26, 26, 93, 26, 93, 85, 35, 85, 72, 77, 100]\n",
    "optimal_steps = [100, 80, 75, 80, 75, 100, 62, 75, 83, 75, 83, 100, 83, 62, 67, 51, 67, 100, 59, 59, 59, 100, 59, 56, 51, 56, 66, 100, 66, 71, 71, 79, 58, 100, 71, 71, 84, 71, 100, 92, 84, 92, 97, 100, 97, 38, 97, 43, 38, 100, 43, 43, 89, 48, 100, 94, 81, 48, 43, 100, 35, 43, 35, 22, 27, 100, 6, 11, 3, 16, 100, 8, 29, 21, 21, 100, 34, 26, 26, 93, 39, 100, 93, 72, 77, 77, 101]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#optimal_steps = [80, 75, 80, 75, 62, 75, 83, 96, 51, 24, 62, 62, 62, 77, 65, 64, 67, 59, 56, 83, 82, 54, 56, 53, 56, 38, 56, 84, 66, 71, 71, 64, 97, 84, 71, 71, 38, 51, 30, 92, 97, 84, 43, 79, 27, 46, 89, 25, 81, 25, 48, 43, 86, 48, 57, 14, 89, 43, 43, 19, 92, 14, 27, 9, 78, 4, 16, 3, 29, 3, 47, 6, 42, 21, 39, 5, 72, 34, 98, 88, 90, 75, 77, 59, 49, 32, 82]\n",
    "print(optimal_steps) # <-- min of max distance reward streamline 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[80, 75, 80, 75, 62, 75, 83, 96, 51, 24, 62, 62, 62, 77, 65, 64, 67, 59, 56, 83, 82, 54, 56, 53, 56, 38, 56, 84, 66, 71, 71, 64, 97, 84, 71, 71, 38, 51, 30, 92, 97, 84, 43, 79, 27, 46, 89, 25, 81, 25, 48, 43, 86, 48, 57, 14, 89, 43, 43, 19, 92, 14, 27, 9, 78, 4, 16, 3, 29, 3, 47, 6, 42, 21, 39, 5, 72, 34, 98, 88, 90, 75, 77, 59, 49, 32, 82]\n"
     ]
    }
   ],
   "source": [
    "optimal_steps = [80, 75, 80, 75, 62, 75, 83, 96, 51, 24, 62, 62, 62, 77, 65, 64, 67, 59, 56, 83, 82, 54, 56, 53, 56, 38, 56, 84, 66, 71, 71, 64, 97, 84, 71, 71, 38, 51, 30, 92, 97, 84, 43, 79, 27, 46, 89, 25, 81, 25, 48, 43, 86, 48, 57, 14, 89, 43, 43, 19, 92, 14, 27, 9, 78, 4, 16, 3, 29, 3, 47, 6, 42, 21, 39, 5, 72, 34, 98, 88, 90, 75, 77, 59, 49, 32, 82]\n",
    "print(optimal_steps) # <-- min of max distance reward streamline 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[80, 88, 54, 96, 59, 37, 54, 37, 67, 91, 62, 78, 64, 70, 64, 62, 69, 83, 56, 59, 59, 53, 42, 53, 53, 56, 79, 58, 87, 60, 87, 58, 92, 52, 46, 58, 38, 58, 30, 58, 38, 84, 17, 55, 30, 76, 25, 76, 17, 76, 17, 81, 30, 86, 48, 65, 27, 97, 14, 84, 6, 97, 14, 89, 3, 27, 8, 19, 13, 19, 13, 29, 8, 96, 2, 88, 31, 47, 26, 59, 5, 72, 72, 85, 61, 39]\n"
     ]
    }
   ],
   "source": [
    "optimal_steps = [80, 88, 54, 96, 59, 37, 54, 37, 67, 91, 62, 78, 64, 70, 64, 62, 69, 83, 56, 59, 59, 53, 42, 53, 53, 56, 79, 58, 87, 60, 87, 58, 92, 52, 46, 58, 38, 58, 30, 58, 38, 84, 17, 55, 30, 76, 25, 76, 17, 76, 17, 81, 30, 86, 48, 65, 27, 97, 14, 84, 6, 97, 14, 89, 3, 27, 8, 19, 13, 19, 13, 29, 8, 96, 2, 88, 31, 47, 26, 59, 5, 72, 72, 85, 61, 39]\n",
    "print(optimal_steps) # <-- min reward"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "# change optimal steps\n",
    "optimal_steps = [17, 30, 100, 17, 30, 17, 17, 6, 0, 6, 0, 0, 0, 78, 24, 16, 24, 24, 100, 37, 45, 45, 70, 100, 99, 86, 86, 78, 94, 62, 100, 65, 70, 86, 65, 100, 86, 94, 99, 45, 99, 100, 100]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 73.651344 107.88106   93.29415 ] tensor([ 73.6513, 107.8811,  93.2942])\n"
     ]
    },
    {
     "ename": "NameError",
     "evalue": "name 'optimal_steps' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-47-fc460226c6be>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0mlen_line\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0menv\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreferenceStreamline_ijk\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[0mall_states\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstate\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgetCoordinate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 8\u001b[0;31m \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0moptimal_steps\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      9\u001b[0m     \u001b[0mnext_state\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mreward\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mterminal\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0menv\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     10\u001b[0m     \u001b[0;31m#print(step, reward)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'optimal_steps' is not defined"
     ]
    }
   ],
   "source": [
    "state = env.reset()\n",
    "print(env.state.getCoordinate().numpy(), env.referenceStreamline_ijk[0])\n",
    "step = 1\n",
    "all_distances = []\n",
    "all_states = []\n",
    "len_line = len(env.referenceStreamline_ijk)-1\n",
    "all_states.append(state.getCoordinate())\n",
    "for i in optimal_steps:\n",
    "    next_state, reward, terminal = env.step(i)\n",
    "    #print(step, reward)\n",
    "    #current_index = np.min([env.points_visited+1,len(env.referenceStreamline_ijk)-1])\n",
    "    #print(\"Reference Line at current index: \", env.referenceStreamline_ijk[current_index])\n",
    "    #distance = lineseg_dist(next_state.getCoordinate().numpy(), referenceLine[step-1].numpy(), referenceLine[np.min([step, len(referenceLine)-1])].numpy())\n",
    "    #distance = 2 + (distance/10)\n",
    "    #distance = ((next_state.getCoordinate()[0] - env.referenceStreamline_ijk[np.min([env.stepCounter, len_line])][0])**2 \\\n",
    "    #                  + (next_state.getCoordinate()[1] - env.referenceStreamline_ijk[np.min([env.stepCounter, len_line])][1])**2 \\\n",
    "    #                  + (next_state.getCoordinate()[2] - env.referenceStreamline_ijk[np.min([env.stepCounter, len_line])][2])**2)\n",
    "    current_index = np.min([env.stepCounter, len(env.referenceStreamline_ijk)-1])\n",
    "    qry_pt = next_state.getCoordinate().view(-1,3)\n",
    "    distance = torch.sum((env.referenceStreamline_ijk[current_index] - qry_pt)**2)\n",
    "    \n",
    "    print(step, i, next_state.getCoordinate().numpy(), env.referenceStreamline_ijk[np.min([env.stepCounter,len_line])].numpy(), reward, -distance.item())\n",
    "    all_distances.append(distance)\n",
    "    all_states.append(next_state.getCoordinate())\n",
    "    #if distance < 0.71:\n",
    "    #    reward = 1 - distance\n",
    "    #    #print(reward)\n",
    "    #    if reward < 0.3:\n",
    "    #        reward = 1\n",
    "    step += 1\n",
    "\n",
    "print(np.min(all_distances), np.max(all_distances), np.sum(all_distances))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([ 76.4527, 108.1185,  91.8665])\n",
      "tensor(108.1185)\n"
     ]
    }
   ],
   "source": [
    "print(env.referenceStreamline_ijk[4])\n",
    "print(env.referenceStreamline_ijk.T[1][4])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Reset to streamline 3/5\n"
     ]
    }
   ],
   "source": [
    "state = env.reset()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([74.9079, 68.6542,  6.6088]) tensor([74.9079, 68.6542,  6.6088])\n",
      "tensor([75.0515, 68.9644,  7.3432], dtype=torch.float64) tensor([75.0415, 68.9379,  7.3448])\n",
      "tensor([75.1951, 69.2746,  8.0775], dtype=torch.float64) tensor([75.1012, 69.2937,  8.0589])\n",
      "tensor([75.0732, 69.6984,  8.7569], dtype=torch.float64) tensor([75.1610, 69.6495,  8.7729])\n",
      "tensor([75.2168, 70.0086,  9.4913], dtype=torch.float64) tensor([75.2207, 70.0053,  9.4869])\n",
      "tensor([75.3605, 70.3188, 10.2256], dtype=torch.float64) tensor([75.3279, 70.4488, 10.1440])\n",
      "tensor([75.5249, 70.8786, 10.7874], dtype=torch.float64) tensor([75.4352, 70.8923, 10.8012])\n",
      "tensor([75.4030, 71.3025, 11.4668], dtype=torch.float64) tensor([75.4949, 71.2481, 11.5152])\n",
      "tensor([75.5466, 71.6127, 12.2012], dtype=torch.float64) tensor([75.6022, 71.6915, 12.1723])\n",
      "tensor([75.6902, 71.9229, 12.9355], dtype=torch.float64) tensor([75.6619, 72.0473, 12.8864])\n",
      "tensor([75.5988, 72.5737, 13.4090], dtype=torch.float64) tensor([75.6980, 72.5632, 13.4967])\n",
      "tensor([75.7633, 73.1335, 13.9709], dtype=torch.float64) tensor([75.7341, 73.0791, 14.1071])\n",
      "tensor([75.6413, 73.5573, 14.6503], dtype=torch.float64) tensor([75.7701, 73.5950, 14.7175])\n",
      "tensor([75.8058, 74.1171, 15.2121], dtype=torch.float64) tensor([75.8062, 74.1109, 15.3278])\n",
      "tensor([75.6839, 74.5409, 15.8915], dtype=torch.float64) tensor([75.8422, 74.6268, 15.9382])\n",
      "tensor([75.8483, 75.1007, 16.4534], dtype=torch.float64) tensor([75.8783, 75.1427, 16.5486])\n",
      "tensor([75.9920, 75.4109, 17.1877], dtype=torch.float64) tensor([75.9855, 75.5862, 17.2057])\n",
      "tensor([76.1564, 75.9707, 17.7496], dtype=torch.float64) tensor([76.0928, 76.0297, 17.8629])\n",
      "tensor([76.0345, 76.3946, 18.4290], dtype=torch.float64) tensor([76.2000, 76.4732, 18.5200])\n",
      "tensor([76.4324, 76.7621, 19.0312], dtype=torch.float64) tensor([76.4056, 76.9388, 19.1372])\n",
      "tensor([76.5760, 77.0723, 19.7656], dtype=torch.float64) tensor([76.5868, 77.3026, 19.8263])\n",
      "tensor([76.7196, 77.3824, 20.4999], dtype=torch.float64) tensor([76.7203, 77.5862, 20.5623])\n",
      "tensor([76.8633, 77.6926, 21.2343], dtype=torch.float64) tensor([76.8539, 77.8699, 21.2983])\n",
      "tensor([77.0069, 78.0028, 21.9686], dtype=torch.float64) tensor([76.9996, 78.0494, 22.0641])\n",
      "tensor([76.8952, 78.1343, 22.7600], dtype=torch.float64) tensor([77.0545, 78.1756, 22.8522])\n",
      "tensor([77.0638, 78.1613, 23.5518], dtype=torch.float64) tensor([77.1093, 78.3018, 23.6403])\n",
      "tensor([77.2325, 78.1883, 24.3436], dtype=torch.float64) tensor([77.1743, 78.3133, 24.4375])\n",
      "tensor([77.2174, 78.0002, 25.1313], dtype=torch.float64) tensor([77.2496, 77.9811, 25.1614])\n",
      "tensor([77.3647, 77.5814, 25.8088], dtype=torch.float64) tensor([77.3263, 77.4440, 25.7493])\n",
      "tensor([77.3177, 76.9954, 26.3661], dtype=torch.float64) tensor([77.4029, 76.9069, 26.3372])\n",
      "tensor([77.4650, 76.5766, 27.0435], dtype=torch.float64) tensor([77.2996, 76.5694, 27.0552])\n",
      "tensor([77.1535, 76.4929, 27.7865], dtype=torch.float64) tensor([77.1912, 76.3470, 27.8160])\n",
      "tensor([77.1384, 76.3048, 28.5742], dtype=torch.float64) tensor([77.1715, 76.1842, 28.5990])\n",
      "tensor([77.2857, 75.8860, 29.2517], dtype=torch.float64) tensor([77.2455, 75.9670, 29.3653])\n",
      "tensor([77.4544, 75.9130, 30.0435], dtype=torch.float64) tensor([77.4148, 75.8119, 30.1317])\n",
      "tensor([77.4393, 75.7248, 30.8312], dtype=torch.float64) tensor([77.5840, 75.6568, 30.8980])\n",
      "tensor([77.7739, 75.5189, 31.5395], dtype=torch.float64) tensor([77.6571, 75.5543, 31.6881])\n",
      "tensor([77.9426, 75.5459, 32.3313], dtype=torch.float64) tensor([77.8233, 75.5124, 32.4695])\n",
      "tensor([77.9275, 75.3577, 33.1190], dtype=torch.float64) tensor([77.9895, 75.4705, 33.2509])\n",
      "tensor([78.0961, 75.3848, 33.9108], dtype=torch.float64) tensor([78.1556, 75.4286, 34.0324])\n",
      "tensor([78.2648, 75.4118, 34.7026], dtype=torch.float64) tensor([78.3218, 75.3867, 34.8138])\n",
      "tensor([78.4335, 75.4388, 35.4944], dtype=torch.float64) tensor([78.4792, 75.4569, 35.5950])\n",
      "tensor([78.5771, 75.7490, 36.2287], dtype=torch.float64) tensor([78.6250, 75.6365, 36.3608])\n",
      "tensor([78.7458, 75.7760, 37.0205], dtype=torch.float64) tensor([78.7585, 75.9202, 37.0968])\n",
      "tensor([78.8894, 76.0862, 37.7548], dtype=torch.float64) tensor([78.8921, 76.2038, 37.8328])\n",
      "tensor([79.0330, 76.3964, 38.4892], dtype=torch.float64) tensor([79.0733, 76.5676, 38.5219])\n",
      "tensor([79.1975, 76.9562, 39.0510], dtype=torch.float64) tensor([79.2544, 76.9314, 39.2110])\n",
      "tensor([79.3411, 77.2664, 39.7853], dtype=torch.float64) tensor([79.4356, 77.2952, 39.9001])\n",
      "tensor([79.4847, 77.5766, 40.5197], dtype=torch.float64) tensor([79.4953, 77.6510, 40.6141])\n",
      "tensor([79.6283, 77.8868, 41.2540], dtype=torch.float64) tensor([79.6289, 77.9347, 41.3501])\n",
      "tensor([79.7720, 78.1970, 41.9883], dtype=torch.float64) tensor([79.7625, 78.2183, 42.0861])\n",
      "tensor([79.9156, 78.5072, 42.7227], dtype=torch.float64) tensor([79.8960, 78.5020, 42.8221])\n",
      "tensor([79.8039, 78.6387, 43.5141], dtype=torch.float64) tensor([79.9359, 78.7429, 43.5840])\n",
      "tensor([79.9475, 78.9489, 44.2484], dtype=torch.float64) tensor([79.9758, 78.9837, 44.3458])\n",
      "tensor([80.0911, 79.2591, 44.9828], dtype=torch.float64) tensor([80.0356, 79.3395, 45.0598])\n",
      "tensor([80.2348, 79.5693, 45.7171], dtype=torch.float64) tensor([80.2167, 79.7033, 45.7489])\n",
      "tensor([80.3992, 80.1291, 46.2789], dtype=torch.float64) tensor([80.3979, 80.0671, 46.4380])\n",
      "tensor([80.5428, 80.4393, 47.0133], dtype=torch.float64) tensor([80.5791, 80.4309, 47.1270])\n",
      "tensor([80.6865, 80.7495, 47.7476], dtype=torch.float64) tensor([80.7602, 80.7947, 47.8161])\n",
      "tensor([80.8509, 81.3093, 48.3095], dtype=torch.float64) tensor([80.9658, 81.2604, 48.4333])\n",
      "tensor([81.2488, 81.6767, 48.9117], dtype=torch.float64) tensor([81.2837, 81.7186, 49.0069])\n",
      "tensor([81.6467, 82.0442, 49.5140], dtype=torch.float64) tensor([81.6016, 82.1768, 49.5804])\n",
      "tensor([82.0446, 82.4117, 50.1163], dtype=torch.float64) tensor([82.0211, 82.6052, 50.1101])\n",
      "tensor([82.4410, 83.0113, 50.4898], dtype=torch.float64) tensor([82.4406, 83.0337, 50.6397])\n",
      "tensor([82.8389, 83.3787, 51.0920], dtype=torch.float64) tensor([82.9928, 83.3187, 51.1434])\n",
      "tensor([83.4771, 83.4912, 51.5781], dtype=torch.float64) tensor([83.6211, 83.5545, 51.5789])\n",
      "tensor([84.0760, 83.8648, 51.9754], dtype=torch.float64) tensor([84.2494, 83.7903, 52.0145])\n",
      "tensor([84.8286, 83.8004, 52.2678], dtype=torch.float64) tensor([84.9416, 83.9694, 52.3732])\n",
      "tensor([85.4275, 84.1740, 52.6651], dtype=torch.float64) tensor([85.6339, 84.1485, 52.7320])\n",
      "tensor([86.0656, 84.2864, 53.1511], dtype=torch.float64) tensor([86.3261, 84.3276, 53.0908])\n",
      "tensor([86.8253, 84.4987, 53.3351], dtype=torch.float64) tensor([87.0183, 84.5068, 53.4496])\n",
      "tensor([87.4635, 84.6111, 53.8212], dtype=torch.float64) tensor([87.6663, 84.6348, 53.9010])\n",
      "tensor([88.2161, 84.5467, 54.1136], dtype=torch.float64) tensor([88.3712, 84.7040, 54.2728])\n",
      "tensor([88.9758, 84.7590, 54.2976], dtype=torch.float64) tensor([89.1131, 84.8213, 54.5483])\n",
      "tensor([89.6139, 84.8715, 54.7837], dtype=torch.float64) tensor([89.8181, 84.8904, 54.9201])\n",
      "tensor([90.1933, 84.6947, 55.3214], dtype=torch.float64) tensor([90.3453, 84.6596, 55.4757])\n",
      "tensor([90.7727, 84.5180, 55.8592], dtype=torch.float64) tensor([90.8480, 84.3259, 56.0010])\n",
      "tensor([91.1989, 84.0752, 56.3869], dtype=torch.float64) tensor([91.2836, 83.8824, 56.5045])\n",
      "tensor([91.6251, 83.6325, 56.9146], dtype=torch.float64) tensor([91.6366, 83.3615, 56.9986])\n",
      "tensor([91.8480, 82.9906, 57.3554], dtype=torch.float64) tensor([91.9971, 82.7743, 57.4050])\n",
      "tensor([92.0709, 82.3487, 57.7963], dtype=torch.float64) tensor([92.2664, 82.1258, 57.7883])\n",
      "tensor([92.5305, 81.7367, 58.0616], dtype=torch.float64) tensor([92.6291, 81.4843, 58.0996])\n",
      "tensor([92.9901, 81.1248, 58.3270], dtype=torch.float64) tensor([92.9918, 80.8427, 58.4109])\n",
      "tensor([93.1874, 80.3549, 58.4830], dtype=torch.float64) tensor([93.3526, 80.1598, 58.6193])\n",
      "tensor([93.6470, 79.7429, 58.7484], dtype=torch.float64) tensor([93.7133, 79.4768, 58.8277])\n",
      "tensor([93.8444, 78.9730, 58.9045], dtype=torch.float64) tensor([94.0740, 78.7938, 59.0361])\n",
      "tensor([94.3039, 78.3610, 59.1698], dtype=torch.float64) tensor([94.3412, 78.0615, 59.2157])\n",
      "tensor([94.5013, 77.5911, 59.3259], dtype=torch.float64) tensor([94.6084, 77.3291, 59.3953])\n",
      "tensor([94.6987, 76.8212, 59.4820], dtype=torch.float64) tensor([94.8756, 76.5968, 59.5749])\n",
      "tensor([94.8960, 76.0513, 59.6380], dtype=torch.float64) tensor([95.1428, 75.8644, 59.7545])\n",
      "tensor([95.3556, 75.4393, 59.9034], dtype=torch.float64) tensor([95.4100, 75.1321, 59.9341])\n",
      "tensor([95.5530, 74.6694, 60.0595], dtype=torch.float64) tensor([95.5819, 74.3928, 60.1869])\n",
      "tensor([95.7759, 74.0275, 60.5003], dtype=torch.float64) tensor([95.8519, 73.6955, 60.4714])\n",
      "tensor([95.9732, 73.2575, 60.6564], dtype=torch.float64) tensor([96.0245, 72.9989, 60.8249])\n",
      "tensor([96.1962, 72.6156, 61.0972], dtype=torch.float64) tensor([96.2938, 72.3504, 61.2082])\n",
      "tensor([96.4191, 71.9737, 61.5381], dtype=torch.float64) tensor([96.4664, 71.6538, 61.5617])\n",
      "tensor([96.3701, 71.2289, 61.8528], dtype=torch.float64) tensor([96.5391, 70.9719, 61.9737])\n",
      "tensor([96.5931, 70.5870, 62.2936], dtype=torch.float64) tensor([96.7118, 70.2753, 62.3272])\n",
      "tensor([96.8160, 69.9451, 62.7344], dtype=torch.float64) tensor([96.7844, 69.5935, 62.7392])\n",
      "tensor([96.7671, 69.2003, 63.0491], dtype=torch.float64) tensor([96.8571, 68.9116, 63.1513])\n",
      "tensor([96.7181, 68.4555, 63.3638], dtype=torch.float64) tensor([96.8297, 68.2003, 63.5164])\n",
      "tensor([96.6692, 67.7108, 63.6785], dtype=torch.float64) tensor([96.7041, 67.5243, 63.9253])\n",
      "tensor([96.6223, 67.1249, 64.2358], dtype=torch.float64) tensor([96.5785, 66.8482, 64.3342])\n",
      "tensor([96.5734, 66.3801, 64.5505], dtype=torch.float64) tensor([96.4529, 66.1722, 64.7431])\n",
      "tensor([96.2485, 65.8134, 65.0295], dtype=torch.float64) tensor([96.2314, 65.5445, 65.1868])\n",
      "tensor([95.9237, 65.2467, 65.5085], dtype=torch.float64) tensor([96.0099, 64.9168, 65.6306])\n",
      "tensor([95.8748, 64.5019, 65.8231], dtype=torch.float64) tensor([95.7884, 64.2891, 66.0744])\n",
      "tensor([95.5499, 63.9352, 66.3021], dtype=torch.float64) tensor([95.4713, 63.6600, 66.4535])\n",
      "tensor([95.2251, 63.3685, 66.7811], dtype=torch.float64) tensor([95.1541, 63.0310, 66.8325])\n",
      "tensor([94.9016, 62.6597, 67.0027], dtype=torch.float64) tensor([94.8370, 62.4019, 67.2116])\n",
      "tensor([94.5768, 62.0930, 67.4816], dtype=torch.float64) tensor([94.5198, 61.7728, 67.5907])\n",
      "tensor([94.2532, 61.3842, 67.7032], dtype=torch.float64) tensor([94.2052, 61.0929, 67.8713])\n",
      "tensor([93.9297, 60.6755, 67.9248], dtype=torch.float64) tensor([93.8905, 60.4131, 68.1519])\n",
      "tensor([93.8808, 59.9307, 68.2394], dtype=torch.float64) tensor([93.6701, 59.6838, 68.3959])\n",
      "tensor([93.5573, 59.2219, 68.4610], dtype=torch.float64) tensor([93.4497, 58.9545, 68.6400])\n",
      "tensor([93.5084, 58.4772, 68.7757], dtype=torch.float64) tensor([93.3240, 58.1902, 68.8402])\n",
      "tensor([93.1849, 57.7684, 68.9973], dtype=torch.float64) tensor([93.1983, 57.4259, 69.0405])\n",
      "tensor([93.1360, 57.0236, 69.3119], dtype=torch.float64) tensor([93.0726, 56.6617, 69.2408])\n",
      "tensor([93.0243, 56.2217, 69.3346], dtype=torch.float64) tensor([92.9469, 55.8974, 69.4410])\n",
      "tensor([92.9126, 55.4197, 69.3572], dtype=torch.float64) tensor([92.8257, 55.1111, 69.5248])\n",
      "tensor([92.8009, 54.6178, 69.3799], dtype=torch.float64) tensor([92.8001, 54.3123, 69.5607])\n",
      "tensor([92.6892, 53.8158, 69.4025], dtype=torch.float64) tensor([92.6942, 53.5203, 69.5218])\n",
      "tensor([92.5775, 53.0139, 69.4252], dtype=torch.float64) tensor([92.5883, 52.7283, 69.4829])\n",
      "tensor([92.4658, 52.2120, 69.4479], dtype=torch.float64) tensor([92.4042, 51.9580, 69.3699])\n",
      "tensor([92.3312, 51.4698, 69.1525], dtype=torch.float64) tensor([92.2202, 51.1877, 69.2568])\n",
      "tensor([91.9594, 50.7573, 69.0518], dtype=torch.float64) tensor([91.9415, 50.4407, 69.1914])\n",
      "tensor([91.6359, 50.0485, 69.2734], dtype=torch.float64) tensor([91.5722, 49.7312, 69.1735])\n",
      "tensor([91.2641, 49.3360, 69.1726], dtype=torch.float64) tensor([91.1155, 49.0750, 69.1997])\n",
      "tensor([90.7106, 48.7541, 69.2781], dtype=torch.float64) tensor([90.5707, 48.4919, 69.2567])\n",
      "tensor([90.1571, 48.1722, 69.3836], dtype=torch.float64) tensor([90.0131, 47.9396, 69.4118])\n",
      "tensor([89.6036, 47.5903, 69.4891], dtype=torch.float64) tensor([89.4481, 47.4342, 69.6674])\n",
      "tensor([89.0415, 47.1288, 69.8457], dtype=torch.float64) tensor([88.9573, 46.8970, 69.9998])\n",
      "tensor([88.7166, 46.5621, 70.3247], dtype=torch.float64) tensor([88.4665, 46.3597, 70.3321])\n",
      "tensor([88.1631, 45.9802, 70.4302], dtype=torch.float64) tensor([88.0605, 45.7443, 70.6426])\n",
      "tensor([87.8396, 45.2714, 70.6518], dtype=torch.float64) tensor([87.6618, 45.0829, 70.8515])\n",
      "tensor([87.5161, 44.5627, 70.8733], dtype=torch.float64) tensor([87.3471, 44.4030, 71.1321])\n",
      "tensor([87.1913, 43.9960, 71.3523], dtype=torch.float64) tensor([87.0324, 43.7231, 71.4127])\n",
      "tensor([86.8678, 43.2872, 71.5739], dtype=torch.float64) tensor([86.7178, 43.0432, 71.6933])\n",
      "tensor([86.5443, 42.5784, 71.7954], dtype=torch.float64) tensor([86.3117, 42.4278, 72.0037])\n",
      "tensor([85.9822, 42.1170, 72.1521], dtype=torch.float64) tensor([85.8209, 41.8906, 72.3361])\n",
      "tensor([85.6573, 41.5502, 72.6311], dtype=torch.float64) tensor([85.4140, 41.3331, 72.7405])\n",
      "tensor([85.0952, 41.0888, 72.9877], dtype=torch.float64) tensor([85.0108, 40.8447, 73.2294])\n",
      "tensor([84.7704, 40.5221, 73.4667], dtype=torch.float64) tensor([84.7028, 40.3502, 73.7777])\n",
      "tensor([84.5618, 40.1495, 74.1550], dtype=torch.float64) tensor([84.3949, 39.8558, 74.3260])\n",
      "tensor([84.2369, 39.5828, 74.6339], dtype=torch.float64) tensor([84.2807, 39.3211, 74.9101])\n",
      "tensor([84.1900, 38.9969, 75.1913], dtype=torch.float64) tensor([84.0753, 38.8421, 75.5170])\n",
      "tensor([83.9814, 38.6243, 75.8796], dtype=torch.float64) tensor([83.8699, 38.3631, 76.1239])\n",
      "tensor([83.6566, 38.0576, 76.3585], dtype=torch.float64) tensor([83.6645, 37.8840, 76.7308])\n",
      "tensor([83.4479, 37.6850, 77.0468], dtype=torch.float64) tensor([83.4590, 37.4050, 77.3377])\n",
      "tensor([83.4010, 37.0990, 77.6042], dtype=torch.float64) tensor([83.2536, 36.9260, 77.9446])\n",
      "tensor([82.9231, 36.8100, 78.1908], dtype=torch.float64) tensor([82.8617, 36.5164, 78.5091])\n",
      "tensor([82.7144, 36.4375, 78.8791], dtype=torch.float64) tensor([82.5670, 36.1024, 79.1270])\n",
      "tensor([82.5058, 36.0649, 79.5674], dtype=torch.float64) tensor([82.3763, 35.7140, 79.7998])\n",
      "tensor([82.1810, 35.4982, 80.0464], dtype=torch.float64)\n",
      "tensor([82.5058, 36.0649, 79.5674], dtype=torch.float64)\n",
      "tensor([82.1810, 35.4982, 80.0464], dtype=torch.float64)\n",
      "tensor([82.5058, 36.0649, 79.5674], dtype=torch.float64)\n",
      "tensor([82.1810, 35.4982, 80.0464], dtype=torch.float64)\n",
      "tensor([82.5058, 36.0649, 79.5674], dtype=torch.float64)\n",
      "tensor([82.1810, 35.4982, 80.0464], dtype=torch.float64)\n",
      "tensor([82.5058, 36.0649, 79.5674], dtype=torch.float64)\n",
      "tensor([82.1810, 35.4982, 80.0464], dtype=torch.float64)\n",
      "tensor([82.5058, 36.0649, 79.5674], dtype=torch.float64)\n",
      "tensor([82.1810, 35.4982, 80.0464], dtype=torch.float64)\n",
      "tensor([82.5058, 36.0649, 79.5674], dtype=torch.float64)\n",
      "tensor([82.1810, 35.4982, 80.0464], dtype=torch.float64)\n",
      "tensor([82.5058, 36.0649, 79.5674], dtype=torch.float64)\n",
      "tensor([82.1810, 35.4982, 80.0464], dtype=torch.float64)\n",
      "tensor([82.5058, 36.0649, 79.5674], dtype=torch.float64)\n",
      "tensor([82.1810, 35.4982, 80.0464], dtype=torch.float64)\n",
      "tensor([82.5058, 36.0649, 79.5674], dtype=torch.float64)\n",
      "tensor([82.1810, 35.4982, 80.0464], dtype=torch.float64)\n",
      "tensor([82.5058, 36.0649, 79.5674], dtype=torch.float64)\n",
      "tensor([82.1810, 35.4982, 80.0464], dtype=torch.float64)\n",
      "tensor([82.5058, 36.0649, 79.5674], dtype=torch.float64)\n",
      "tensor([82.1810, 35.4982, 80.0464], dtype=torch.float64)\n",
      "tensor([82.5058, 36.0649, 79.5674], dtype=torch.float64)\n",
      "tensor([82.1810, 35.4982, 80.0464], dtype=torch.float64)\n",
      "tensor([82.5058, 36.0649, 79.5674], dtype=torch.float64)\n",
      "tensor([82.1810, 35.4982, 80.0464], dtype=torch.float64)\n",
      "tensor([82.5058, 36.0649, 79.5674], dtype=torch.float64)\n",
      "tensor([82.1810, 35.4982, 80.0464], dtype=torch.float64)\n",
      "tensor([82.5058, 36.0649, 79.5674], dtype=torch.float64)\n",
      "tensor([82.1810, 35.4982, 80.0464], dtype=torch.float64)\n",
      "tensor([82.5058, 36.0649, 79.5674], dtype=torch.float64)\n",
      "tensor([82.1810, 35.4982, 80.0464], dtype=torch.float64)\n",
      "tensor([82.5058, 36.0649, 79.5674], dtype=torch.float64)\n",
      "tensor([82.1810, 35.4982, 80.0464], dtype=torch.float64)\n",
      "tensor([82.5058, 36.0649, 79.5674], dtype=torch.float64)\n",
      "tensor([82.1810, 35.4982, 80.0464], dtype=torch.float64)\n",
      "tensor([82.5058, 36.0649, 79.5674], dtype=torch.float64)\n",
      "tensor([82.1810, 35.4982, 80.0464], dtype=torch.float64)\n",
      "tensor([82.5058, 36.0649, 79.5674], dtype=torch.float64)\n",
      "tensor([82.1810, 35.4982, 80.0464], dtype=torch.float64)\n",
      "tensor([82.5058, 36.0649, 79.5674], dtype=torch.float64)\n",
      "tensor([82.1810, 35.4982, 80.0464], dtype=torch.float64)\n",
      "tensor([82.5058, 36.0649, 79.5674], dtype=torch.float64)\n",
      "tensor([82.1810, 35.4982, 80.0464], dtype=torch.float64)\n",
      "tensor([82.5058, 36.0649, 79.5674], dtype=torch.float64)\n",
      "tensor([82.1810, 35.4982, 80.0464], dtype=torch.float64)\n",
      "tensor([82.5058, 36.0649, 79.5674], dtype=torch.float64)\n",
      "tensor([82.1810, 35.4982, 80.0464], dtype=torch.float64)\n",
      "tensor([82.5058, 36.0649, 79.5674], dtype=torch.float64)\n",
      "tensor([82.1810, 35.4982, 80.0464], dtype=torch.float64)\n",
      "tensor([82.5058, 36.0649, 79.5674], dtype=torch.float64)\n",
      "tensor([82.1810, 35.4982, 80.0464], dtype=torch.float64)\n",
      "tensor([82.5058, 36.0649, 79.5674], dtype=torch.float64)\n",
      "tensor([82.1810, 35.4982, 80.0464], dtype=torch.float64)\n",
      "tensor([82.5058, 36.0649, 79.5674], dtype=torch.float64)\n",
      "tensor([82.1810, 35.4982, 80.0464], dtype=torch.float64)\n",
      "tensor([82.5058, 36.0649, 79.5674], dtype=torch.float64)\n",
      "tensor([82.1810, 35.4982, 80.0464], dtype=torch.float64)\n",
      "tensor([82.5058, 36.0649, 79.5674], dtype=torch.float64)\n",
      "tensor([82.1810, 35.4982, 80.0464], dtype=torch.float64)\n",
      "tensor([82.5058, 36.0649, 79.5674], dtype=torch.float64)\n",
      "tensor([82.1810, 35.4982, 80.0464], dtype=torch.float64)\n",
      "tensor([82.5058, 36.0649, 79.5674], dtype=torch.float64)\n",
      "tensor([82.1810, 35.4982, 80.0464], dtype=torch.float64)\n",
      "tensor([82.5058, 36.0649, 79.5674], dtype=torch.float64)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([82.1810, 35.4982, 80.0464], dtype=torch.float64)\n",
      "tensor([82.5058, 36.0649, 79.5674], dtype=torch.float64)\n",
      "tensor([82.1810, 35.4982, 80.0464], dtype=torch.float64)\n",
      "tensor([82.5058, 36.0649, 79.5674], dtype=torch.float64)\n",
      "tensor([82.1810, 35.4982, 80.0464], dtype=torch.float64)\n",
      "tensor([82.5058, 36.0649, 79.5674], dtype=torch.float64)\n",
      "tensor([82.1810, 35.4982, 80.0464], dtype=torch.float64)\n",
      "tensor([82.5058, 36.0649, 79.5674], dtype=torch.float64)\n",
      "tensor([82.1810, 35.4982, 80.0464], dtype=torch.float64)\n",
      "tensor([82.5058, 36.0649, 79.5674], dtype=torch.float64)\n",
      "tensor([82.1810, 35.4982, 80.0464], dtype=torch.float64)\n",
      "tensor([82.5058, 36.0649, 79.5674], dtype=torch.float64)\n",
      "tensor([82.1810, 35.4982, 80.0464], dtype=torch.float64)\n",
      "tensor([82.5058, 36.0649, 79.5674], dtype=torch.float64)\n",
      "tensor([82.1810, 35.4982, 80.0464], dtype=torch.float64)\n",
      "tensor([82.5058, 36.0649, 79.5674], dtype=torch.float64)\n",
      "tensor([82.1810, 35.4982, 80.0464], dtype=torch.float64)\n",
      "tensor([82.5058, 36.0649, 79.5674], dtype=torch.float64)\n",
      "tensor([82.1810, 35.4982, 80.0464], dtype=torch.float64)\n",
      "tensor([82.5058, 36.0649, 79.5674], dtype=torch.float64)\n",
      "tensor([82.1810, 35.4982, 80.0464], dtype=torch.float64)\n",
      "tensor([82.5058, 36.0649, 79.5674], dtype=torch.float64)\n",
      "tensor([82.1810, 35.4982, 80.0464], dtype=torch.float64)\n",
      "tensor([82.5058, 36.0649, 79.5674], dtype=torch.float64)\n",
      "tensor([82.1810, 35.4982, 80.0464], dtype=torch.float64)\n",
      "tensor([82.5058, 36.0649, 79.5674], dtype=torch.float64)\n",
      "tensor([82.1810, 35.4982, 80.0464], dtype=torch.float64)\n"
     ]
    }
   ],
   "source": [
    "for i, x in enumerate(all_states):\n",
    "    try:\n",
    "        print(x, env.referenceStreamline_ijk[i])\n",
    "    except IndexError:\n",
    "        print(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/javascript": [
       "/* Put everything inside the global mpl namespace */\n",
       "window.mpl = {};\n",
       "\n",
       "\n",
       "mpl.get_websocket_type = function() {\n",
       "    if (typeof(WebSocket) !== 'undefined') {\n",
       "        return WebSocket;\n",
       "    } else if (typeof(MozWebSocket) !== 'undefined') {\n",
       "        return MozWebSocket;\n",
       "    } else {\n",
       "        alert('Your browser does not have WebSocket support. ' +\n",
       "              'Please try Chrome, Safari or Firefox  6. ' +\n",
       "              'Firefox 4 and 5 are also supported but you ' +\n",
       "              'have to enable WebSockets in about:config.');\n",
       "    };\n",
       "}\n",
       "\n",
       "mpl.figure = function(figure_id, websocket, ondownload, parent_element) {\n",
       "    this.id = figure_id;\n",
       "\n",
       "    this.ws = websocket;\n",
       "\n",
       "    this.supports_binary = (this.ws.binaryType != undefined);\n",
       "\n",
       "    if (!this.supports_binary) {\n",
       "        var warnings = document.getElementById(\"mpl-warnings\");\n",
       "        if (warnings) {\n",
       "            warnings.style.display = 'block';\n",
       "            warnings.textContent = (\n",
       "                \"This browser does not support binary websocket messages. \" +\n",
       "                    \"Performance may be slow.\");\n",
       "        }\n",
       "    }\n",
       "\n",
       "    this.imageObj = new Image();\n",
       "\n",
       "    this.context = undefined;\n",
       "    this.message = undefined;\n",
       "    this.canvas = undefined;\n",
       "    this.rubberband_canvas = undefined;\n",
       "    this.rubberband_context = undefined;\n",
       "    this.format_dropdown = undefined;\n",
       "\n",
       "    this.image_mode = 'full';\n",
       "\n",
       "    this.root = $('<div/>');\n",
       "    this._root_extra_style(this.root)\n",
       "    this.root.attr('style', 'display: inline-block');\n",
       "\n",
       "    $(parent_element).append(this.root);\n",
       "\n",
       "    this._init_header(this);\n",
       "    this._init_canvas(this);\n",
       "    this._init_toolbar(this);\n",
       "\n",
       "    var fig = this;\n",
       "\n",
       "    this.waiting = false;\n",
       "\n",
       "    this.ws.onopen =  function () {\n",
       "            fig.send_message(\"supports_binary\", {value: fig.supports_binary});\n",
       "            fig.send_message(\"send_image_mode\", {});\n",
       "            if (mpl.ratio != 1) {\n",
       "                fig.send_message(\"set_dpi_ratio\", {'dpi_ratio': mpl.ratio});\n",
       "            }\n",
       "            fig.send_message(\"refresh\", {});\n",
       "        }\n",
       "\n",
       "    this.imageObj.onload = function() {\n",
       "            if (fig.image_mode == 'full') {\n",
       "                // Full images could contain transparency (where diff images\n",
       "                // almost always do), so we need to clear the canvas so that\n",
       "                // there is no ghosting.\n",
       "                fig.context.clearRect(0, 0, fig.canvas.width, fig.canvas.height);\n",
       "            }\n",
       "            fig.context.drawImage(fig.imageObj, 0, 0);\n",
       "        };\n",
       "\n",
       "    this.imageObj.onunload = function() {\n",
       "        fig.ws.close();\n",
       "    }\n",
       "\n",
       "    this.ws.onmessage = this._make_on_message_function(this);\n",
       "\n",
       "    this.ondownload = ondownload;\n",
       "}\n",
       "\n",
       "mpl.figure.prototype._init_header = function() {\n",
       "    var titlebar = $(\n",
       "        '<div class=\"ui-dialog-titlebar ui-widget-header ui-corner-all ' +\n",
       "        'ui-helper-clearfix\"/>');\n",
       "    var titletext = $(\n",
       "        '<div class=\"ui-dialog-title\" style=\"width: 100%; ' +\n",
       "        'text-align: center; padding: 3px;\"/>');\n",
       "    titlebar.append(titletext)\n",
       "    this.root.append(titlebar);\n",
       "    this.header = titletext[0];\n",
       "}\n",
       "\n",
       "\n",
       "\n",
       "mpl.figure.prototype._canvas_extra_style = function(canvas_div) {\n",
       "\n",
       "}\n",
       "\n",
       "\n",
       "mpl.figure.prototype._root_extra_style = function(canvas_div) {\n",
       "\n",
       "}\n",
       "\n",
       "mpl.figure.prototype._init_canvas = function() {\n",
       "    var fig = this;\n",
       "\n",
       "    var canvas_div = $('<div/>');\n",
       "\n",
       "    canvas_div.attr('style', 'position: relative; clear: both; outline: 0');\n",
       "\n",
       "    function canvas_keyboard_event(event) {\n",
       "        return fig.key_event(event, event['data']);\n",
       "    }\n",
       "\n",
       "    canvas_div.keydown('key_press', canvas_keyboard_event);\n",
       "    canvas_div.keyup('key_release', canvas_keyboard_event);\n",
       "    this.canvas_div = canvas_div\n",
       "    this._canvas_extra_style(canvas_div)\n",
       "    this.root.append(canvas_div);\n",
       "\n",
       "    var canvas = $('<canvas/>');\n",
       "    canvas.addClass('mpl-canvas');\n",
       "    canvas.attr('style', \"left: 0; top: 0; z-index: 0; outline: 0\")\n",
       "\n",
       "    this.canvas = canvas[0];\n",
       "    this.context = canvas[0].getContext(\"2d\");\n",
       "\n",
       "    var backingStore = this.context.backingStorePixelRatio ||\n",
       "\tthis.context.webkitBackingStorePixelRatio ||\n",
       "\tthis.context.mozBackingStorePixelRatio ||\n",
       "\tthis.context.msBackingStorePixelRatio ||\n",
       "\tthis.context.oBackingStorePixelRatio ||\n",
       "\tthis.context.backingStorePixelRatio || 1;\n",
       "\n",
       "    mpl.ratio = (window.devicePixelRatio || 1) / backingStore;\n",
       "\n",
       "    var rubberband = $('<canvas/>');\n",
       "    rubberband.attr('style', \"position: absolute; left: 0; top: 0; z-index: 1;\")\n",
       "\n",
       "    var pass_mouse_events = true;\n",
       "\n",
       "    canvas_div.resizable({\n",
       "        start: function(event, ui) {\n",
       "            pass_mouse_events = false;\n",
       "        },\n",
       "        resize: function(event, ui) {\n",
       "            fig.request_resize(ui.size.width, ui.size.height);\n",
       "        },\n",
       "        stop: function(event, ui) {\n",
       "            pass_mouse_events = true;\n",
       "            fig.request_resize(ui.size.width, ui.size.height);\n",
       "        },\n",
       "    });\n",
       "\n",
       "    function mouse_event_fn(event) {\n",
       "        if (pass_mouse_events)\n",
       "            return fig.mouse_event(event, event['data']);\n",
       "    }\n",
       "\n",
       "    rubberband.mousedown('button_press', mouse_event_fn);\n",
       "    rubberband.mouseup('button_release', mouse_event_fn);\n",
       "    // Throttle sequential mouse events to 1 every 20ms.\n",
       "    rubberband.mousemove('motion_notify', mouse_event_fn);\n",
       "\n",
       "    rubberband.mouseenter('figure_enter', mouse_event_fn);\n",
       "    rubberband.mouseleave('figure_leave', mouse_event_fn);\n",
       "\n",
       "    canvas_div.on(\"wheel\", function (event) {\n",
       "        event = event.originalEvent;\n",
       "        event['data'] = 'scroll'\n",
       "        if (event.deltaY < 0) {\n",
       "            event.step = 1;\n",
       "        } else {\n",
       "            event.step = -1;\n",
       "        }\n",
       "        mouse_event_fn(event);\n",
       "    });\n",
       "\n",
       "    canvas_div.append(canvas);\n",
       "    canvas_div.append(rubberband);\n",
       "\n",
       "    this.rubberband = rubberband;\n",
       "    this.rubberband_canvas = rubberband[0];\n",
       "    this.rubberband_context = rubberband[0].getContext(\"2d\");\n",
       "    this.rubberband_context.strokeStyle = \"#000000\";\n",
       "\n",
       "    this._resize_canvas = function(width, height) {\n",
       "        // Keep the size of the canvas, canvas container, and rubber band\n",
       "        // canvas in synch.\n",
       "        canvas_div.css('width', width)\n",
       "        canvas_div.css('height', height)\n",
       "\n",
       "        canvas.attr('width', width * mpl.ratio);\n",
       "        canvas.attr('height', height * mpl.ratio);\n",
       "        canvas.attr('style', 'width: ' + width + 'px; height: ' + height + 'px;');\n",
       "\n",
       "        rubberband.attr('width', width);\n",
       "        rubberband.attr('height', height);\n",
       "    }\n",
       "\n",
       "    // Set the figure to an initial 600x600px, this will subsequently be updated\n",
       "    // upon first draw.\n",
       "    this._resize_canvas(600, 600);\n",
       "\n",
       "    // Disable right mouse context menu.\n",
       "    $(this.rubberband_canvas).bind(\"contextmenu\",function(e){\n",
       "        return false;\n",
       "    });\n",
       "\n",
       "    function set_focus () {\n",
       "        canvas.focus();\n",
       "        canvas_div.focus();\n",
       "    }\n",
       "\n",
       "    window.setTimeout(set_focus, 100);\n",
       "}\n",
       "\n",
       "mpl.figure.prototype._init_toolbar = function() {\n",
       "    var fig = this;\n",
       "\n",
       "    var nav_element = $('<div/>');\n",
       "    nav_element.attr('style', 'width: 100%');\n",
       "    this.root.append(nav_element);\n",
       "\n",
       "    // Define a callback function for later on.\n",
       "    function toolbar_event(event) {\n",
       "        return fig.toolbar_button_onclick(event['data']);\n",
       "    }\n",
       "    function toolbar_mouse_event(event) {\n",
       "        return fig.toolbar_button_onmouseover(event['data']);\n",
       "    }\n",
       "\n",
       "    for(var toolbar_ind in mpl.toolbar_items) {\n",
       "        var name = mpl.toolbar_items[toolbar_ind][0];\n",
       "        var tooltip = mpl.toolbar_items[toolbar_ind][1];\n",
       "        var image = mpl.toolbar_items[toolbar_ind][2];\n",
       "        var method_name = mpl.toolbar_items[toolbar_ind][3];\n",
       "\n",
       "        if (!name) {\n",
       "            // put a spacer in here.\n",
       "            continue;\n",
       "        }\n",
       "        var button = $('<button/>');\n",
       "        button.addClass('ui-button ui-widget ui-state-default ui-corner-all ' +\n",
       "                        'ui-button-icon-only');\n",
       "        button.attr('role', 'button');\n",
       "        button.attr('aria-disabled', 'false');\n",
       "        button.click(method_name, toolbar_event);\n",
       "        button.mouseover(tooltip, toolbar_mouse_event);\n",
       "\n",
       "        var icon_img = $('<span/>');\n",
       "        icon_img.addClass('ui-button-icon-primary ui-icon');\n",
       "        icon_img.addClass(image);\n",
       "        icon_img.addClass('ui-corner-all');\n",
       "\n",
       "        var tooltip_span = $('<span/>');\n",
       "        tooltip_span.addClass('ui-button-text');\n",
       "        tooltip_span.html(tooltip);\n",
       "\n",
       "        button.append(icon_img);\n",
       "        button.append(tooltip_span);\n",
       "\n",
       "        nav_element.append(button);\n",
       "    }\n",
       "\n",
       "    var fmt_picker_span = $('<span/>');\n",
       "\n",
       "    var fmt_picker = $('<select/>');\n",
       "    fmt_picker.addClass('mpl-toolbar-option ui-widget ui-widget-content');\n",
       "    fmt_picker_span.append(fmt_picker);\n",
       "    nav_element.append(fmt_picker_span);\n",
       "    this.format_dropdown = fmt_picker[0];\n",
       "\n",
       "    for (var ind in mpl.extensions) {\n",
       "        var fmt = mpl.extensions[ind];\n",
       "        var option = $(\n",
       "            '<option/>', {selected: fmt === mpl.default_extension}).html(fmt);\n",
       "        fmt_picker.append(option);\n",
       "    }\n",
       "\n",
       "    // Add hover states to the ui-buttons\n",
       "    $( \".ui-button\" ).hover(\n",
       "        function() { $(this).addClass(\"ui-state-hover\");},\n",
       "        function() { $(this).removeClass(\"ui-state-hover\");}\n",
       "    );\n",
       "\n",
       "    var status_bar = $('<span class=\"mpl-message\"/>');\n",
       "    nav_element.append(status_bar);\n",
       "    this.message = status_bar[0];\n",
       "}\n",
       "\n",
       "mpl.figure.prototype.request_resize = function(x_pixels, y_pixels) {\n",
       "    // Request matplotlib to resize the figure. Matplotlib will then trigger a resize in the client,\n",
       "    // which will in turn request a refresh of the image.\n",
       "    this.send_message('resize', {'width': x_pixels, 'height': y_pixels});\n",
       "}\n",
       "\n",
       "mpl.figure.prototype.send_message = function(type, properties) {\n",
       "    properties['type'] = type;\n",
       "    properties['figure_id'] = this.id;\n",
       "    this.ws.send(JSON.stringify(properties));\n",
       "}\n",
       "\n",
       "mpl.figure.prototype.send_draw_message = function() {\n",
       "    if (!this.waiting) {\n",
       "        this.waiting = true;\n",
       "        this.ws.send(JSON.stringify({type: \"draw\", figure_id: this.id}));\n",
       "    }\n",
       "}\n",
       "\n",
       "\n",
       "mpl.figure.prototype.handle_save = function(fig, msg) {\n",
       "    var format_dropdown = fig.format_dropdown;\n",
       "    var format = format_dropdown.options[format_dropdown.selectedIndex].value;\n",
       "    fig.ondownload(fig, format);\n",
       "}\n",
       "\n",
       "\n",
       "mpl.figure.prototype.handle_resize = function(fig, msg) {\n",
       "    var size = msg['size'];\n",
       "    if (size[0] != fig.canvas.width || size[1] != fig.canvas.height) {\n",
       "        fig._resize_canvas(size[0], size[1]);\n",
       "        fig.send_message(\"refresh\", {});\n",
       "    };\n",
       "}\n",
       "\n",
       "mpl.figure.prototype.handle_rubberband = function(fig, msg) {\n",
       "    var x0 = msg['x0'] / mpl.ratio;\n",
       "    var y0 = (fig.canvas.height - msg['y0']) / mpl.ratio;\n",
       "    var x1 = msg['x1'] / mpl.ratio;\n",
       "    var y1 = (fig.canvas.height - msg['y1']) / mpl.ratio;\n",
       "    x0 = Math.floor(x0) + 0.5;\n",
       "    y0 = Math.floor(y0) + 0.5;\n",
       "    x1 = Math.floor(x1) + 0.5;\n",
       "    y1 = Math.floor(y1) + 0.5;\n",
       "    var min_x = Math.min(x0, x1);\n",
       "    var min_y = Math.min(y0, y1);\n",
       "    var width = Math.abs(x1 - x0);\n",
       "    var height = Math.abs(y1 - y0);\n",
       "\n",
       "    fig.rubberband_context.clearRect(\n",
       "        0, 0, fig.canvas.width / mpl.ratio, fig.canvas.height / mpl.ratio);\n",
       "\n",
       "    fig.rubberband_context.strokeRect(min_x, min_y, width, height);\n",
       "}\n",
       "\n",
       "mpl.figure.prototype.handle_figure_label = function(fig, msg) {\n",
       "    // Updates the figure title.\n",
       "    fig.header.textContent = msg['label'];\n",
       "}\n",
       "\n",
       "mpl.figure.prototype.handle_cursor = function(fig, msg) {\n",
       "    var cursor = msg['cursor'];\n",
       "    switch(cursor)\n",
       "    {\n",
       "    case 0:\n",
       "        cursor = 'pointer';\n",
       "        break;\n",
       "    case 1:\n",
       "        cursor = 'default';\n",
       "        break;\n",
       "    case 2:\n",
       "        cursor = 'crosshair';\n",
       "        break;\n",
       "    case 3:\n",
       "        cursor = 'move';\n",
       "        break;\n",
       "    }\n",
       "    fig.rubberband_canvas.style.cursor = cursor;\n",
       "}\n",
       "\n",
       "mpl.figure.prototype.handle_message = function(fig, msg) {\n",
       "    fig.message.textContent = msg['message'];\n",
       "}\n",
       "\n",
       "mpl.figure.prototype.handle_draw = function(fig, msg) {\n",
       "    // Request the server to send over a new figure.\n",
       "    fig.send_draw_message();\n",
       "}\n",
       "\n",
       "mpl.figure.prototype.handle_image_mode = function(fig, msg) {\n",
       "    fig.image_mode = msg['mode'];\n",
       "}\n",
       "\n",
       "mpl.figure.prototype.updated_canvas_event = function() {\n",
       "    // Called whenever the canvas gets updated.\n",
       "    this.send_message(\"ack\", {});\n",
       "}\n",
       "\n",
       "// A function to construct a web socket function for onmessage handling.\n",
       "// Called in the figure constructor.\n",
       "mpl.figure.prototype._make_on_message_function = function(fig) {\n",
       "    return function socket_on_message(evt) {\n",
       "        if (evt.data instanceof Blob) {\n",
       "            /* FIXME: We get \"Resource interpreted as Image but\n",
       "             * transferred with MIME type text/plain:\" errors on\n",
       "             * Chrome.  But how to set the MIME type?  It doesn't seem\n",
       "             * to be part of the websocket stream */\n",
       "            evt.data.type = \"image/png\";\n",
       "\n",
       "            /* Free the memory for the previous frames */\n",
       "            if (fig.imageObj.src) {\n",
       "                (window.URL || window.webkitURL).revokeObjectURL(\n",
       "                    fig.imageObj.src);\n",
       "            }\n",
       "\n",
       "            fig.imageObj.src = (window.URL || window.webkitURL).createObjectURL(\n",
       "                evt.data);\n",
       "            fig.updated_canvas_event();\n",
       "            fig.waiting = false;\n",
       "            return;\n",
       "        }\n",
       "        else if (typeof evt.data === 'string' && evt.data.slice(0, 21) == \"data:image/png;base64\") {\n",
       "            fig.imageObj.src = evt.data;\n",
       "            fig.updated_canvas_event();\n",
       "            fig.waiting = false;\n",
       "            return;\n",
       "        }\n",
       "\n",
       "        var msg = JSON.parse(evt.data);\n",
       "        var msg_type = msg['type'];\n",
       "\n",
       "        // Call the  \"handle_{type}\" callback, which takes\n",
       "        // the figure and JSON message as its only arguments.\n",
       "        try {\n",
       "            var callback = fig[\"handle_\" + msg_type];\n",
       "        } catch (e) {\n",
       "            console.log(\"No handler for the '\" + msg_type + \"' message type: \", msg);\n",
       "            return;\n",
       "        }\n",
       "\n",
       "        if (callback) {\n",
       "            try {\n",
       "                // console.log(\"Handling '\" + msg_type + \"' message: \", msg);\n",
       "                callback(fig, msg);\n",
       "            } catch (e) {\n",
       "                console.log(\"Exception inside the 'handler_\" + msg_type + \"' callback:\", e, e.stack, msg);\n",
       "            }\n",
       "        }\n",
       "    };\n",
       "}\n",
       "\n",
       "// from http://stackoverflow.com/questions/1114465/getting-mouse-location-in-canvas\n",
       "mpl.findpos = function(e) {\n",
       "    //this section is from http://www.quirksmode.org/js/events_properties.html\n",
       "    var targ;\n",
       "    if (!e)\n",
       "        e = window.event;\n",
       "    if (e.target)\n",
       "        targ = e.target;\n",
       "    else if (e.srcElement)\n",
       "        targ = e.srcElement;\n",
       "    if (targ.nodeType == 3) // defeat Safari bug\n",
       "        targ = targ.parentNode;\n",
       "\n",
       "    // jQuery normalizes the pageX and pageY\n",
       "    // pageX,Y are the mouse positions relative to the document\n",
       "    // offset() returns the position of the element relative to the document\n",
       "    var x = e.pageX - $(targ).offset().left;\n",
       "    var y = e.pageY - $(targ).offset().top;\n",
       "\n",
       "    return {\"x\": x, \"y\": y};\n",
       "};\n",
       "\n",
       "/*\n",
       " * return a copy of an object with only non-object keys\n",
       " * we need this to avoid circular references\n",
       " * http://stackoverflow.com/a/24161582/3208463\n",
       " */\n",
       "function simpleKeys (original) {\n",
       "  return Object.keys(original).reduce(function (obj, key) {\n",
       "    if (typeof original[key] !== 'object')\n",
       "        obj[key] = original[key]\n",
       "    return obj;\n",
       "  }, {});\n",
       "}\n",
       "\n",
       "mpl.figure.prototype.mouse_event = function(event, name) {\n",
       "    var canvas_pos = mpl.findpos(event)\n",
       "\n",
       "    if (name === 'button_press')\n",
       "    {\n",
       "        this.canvas.focus();\n",
       "        this.canvas_div.focus();\n",
       "    }\n",
       "\n",
       "    var x = canvas_pos.x * mpl.ratio;\n",
       "    var y = canvas_pos.y * mpl.ratio;\n",
       "\n",
       "    this.send_message(name, {x: x, y: y, button: event.button,\n",
       "                             step: event.step,\n",
       "                             guiEvent: simpleKeys(event)});\n",
       "\n",
       "    /* This prevents the web browser from automatically changing to\n",
       "     * the text insertion cursor when the button is pressed.  We want\n",
       "     * to control all of the cursor setting manually through the\n",
       "     * 'cursor' event from matplotlib */\n",
       "    event.preventDefault();\n",
       "    return false;\n",
       "}\n",
       "\n",
       "mpl.figure.prototype._key_event_extra = function(event, name) {\n",
       "    // Handle any extra behaviour associated with a key event\n",
       "}\n",
       "\n",
       "mpl.figure.prototype.key_event = function(event, name) {\n",
       "\n",
       "    // Prevent repeat events\n",
       "    if (name == 'key_press')\n",
       "    {\n",
       "        if (event.which === this._key)\n",
       "            return;\n",
       "        else\n",
       "            this._key = event.which;\n",
       "    }\n",
       "    if (name == 'key_release')\n",
       "        this._key = null;\n",
       "\n",
       "    var value = '';\n",
       "    if (event.ctrlKey && event.which != 17)\n",
       "        value += \"ctrl+\";\n",
       "    if (event.altKey && event.which != 18)\n",
       "        value += \"alt+\";\n",
       "    if (event.shiftKey && event.which != 16)\n",
       "        value += \"shift+\";\n",
       "\n",
       "    value += 'k';\n",
       "    value += event.which.toString();\n",
       "\n",
       "    this._key_event_extra(event, name);\n",
       "\n",
       "    this.send_message(name, {key: value,\n",
       "                             guiEvent: simpleKeys(event)});\n",
       "    return false;\n",
       "}\n",
       "\n",
       "mpl.figure.prototype.toolbar_button_onclick = function(name) {\n",
       "    if (name == 'download') {\n",
       "        this.handle_save(this, null);\n",
       "    } else {\n",
       "        this.send_message(\"toolbar_button\", {name: name});\n",
       "    }\n",
       "};\n",
       "\n",
       "mpl.figure.prototype.toolbar_button_onmouseover = function(tooltip) {\n",
       "    this.message.textContent = tooltip;\n",
       "};\n",
       "mpl.toolbar_items = [[\"Home\", \"Reset original view\", \"fa fa-home icon-home\", \"home\"], [\"Back\", \"Back to previous view\", \"fa fa-arrow-left icon-arrow-left\", \"back\"], [\"Forward\", \"Forward to next view\", \"fa fa-arrow-right icon-arrow-right\", \"forward\"], [\"\", \"\", \"\", \"\"], [\"Pan\", \"Pan axes with left mouse, zoom with right\", \"fa fa-arrows icon-move\", \"pan\"], [\"Zoom\", \"Zoom to rectangle\", \"fa fa-square-o icon-check-empty\", \"zoom\"], [\"\", \"\", \"\", \"\"], [\"Download\", \"Download plot\", \"fa fa-floppy-o icon-save\", \"download\"]];\n",
       "\n",
       "mpl.extensions = [\"eps\", \"jpeg\", \"pdf\", \"png\", \"ps\", \"raw\", \"svg\", \"tif\"];\n",
       "\n",
       "mpl.default_extension = \"png\";var comm_websocket_adapter = function(comm) {\n",
       "    // Create a \"websocket\"-like object which calls the given IPython comm\n",
       "    // object with the appropriate methods. Currently this is a non binary\n",
       "    // socket, so there is still some room for performance tuning.\n",
       "    var ws = {};\n",
       "\n",
       "    ws.close = function() {\n",
       "        comm.close()\n",
       "    };\n",
       "    ws.send = function(m) {\n",
       "        //console.log('sending', m);\n",
       "        comm.send(m);\n",
       "    };\n",
       "    // Register the callback with on_msg.\n",
       "    comm.on_msg(function(msg) {\n",
       "        //console.log('receiving', msg['content']['data'], msg);\n",
       "        // Pass the mpl event to the overridden (by mpl) onmessage function.\n",
       "        ws.onmessage(msg['content']['data'])\n",
       "    });\n",
       "    return ws;\n",
       "}\n",
       "\n",
       "mpl.mpl_figure_comm = function(comm, msg) {\n",
       "    // This is the function which gets called when the mpl process\n",
       "    // starts-up an IPython Comm through the \"matplotlib\" channel.\n",
       "\n",
       "    var id = msg.content.data.id;\n",
       "    // Get hold of the div created by the display call when the Comm\n",
       "    // socket was opened in Python.\n",
       "    var element = $(\"#\" + id);\n",
       "    var ws_proxy = comm_websocket_adapter(comm)\n",
       "\n",
       "    function ondownload(figure, format) {\n",
       "        window.open(figure.imageObj.src);\n",
       "    }\n",
       "\n",
       "    var fig = new mpl.figure(id, ws_proxy,\n",
       "                           ondownload,\n",
       "                           element.get(0));\n",
       "\n",
       "    // Call onopen now - mpl needs it, as it is assuming we've passed it a real\n",
       "    // web socket which is closed, not our websocket->open comm proxy.\n",
       "    ws_proxy.onopen();\n",
       "\n",
       "    fig.parent_element = element.get(0);\n",
       "    fig.cell_info = mpl.find_output_cell(\"<div id='\" + id + \"'></div>\");\n",
       "    if (!fig.cell_info) {\n",
       "        console.error(\"Failed to find cell for figure\", id, fig);\n",
       "        return;\n",
       "    }\n",
       "\n",
       "    var output_index = fig.cell_info[2]\n",
       "    var cell = fig.cell_info[0];\n",
       "\n",
       "};\n",
       "\n",
       "mpl.figure.prototype.handle_close = function(fig, msg) {\n",
       "    var width = fig.canvas.width/mpl.ratio\n",
       "    fig.root.unbind('remove')\n",
       "\n",
       "    // Update the output cell to use the data from the current canvas.\n",
       "    fig.push_to_output();\n",
       "    var dataURL = fig.canvas.toDataURL();\n",
       "    // Re-enable the keyboard manager in IPython - without this line, in FF,\n",
       "    // the notebook keyboard shortcuts fail.\n",
       "    IPython.keyboard_manager.enable()\n",
       "    $(fig.parent_element).html('<img src=\"' + dataURL + '\" width=\"' + width + '\">');\n",
       "    fig.close_ws(fig, msg);\n",
       "}\n",
       "\n",
       "mpl.figure.prototype.close_ws = function(fig, msg){\n",
       "    fig.send_message('closing', msg);\n",
       "    // fig.ws.close()\n",
       "}\n",
       "\n",
       "mpl.figure.prototype.push_to_output = function(remove_interactive) {\n",
       "    // Turn the data on the canvas into data in the output cell.\n",
       "    var width = this.canvas.width/mpl.ratio\n",
       "    var dataURL = this.canvas.toDataURL();\n",
       "    this.cell_info[1]['text/html'] = '<img src=\"' + dataURL + '\" width=\"' + width + '\">';\n",
       "}\n",
       "\n",
       "mpl.figure.prototype.updated_canvas_event = function() {\n",
       "    // Tell IPython that the notebook contents must change.\n",
       "    IPython.notebook.set_dirty(true);\n",
       "    this.send_message(\"ack\", {});\n",
       "    var fig = this;\n",
       "    // Wait a second, then push the new image to the DOM so\n",
       "    // that it is saved nicely (might be nice to debounce this).\n",
       "    setTimeout(function () { fig.push_to_output() }, 1000);\n",
       "}\n",
       "\n",
       "mpl.figure.prototype._init_toolbar = function() {\n",
       "    var fig = this;\n",
       "\n",
       "    var nav_element = $('<div/>');\n",
       "    nav_element.attr('style', 'width: 100%');\n",
       "    this.root.append(nav_element);\n",
       "\n",
       "    // Define a callback function for later on.\n",
       "    function toolbar_event(event) {\n",
       "        return fig.toolbar_button_onclick(event['data']);\n",
       "    }\n",
       "    function toolbar_mouse_event(event) {\n",
       "        return fig.toolbar_button_onmouseover(event['data']);\n",
       "    }\n",
       "\n",
       "    for(var toolbar_ind in mpl.toolbar_items){\n",
       "        var name = mpl.toolbar_items[toolbar_ind][0];\n",
       "        var tooltip = mpl.toolbar_items[toolbar_ind][1];\n",
       "        var image = mpl.toolbar_items[toolbar_ind][2];\n",
       "        var method_name = mpl.toolbar_items[toolbar_ind][3];\n",
       "\n",
       "        if (!name) { continue; };\n",
       "\n",
       "        var button = $('<button class=\"btn btn-default\" href=\"#\" title=\"' + name + '\"><i class=\"fa ' + image + ' fa-lg\"></i></button>');\n",
       "        button.click(method_name, toolbar_event);\n",
       "        button.mouseover(tooltip, toolbar_mouse_event);\n",
       "        nav_element.append(button);\n",
       "    }\n",
       "\n",
       "    // Add the status bar.\n",
       "    var status_bar = $('<span class=\"mpl-message\" style=\"text-align:right; float: right;\"/>');\n",
       "    nav_element.append(status_bar);\n",
       "    this.message = status_bar[0];\n",
       "\n",
       "    // Add the close button to the window.\n",
       "    var buttongrp = $('<div class=\"btn-group inline pull-right\"></div>');\n",
       "    var button = $('<button class=\"btn btn-mini btn-primary\" href=\"#\" title=\"Stop Interaction\"><i class=\"fa fa-power-off icon-remove icon-large\"></i></button>');\n",
       "    button.click(function (evt) { fig.handle_close(fig, {}); } );\n",
       "    button.mouseover('Stop Interaction', toolbar_mouse_event);\n",
       "    buttongrp.append(button);\n",
       "    var titlebar = this.root.find($('.ui-dialog-titlebar'));\n",
       "    titlebar.prepend(buttongrp);\n",
       "}\n",
       "\n",
       "mpl.figure.prototype._root_extra_style = function(el){\n",
       "    var fig = this\n",
       "    el.on(\"remove\", function(){\n",
       "\tfig.close_ws(fig, {});\n",
       "    });\n",
       "}\n",
       "\n",
       "mpl.figure.prototype._canvas_extra_style = function(el){\n",
       "    // this is important to make the div 'focusable\n",
       "    el.attr('tabindex', 0)\n",
       "    // reach out to IPython and tell the keyboard manager to turn it's self\n",
       "    // off when our div gets focus\n",
       "\n",
       "    // location in version 3\n",
       "    if (IPython.notebook.keyboard_manager) {\n",
       "        IPython.notebook.keyboard_manager.register_events(el);\n",
       "    }\n",
       "    else {\n",
       "        // location in version 2\n",
       "        IPython.keyboard_manager.register_events(el);\n",
       "    }\n",
       "\n",
       "}\n",
       "\n",
       "mpl.figure.prototype._key_event_extra = function(event, name) {\n",
       "    var manager = IPython.notebook.keyboard_manager;\n",
       "    if (!manager)\n",
       "        manager = IPython.keyboard_manager;\n",
       "\n",
       "    // Check for shift+enter\n",
       "    if (event.shiftKey && event.which == 13) {\n",
       "        this.canvas_div.blur();\n",
       "        // select the cell after this one\n",
       "        var index = IPython.notebook.find_cell_index(this.cell_info[0]);\n",
       "        IPython.notebook.select(index + 1);\n",
       "    }\n",
       "}\n",
       "\n",
       "mpl.figure.prototype.handle_save = function(fig, msg) {\n",
       "    fig.ondownload(fig, null);\n",
       "}\n",
       "\n",
       "\n",
       "mpl.find_output_cell = function(html_output) {\n",
       "    // Return the cell and output element which can be found *uniquely* in the notebook.\n",
       "    // Note - this is a bit hacky, but it is done because the \"notebook_saving.Notebook\"\n",
       "    // IPython event is triggered only after the cells have been serialised, which for\n",
       "    // our purposes (turning an active figure into a static one), is too late.\n",
       "    var cells = IPython.notebook.get_cells();\n",
       "    var ncells = cells.length;\n",
       "    for (var i=0; i<ncells; i++) {\n",
       "        var cell = cells[i];\n",
       "        if (cell.cell_type === 'code'){\n",
       "            for (var j=0; j<cell.output_area.outputs.length; j++) {\n",
       "                var data = cell.output_area.outputs[j];\n",
       "                if (data.data) {\n",
       "                    // IPython >= 3 moved mimebundle to data attribute of output\n",
       "                    data = data.data;\n",
       "                }\n",
       "                if (data['text/html'] == html_output) {\n",
       "                    return [cell, data, j];\n",
       "                }\n",
       "            }\n",
       "        }\n",
       "    }\n",
       "}\n",
       "\n",
       "// Register the function which deals with the matplotlib target/channel.\n",
       "// The kernel may be null if the page has been refreshed.\n",
       "if (IPython.notebook.kernel != null) {\n",
       "    IPython.notebook.kernel.comm_manager.register_target('matplotlib', mpl.mpl_figure_comm);\n",
       "}\n"
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<img src=\"data:image/png;base64,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\" width=\"640\">"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "[<mpl_toolkits.mplot3d.art3d.Line3D at 0x2aab4b8a2580>]"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%matplotlib notebook\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "#for i in range(len(states)):\n",
    "#    print(states[i], env.referenceStreamline_ijk[i])\n",
    "#    distance = ((states.T[0][i] - env.referenceStreamline_ijk.T[0][i])**2 \\\n",
    "#                      + (states.T[1][i] - env.referenceStreamline_ijk.T[1][i] )**2 \\\n",
    "#                      + (states.T[2][i] - env.referenceStreamline_ijk.T[2][i])**2)\n",
    "#    print(distance)\n",
    "\n",
    "\n",
    "fig = plt.figure()\n",
    "ax = plt.axes(projection='3d')\n",
    "ax.plot3D(env.referenceStreamline_ijk.T[0][:], env.referenceStreamline_ijk.T[1][:], env.referenceStreamline_ijk.T[2][:])\n",
    "ax.plot3D(states.T[0][:], states.T[1][:], states.T[2][:])\n",
    "#print(optimal_steps[:])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([24.1166, 24.7622, 25.4003], dtype=torch.float64)\n"
     ]
    }
   ],
   "source": [
    "states = torch.stack(all_states)\n",
    "print(states.T[0][:3])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([ 71.7731, 113.9662,  79.6186])\n"
     ]
    }
   ],
   "source": [
    "print(referenceLine[86])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 73.651344 107.88106   93.29415 ] tensor([ 73.6513, 107.8811,  93.2942])\n",
      "tensor(66.2049, dtype=torch.float64)\n"
     ]
    }
   ],
   "source": [
    "env.reset()\n",
    "print(env.state.getCoordinate().numpy(), referenceLine[0])\n",
    "step = 0\n",
    "#all_rewards = []\n",
    "eps_reward = 0\n",
    "for i in optimal_steps:\n",
    "    next_state, distance, terminal = env.step(i)\n",
    "    if distance < 0.71:\n",
    "        reward = 1 - distance\n",
    "        #print(reward)\n",
    "        if reward < 0.3:\n",
    "            reward = 1\n",
    "    eps_reward += reward\n",
    "    #all_rewards.append(reward)\n",
    "    step += 1\n",
    "print(eps_reward)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(n_actions):\n",
    "    \n",
    "    next_state, distance, terminal = env.step(i)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Action:  100 Step:  1 Coordinates:  [ 73.651344 107.88106   93.29415 ] [ 74.42344 107.87124  93.08491]\n",
      "Action:  67 Step:  2 Coordinates:  [ 74.34808267 107.88351105  92.57683017] [ 75.16057  107.88882   92.774536]\n",
      "Action:  100 Step:  3 Coordinates:  [ 74.34808267 107.88351105  92.57683017] [ 75.78847 107.96255  92.28433]\n",
      "Action:  100 Step:  4 Coordinates:  [ 74.34808267 107.88351105  92.57683017] [ 76.45265  108.118454  91.86654 ]\n",
      "Action:  100 Step:  5 Coordinates:  [ 74.34808267 107.88351105  92.57683017] [ 77.116844 108.27435   91.448746]\n",
      "Action:  100 Step:  6 Coordinates:  [ 74.34808267 107.88351105  92.57683017] [ 77.739716 108.54131   91.02359 ]\n",
      "Action:  100 Step:  7 Coordinates:  [ 74.34808267 107.88351105  92.57683017] [ 78.36259  108.80828   90.598434]\n",
      "Action:  100 Step:  8 Coordinates:  [ 74.34808267 107.88351105  92.57683017] [ 78.996666 109.15176   90.25207 ]\n",
      "Action:  100 Step:  9 Coordinates:  [ 74.34808267 107.88351105  92.57683017] [ 79.630745 109.495224  89.9057  ]\n",
      "Action:  100 Step:  10 Coordinates:  [ 74.34808267 107.88351105  92.57683017] [ 80.264824 109.8387    89.55933 ]\n",
      "Action:  100 Step:  11 Coordinates:  [ 74.34808267 107.88351105  92.57683017] [ 80.833374 110.28288   89.21371 ]\n",
      "Action:  100 Step:  12 Coordinates:  [ 74.34808267 107.88351105  92.57683017] [ 81.32385 110.75597  88.79464]\n",
      "Action:  100 Step:  13 Coordinates:  [ 74.34808267 107.88351105  92.57683017] [ 81.78852 111.07612  88.22755]\n",
      "Action:  100 Step:  14 Coordinates:  [ 74.34808267 107.88351105  92.57683017] [ 82.26274  111.20639   87.596565]\n",
      "Action:  100 Step:  15 Coordinates:  [ 74.34808267 107.88351105  92.57683017] [ 82.764885 111.12094   86.97968 ]\n",
      "Action:  100 Step:  16 Coordinates:  [ 74.34808267 107.88351105  92.57683017] [ 83.17989 111.072    86.2975 ]\n",
      "Action:  100 Step:  17 Coordinates:  [ 74.34808267 107.88351105  92.57683017] [ 83.60093  110.91725   85.635086]\n",
      "Action:  100 Step:  18 Coordinates:  [ 74.34808267 107.88351105  92.57683017] [ 84.02196  110.762505  84.97268 ]\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-8-9b9d7b386c25>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[0;32mwhile\u001b[0m \u001b[0mterminal\u001b[0m \u001b[0;34m!=\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m     \u001b[0maction\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrandom\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrandint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mn_actions\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 9\u001b[0;31m     \u001b[0mnext_state\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mreward\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mterminal\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0menv\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0maction\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     10\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mreward\u001b[0m \u001b[0;34m<\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     11\u001b[0m         \u001b[0mactions\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0maction\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/fibre_tracking/deepFibreTracking/dfibert/envs/RLtractEnvironment.py\u001b[0m in \u001b[0;36mstep\u001b[0;34m(self, action)\u001b[0m\n\u001b[1;32m    110\u001b[0m         \u001b[0mpositionNextState\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstate\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgetCoordinate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstepWidth\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0maction_vector\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    111\u001b[0m         \u001b[0mnextState\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mTractographyState\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpositionNextState\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minterpolateDWIatState\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 112\u001b[0;31m         \u001b[0;32mif\u001b[0m \u001b[0mnextState\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgetValue\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    113\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstate\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m-\u001b[0m\u001b[0;36m10\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    114\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/fibre_tracking/deepFibreTracking/dfibert/envs/_state.py\u001b[0m in \u001b[0;36mgetValue\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m     14\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minterpolatedDWI\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     15\u001b[0m         \u001b[0;31m# interpolate DWI value at self.coordinate\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 16\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minterpolatedDWI\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minterpolFuncHandle\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcoordinate\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     17\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minterpolatedDWI\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/fibre_tracking/deepFibreTracking/dfibert/envs/RLtractEnvironment.py\u001b[0m in \u001b[0;36minterpolateDWIatState\u001b[0;34m(self, stateCoordinates)\u001b[0m\n\u001b[1;32m     51\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     52\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 53\u001b[0;31m             \u001b[0minterpolated_dwi\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_interpolated_dwi\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mras_points\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpostprocessing\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdwi_postprocessor\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     54\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mValueError\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     55\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/fibre_tracking/deepFibreTracking/dfibert/data/__init__.py\u001b[0m in \u001b[0;36mget_interpolated_dwi\u001b[0;34m(self, points, postprocessing, ignore_outside_points)\u001b[0m\n\u001b[1;32m    286\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    287\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mpostprocessing\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 288\u001b[0;31m             result = postprocessing(result, self.data.b0, \n\u001b[0m\u001b[1;32m    289\u001b[0m                                  \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbvecs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    290\u001b[0m                                  self.data.bvals)\n",
      "\u001b[0;32m~/fibre_tracking/deepFibreTracking/dfibert/data/postprocessing.py\u001b[0m in \u001b[0;36m_wrapper\u001b[0;34m(dwi, b0, bvecs, bvals)\u001b[0m\n\u001b[1;32m     91\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     92\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_wrapper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdwi\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mb0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbvecs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbvals\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 93\u001b[0;31m         \u001b[0mdata_sh\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mspherical_harmonics\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msh_order\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msh_order\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msmooth\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msmooth\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdwi\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mb0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbvecs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbvals\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     94\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     95\u001b[0m         \u001b[0mdata_resampled\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdot\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata_sh\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mreal_sh\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mT\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/fibre_tracking/deepFibreTracking/dfibert/data/postprocessing.py\u001b[0m in \u001b[0;36m_wrapper\u001b[0;34m(dwi, _b0, bvecs, _bvals)\u001b[0m\n\u001b[1;32m     53\u001b[0m         \u001b[0mreal_sh\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mn\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mreal_sym_sh_mrtrix\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msh_order\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mraw_sphere\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtheta\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mraw_sphere\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mphi\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     54\u001b[0m         \u001b[0ml\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m-\u001b[0m\u001b[0mn\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mn\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 55\u001b[0;31m         \u001b[0minv_b\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msmooth_pinv\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mreal_sh\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msqrt\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msmooth\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0ml\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     56\u001b[0m         \u001b[0mdata_sh\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdot\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdwi\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minv_b\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mT\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     57\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.conda/envs/atari/lib/python3.8/site-packages/dipy/reconst/shm.py\u001b[0m in \u001b[0;36msmooth_pinv\u001b[0;34m(B, L)\u001b[0m\n\u001b[1;32m    661\u001b[0m     \"\"\"\n\u001b[1;32m    662\u001b[0m     \u001b[0mL\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdiag\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mL\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 663\u001b[0;31m     \u001b[0minv\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlinalg\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpinv\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconcatenate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mB\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mL\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    664\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0minv\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m:\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mB\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    665\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<__array_function__ internals>\u001b[0m in \u001b[0;36mpinv\u001b[0;34m(*args, **kwargs)\u001b[0m\n",
      "\u001b[0;32m~/.conda/envs/atari/lib/python3.8/site-packages/numpy/linalg/linalg.py\u001b[0m in \u001b[0;36mpinv\u001b[0;34m(a, rcond, hermitian)\u001b[0m\n\u001b[1;32m   1959\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mwrap\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mres\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1960\u001b[0m     \u001b[0ma\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0ma\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconjugate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1961\u001b[0;31m     \u001b[0mu\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0ms\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvt\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msvd\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0ma\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfull_matrices\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhermitian\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mhermitian\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1962\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1963\u001b[0m     \u001b[0;31m# discard small singular values\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<__array_function__ internals>\u001b[0m in \u001b[0;36msvd\u001b[0;34m(*args, **kwargs)\u001b[0m\n",
      "\u001b[0;32m~/.conda/envs/atari/lib/python3.8/site-packages/numpy/linalg/linalg.py\u001b[0m in \u001b[0;36msvd\u001b[0;34m(a, full_matrices, compute_uv, hermitian)\u001b[0m\n\u001b[1;32m   1624\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1625\u001b[0m         \u001b[0msignature\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m'D->DdD'\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0misComplexType\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mt\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0;34m'd->ddd'\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1626\u001b[0;31m         \u001b[0mu\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0ms\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvh\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mgufunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0ma\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msignature\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msignature\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mextobj\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mextobj\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1627\u001b[0m         \u001b[0mu\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mu\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mastype\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mresult_t\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcopy\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1628\u001b[0m         \u001b[0ms\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0ms\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mastype\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0m_realType\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mresult_t\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcopy\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "env.reset()\n",
    "terminal = False\n",
    "step = 0\n",
    "actions = []\n",
    "past_state = env.state\n",
    "step = 1\n",
    "while terminal != True:\n",
    "    for i in range(n_actions)\n",
    "    action = np.random.randint(n_actions)\n",
    "    next_state, reward, terminal = env.step(action)\n",
    "    if reward < 1:\n",
    "        actions.append(action)\n",
    "        past_state = next_state\n",
    "        print(\"Action: \", action, \"Step: \",step, \"Coordinates: \", next_state.getCoordinate().numpy(), referenceLine[step].numpy())\n",
    "        step += 1\n",
    "    else:\n",
    "        env.state = past_state\n",
    "        env.stepCounter = step\n",
    "    #action = np.random.choice(possible_actions[step])\n",
    "    #next_state, reward, terminal = env.step(action)\n",
    "    #step += 1\n",
    "\n",
    "print(actions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([ 77.7397, 108.5413,  91.0236])\n",
      "tensor([ 78.3626, 108.8083,  90.5984])\n"
     ]
    }
   ],
   "source": [
    "print(referenceLine[6])\n",
    "print(referenceLine[7])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([ 78.1077, 108.7354,  91.6977], dtype=torch.float64)\n",
      "tensor([ 77.7615, 108.8643,  91.6973], dtype=torch.float64)\n",
      "tensor([ 77.8808, 108.4698,  91.6927], dtype=torch.float64)\n",
      "tensor([ 78.0768, 109.0850,  91.6268], dtype=torch.float64)\n",
      "tensor([ 77.5148, 108.5987,  91.6375], dtype=torch.float64)\n",
      "tensor([ 78.3125, 108.4477,  91.5947], dtype=torch.float64)\n",
      "tensor([ 77.7489, 109.2253,  91.5590], dtype=torch.float64)\n",
      "tensor([ 77.6419, 108.2420,  91.5700], dtype=torch.float64)\n",
      "tensor([ 78.4297, 108.8083,  91.5614], dtype=torch.float64)\n",
      "tensor([ 77.4379, 108.9717,  91.5654], dtype=torch.float64)\n",
      "tensor([ 78.0813, 108.1849,  91.5566], dtype=torch.float64)\n",
      "tensor([ 78.1025, 109.3932,  91.4139], dtype=torch.float64)\n",
      "tensor([ 77.3094, 108.3452,  91.4445], dtype=torch.float64)\n",
      "tensor([ 78.6147, 108.4838,  91.3841], dtype=torch.float64)\n",
      "tensor([ 77.4417, 109.2998,  91.3783], dtype=torch.float64)\n",
      "tensor([ 77.8415, 107.9787,  91.4083], dtype=torch.float64)\n",
      "tensor([ 78.3907, 109.1557,  91.4638], dtype=torch.float64)\n",
      "tensor([ 77.2027, 108.6996,  91.4375], dtype=torch.float64)\n",
      "tensor([ 78.4256, 108.1555,  91.3717], dtype=torch.float64)\n",
      "tensor([ 77.7865, 109.5055,  91.3048], dtype=torch.float64)\n",
      "tensor([ 77.4984, 108.0024,  91.3116], dtype=torch.float64)\n",
      "tensor([ 78.6872, 108.8408,  91.3203], dtype=torch.float64)\n",
      "tensor([ 77.1729, 109.0570,  91.3086], dtype=torch.float64)\n",
      "tensor([ 78.1746, 107.9095,  91.2645], dtype=torch.float64)\n",
      "tensor([ 78.3889, 109.4422,  91.1813], dtype=torch.float64)\n",
      "tensor([ 77.0434, 108.4461,  91.1692], dtype=torch.float64)\n",
      "tensor([ 78.6965, 108.2442,  91.1141], dtype=torch.float64)\n",
      "tensor([ 77.5030, 109.5370,  91.1019], dtype=torch.float64)\n",
      "tensor([ 77.5000, 107.8270,  90.9938], dtype=torch.float64)\n",
      "tensor([ 78.6388, 109.1633,  91.2107], dtype=torch.float64)\n",
      "tensor([ 76.9888, 108.7771,  91.1266], dtype=torch.float64)\n",
      "tensor([ 78.4668, 107.9465,  91.0478], dtype=torch.float64)\n",
      "tensor([ 78.0655, 109.6183,  91.0848], dtype=torch.float64)\n",
      "tensor([ 77.2055, 108.1323,  91.1605], dtype=torch.float64)\n",
      "tensor([ 78.8286, 108.6225,  91.0812], dtype=torch.float64)\n",
      "tensor([ 77.2105, 109.3476,  91.0498], dtype=torch.float64)\n",
      "tensor([ 77.8390, 107.7826,  91.1087], dtype=torch.float64)\n",
      "tensor([ 78.6632, 109.3198,  90.9072], dtype=torch.float64)\n",
      "tensor([ 76.9030, 108.6561,  90.7911], dtype=torch.float64)\n",
      "tensor([ 78.6834, 108.0832,  90.7689], dtype=torch.float64)\n",
      "tensor([ 77.7496, 109.6751,  90.8953], dtype=torch.float64)\n",
      "tensor([ 77.2161, 107.9836,  90.8505], dtype=torch.float64)\n",
      "tensor([ 78.8374, 108.9642,  90.9474], dtype=torch.float64)\n",
      "tensor([ 77.0033, 109.0777,  90.9567], dtype=torch.float64)\n",
      "tensor([ 78.1431, 107.7515,  90.9129], dtype=torch.float64)\n",
      "tensor([ 78.3585, 109.5817,  90.8446], dtype=torch.float64)\n",
      "tensor([ 76.9926, 108.2972,  90.8376], dtype=torch.float64)\n",
      "tensor([ 78.8549, 108.4211,  90.8108], dtype=torch.float64)\n",
      "tensor([ 77.3852, 109.5591,  90.7525], dtype=torch.float64)\n",
      "tensor([ 77.7615, 107.7120,  90.7482], dtype=torch.float64)\n",
      "tensor([ 77.6912, 108.6687,  89.7427], dtype=torch.float64)\n",
      "tensor([ 78.0374, 108.5397,  89.7432], dtype=torch.float64)\n",
      "tensor([ 77.9181, 108.9343,  89.7477], dtype=torch.float64)\n",
      "tensor([ 77.7221, 108.3191,  89.8136], dtype=torch.float64)\n",
      "tensor([ 78.2841, 108.8053,  89.8029], dtype=torch.float64)\n",
      "tensor([ 77.4863, 108.9563,  89.8458], dtype=torch.float64)\n",
      "tensor([ 78.0500, 108.1788,  89.8814], dtype=torch.float64)\n",
      "tensor([ 78.1570, 109.1620,  89.8705], dtype=torch.float64)\n",
      "tensor([ 77.3692, 108.5958,  89.8791], dtype=torch.float64)\n",
      "tensor([ 78.3610, 108.4323,  89.8751], dtype=torch.float64)\n",
      "tensor([ 77.7176, 109.2191,  89.8838], dtype=torch.float64)\n",
      "tensor([ 77.6964, 108.0109,  90.0266], dtype=torch.float64)\n",
      "tensor([ 78.4895, 109.0588,  89.9960], dtype=torch.float64)\n",
      "tensor([ 77.1842, 108.9202,  90.0563], dtype=torch.float64)\n",
      "tensor([ 78.3572, 108.1042,  90.0621], dtype=torch.float64)\n",
      "tensor([ 77.9574, 109.4254,  90.0322], dtype=torch.float64)\n",
      "tensor([ 77.4082, 108.2484,  89.9767], dtype=torch.float64)\n",
      "tensor([ 78.5962, 108.7045,  90.0029], dtype=torch.float64)\n",
      "tensor([ 77.3733, 109.2486,  90.0688], dtype=torch.float64)\n",
      "tensor([ 78.0123, 107.8986,  90.1357], dtype=torch.float64)\n",
      "tensor([ 78.3005, 109.4017,  90.1289], dtype=torch.float64)\n",
      "tensor([ 77.1116, 108.5632,  90.1201], dtype=torch.float64)\n",
      "tensor([ 78.6259, 108.3471,  90.1318], dtype=torch.float64)\n",
      "tensor([ 77.6242, 109.4945,  90.1760], dtype=torch.float64)\n",
      "tensor([ 77.4100, 107.9618,  90.2592], dtype=torch.float64)\n",
      "tensor([ 78.7555, 108.9580,  90.2712], dtype=torch.float64)\n",
      "75 [ 78.7555186  108.95801267  90.27122457] [ 78.36259  108.80828   90.598434] 0.2838811622505798\n",
      "tensor([ 77.1024, 109.1599,  90.3263], dtype=torch.float64)\n",
      "tensor([ 78.2959, 107.8671,  90.3386], dtype=torch.float64)\n",
      "tensor([ 78.2988, 109.5771,  90.4467], dtype=torch.float64)\n",
      "tensor([ 77.1600, 108.2408,  90.2298], dtype=torch.float64)\n",
      "tensor([ 78.8100, 108.6269,  90.3138], dtype=torch.float64)\n",
      "tensor([ 77.3321, 109.4575,  90.3926], dtype=torch.float64)\n",
      "tensor([ 77.7333, 107.7858,  90.3557], dtype=torch.float64)\n",
      "tensor([ 78.5934, 109.2718,  90.2799], dtype=torch.float64)\n",
      "tensor([ 76.9703, 108.7816,  90.3592], dtype=torch.float64)\n",
      "tensor([ 78.5884, 108.0565,  90.3906], dtype=torch.float64)\n",
      "tensor([ 77.9598, 109.6215,  90.3317], dtype=torch.float64)\n",
      "tensor([ 77.1356, 108.0842,  90.5333], dtype=torch.float64)\n",
      "tensor([ 78.8959, 108.7480,  90.6493], dtype=torch.float64)\n",
      "88 [ 78.89586077 108.74800996  90.64932975] [ 78.36259  108.80828   90.598434] 0.2906038664155419\n",
      "tensor([ 77.1154, 109.3209,  90.6715], dtype=torch.float64)\n",
      "tensor([ 78.0493, 107.7290,  90.5451], dtype=torch.float64)\n",
      "tensor([ 78.5828, 109.4204,  90.5900], dtype=torch.float64)\n",
      "tensor([ 76.9615, 108.4399,  90.4931], dtype=torch.float64)\n",
      "tensor([ 78.7955, 108.3264,  90.4838], dtype=torch.float64)\n",
      "tensor([ 77.6558, 109.6526,  90.5275], dtype=torch.float64)\n",
      "tensor([ 77.4404, 107.8224,  90.5959], dtype=torch.float64)\n",
      "tensor([ 78.8063, 109.1069,  90.6029], dtype=torch.float64)\n",
      "96 [ 78.80625982 109.10688665  90.60289128] [ 78.36259  108.80828   90.598434] 0.28603082585170475\n",
      "tensor([ 76.9440, 108.9829,  90.6297], dtype=torch.float64)\n",
      "tensor([ 78.4137, 107.8450,  90.6879], dtype=torch.float64)\n",
      "tensor([ 78.0373, 109.6921,  90.6923], dtype=torch.float64)\n",
      "100 [ 77.89944  108.702034  90.72022 ] [ 78.36259  108.80828   90.598434] 0.24062869\n"
     ]
    }
   ],
   "source": [
    "state = TractographyState(torch.Tensor([ 77.8994346, 108.7020324, 90.72022516]), env.interpolateDWIatState)\n",
    "for i in range(n_actions):\n",
    "    env.state = state\n",
    "    env.stepCounter -= 1\n",
    "    next_state, _, terminal = env.step(i)\n",
    "    qry_pt = next_state.getCoordinate().view(-1,3)\n",
    "    distance = torch.min(torch.sum((referenceLine[7] - qry_pt)**2, dim=1))\n",
    "    if distance < 0.3:\n",
    "        print(i, next_state.getCoordinate().numpy(), referenceLine[7].numpy(), distance.numpy())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(187.0214)\n",
      "[ 73.651344 107.88106   93.29415 ]\n",
      "-1\n",
      "True\n"
     ]
    }
   ],
   "source": [
    "env.reset()\n",
    "next_state, reward, terminal = env.step(100)\n",
    "print(next_state.getCoordinate().numpy())\n",
    "print(reward)\n",
    "print(terminal)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[47, 75, 80, 88, 93, 96], [67, 75, 80, 88, 93], [62, 67, 75, 80], [62, 67, 75, 80, 83], [62, 67, 75, 80, 83], [62, 67, 75, 83, 96], [62, 67, 75, 83, 96], [62, 75, 83, 91, 96], [62, 75, 83, 91, 96], [62, 75, 83, 91, 96], [62, 70, 75, 83, 91, 96], [62, 70, 75, 78, 83, 91], [54, 57, 62, 67, 70, 75, 83], [54, 62, 67, 75], [54, 59, 67, 72], [51, 54, 59, 62, 67, 72], [51, 54, 59, 64, 67, 72], [51, 54, 59, 64, 67, 72], [51, 54, 59, 64, 67, 72], [51, 54, 56, 59, 64, 67, 72], [51, 54, 56, 59, 64, 67, 72], [51, 56, 59, 64], [51, 56, 59, 64], [51, 56, 59, 64], [50, 51, 53, 56, 59], [50, 51, 53, 56, 61, 66], [53, 58, 61, 66, 74, 79], [58, 66, 71, 74, 79], [58, 66, 71, 79], [58, 63, 66, 71, 79], [58, 63, 66, 71, 79], [58, 63, 66, 71, 79], [58, 63, 66, 71, 79], [58, 63, 66, 71, 79, 84], [58, 63, 71, 79, 84, 92], [58, 63, 71, 79, 84, 92], [63, 71, 79, 84, 92], [63, 71, 79, 84, 92], [38, 71, 79, 84, 92], [38, 63, 71, 84, 92, 97], [38, 71, 84, 92, 97], [38, 84, 92, 97], [38, 76, 84, 92, 97], [38, 76, 84, 92, 97], [38, 43, 84, 89, 97], [38, 43, 84, 89, 97], [30, 38, 43, 97], [30, 38, 43, 97], [30, 38, 43, 97], [22, 30, 38, 43, 97], [22, 30, 38, 43, 97], [22, 35, 43, 89, 97], [35, 43, 48, 89], [40, 48, 81, 89, 94], [40, 48, 73, 81, 86, 94], [73, 81, 86, 94], [40, 48, 81, 89, 94], [35, 43, 48, 89], [22, 35, 43, 89, 97], [22, 35, 43, 89, 97], [22, 30, 35, 43, 89], [22, 30, 35, 43, 89], [14, 22, 27, 35, 43], [14, 22, 27, 35], [6, 14, 19, 22, 27, 35], [6, 11, 14, 19, 27], [3, 6, 11, 19], [3, 6, 11, 16], [3, 8, 11, 16], [3, 8, 11, 16, 24, 29], [3, 8, 16, 21, 29], [8, 16, 21, 29], [8, 13, 16, 21, 29], [8, 13, 16, 21, 29], [21, 29, 34, 42], [13, 21, 26, 34, 47], [13, 18, 26, 31, 34, 39, 47], [26, 34, 39, 47, 93], [26, 34, 39, 47, 93], [26, 39, 47, 85, 93], [26, 39, 47, 85, 93], [39, 47, 72, 85, 93], [64, 72, 80, 85, 93], [64, 72, 77, 85, 93], [56, 64, 69, 72, 77, 85], [64, 69, 77, 85, 90, 98], [100]]\n"
     ]
    }
   ],
   "source": [
    "print(possible_actions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([ 71.5173, 114.6476,  79.9506])\n",
      "tensor([ 71.7731, 113.9662,  79.6186])\n",
      "[64, 69, 77, 85, 90, 98]\n",
      "tensor([ 71.5173, 114.6476,  79.9506]) tensor(0.4643)\n",
      "tensor([ 71.5173, 114.6476,  79.9506]) tensor(0.4643)\n",
      "tensor([ 71.5173, 114.6476,  79.9506]) tensor(0.4643)\n",
      "tensor([ 71.5173, 114.6476,  79.9506]) tensor(0.4643)\n",
      "tensor([ 71.5173, 114.6476,  79.9506]) tensor(0.4643)\n",
      "tensor([ 71.5173, 114.6476,  79.9506]) tensor(0.4643)\n"
     ]
    }
   ],
   "source": [
    "env.state = TractographyState(referenceLine[85], env.interpolateDWIatState)\n",
    "print(env.state.getCoordinate())\n",
    "print(referenceLine[86])\n",
    "print(possible_actions[85])\n",
    "for i in possible_actions[85]:\n",
    "    env.state = TractographyState(referenceLine[85], env.interpolateDWIatState)\n",
    "    env.stepCounter = 84\n",
    "    next_state, reward, _ = env.step(z)\n",
    "    print(next_state.getCoordinate(), reward)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 71.773056 113.966225  79.618576] [ 72.30127204 114.02878755  79.99932066] 0.27901215525974304\n",
      "[ 71.773056 113.966225  79.618576] [ 71.7609279  113.6971063   80.14330044] 0.2753356828217112\n",
      "[ 71.773056 113.966225  79.618576] [ 71.37937604 113.65758474  79.97858924] 0.15498393104601757\n",
      "[ 71.773056 113.966225  79.618576] [ 71.66780472 114.12438903  79.11184227] 0.2567791198339029\n",
      "[ 71.773056 113.966225  79.618576] [ 71.97880832 114.37794723  79.10548775] 0.26325960220840583\n",
      "[ 71.773056 113.966225  79.618576] [ 71.31423388 113.95652005  79.25698482] 0.2105177635246191\n",
      "[ 71.773056 113.966225  79.618576] [ 71.97504289 114.04982978  79.29253904] 0.10630013104166292\n",
      "[ 71.773056 113.966225  79.618576] [ 71.63016002 113.84417747  79.3660627 ] 0.06376299386222199\n",
      "[ 71.773056 113.966225  79.618576] [ 72.24376411 114.29266559  79.36222956] 0.2215660937612901\n",
      "[ 71.773056 113.966225  79.618576] [ 71.91375289 113.81268975  79.56895814] 0.023572970787664616\n",
      "[ 71.773056 113.966225  79.618576] [ 71.35118583 113.73139254  79.58605126] 0.1779744651043897\n",
      "[ 71.773056 113.966225  79.618576] [ 72.20619251 114.00206886  79.62102829] 0.18760720625139998\n",
      "[ 71.773056 113.966225  79.618576] [ 71.66712842 113.67455586  79.7755295 ] 0.08507069391326497\n",
      "[ 71.773056 113.966225  79.618576] [ 72.03154546 113.7906186   79.91830767] 0.0898390464981324\n"
     ]
    }
   ],
   "source": [
    "#env.state = TractographyState(referenceLine[85], env.interpolateDWIatState)\n",
    "for i in range(n_actions):\n",
    "    env.reset()\n",
    "    env.state = TractographyState(referenceLine[85], env.interpolateDWIatState)\n",
    "    next_state, reward, _ = env.step(i)\n",
    "    distance = env.rewardForTerminalState(next_state)\n",
    "    if distance < 0.3:\n",
    "        print(referenceLine[86].numpy(), next_state.getCoordinate().numpy(), distance.item())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([ 71.7731, 113.9662,  79.6186])\n",
      "tensor(122.0777, dtype=torch.float64)\n"
     ]
    }
   ],
   "source": [
    "distance = env.rewardForTerminalState(next_state)\n",
    "print(referenceLine[86])\n",
    "print(distance)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(n_actions):\n",
    "    env.state = TractographyState(torch.FloatTensor([ 74.64776812, 107.9270337, 93.22325858]), env.interpolateDWIatState)\n",
    "    next_state, reward, _ = env.step(i)\n",
    "    env.stepCounter = 2\n",
    "    if reward < 0.1:\n",
    "        reward = 1\n",
    "    elif reward < 0.5:\n",
    "        reward = 0\n",
    "    else:\n",
    "        reward = -1\n",
    "    if reward == 1:\n",
    "        #best_actions.append(i)\n",
    "        print(\"[{}]\".format(i), referenceLine[2].numpy(), next_state.getCoordinate().numpy(), reward)\n",
    "#print(best_actions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "state = TractographyState(torch.FloatTensor(referenceLine[0]), env.interpolateDWIatState)\n",
    "coordinates = state.getCoordinate()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(referenceLine[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(referenceLine[0])\n",
    "print(referenceLine[70])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "state = TractographyState(referenceLine[69], env.interpolateDWIatState)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "shape = env.reset().getValue().reshape(-1).shape[0]\n",
    "print(shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "state = torch.FloatTensor(state.getValue()).unsqueeze(0).to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "q_vals = agent.main_dqn(state)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(state.getValue().shape)\n",
    "shape = state.getValue().shape\n",
    "shape = np.prod(np.array(shape))\n",
    "print(shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "state = TractographyState(referenceLine[70], env.interpolateDWIatState)\n",
    "qry_pt = torch.FloatTensor(state.getCoordinate()).view(-1,3)\n",
    "distance = torch.min(torch.sum( (referenceLine - qry_pt)**2, dim =1 ))\n",
    "qry_pt = torch.FloatTensor(state.getCoordinate()).view(3)\n",
    "distance_terminal = torch.sum( (referenceLine[-1,:] - qry_pt)**2 )\n",
    "\n",
    "#print(distance)\n",
    "#print(distance_terminal)\n",
    "reward = (torch.tanh(-distance+5.3) + 2*torch.tanh(-distance_terminal+5.3))/2\n",
    "print(reward)\n",
    "\n",
    "print(torch.tanh(-distance+5.3))\n",
    "print(torch.tanh(-distance_terminal+5.3))\n",
    "\n",
    "reward += 200/20 * reward.sign()\n",
    "print(reward)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(torch.tanh(-distance_terminal+5.3)+2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "state = TractographyState([32., 84., 94.], env.interpolateDWIatState)\n",
    "qry_pt = torch.FloatTensor(state.getCoordinate()).view(-1,3)\n",
    "distance = torch.min(torch.sum( (referenceLine - qry_pt)**2, dim =1 ))\n",
    "print(torch.tanh(-distance+5.3))\n",
    "qry_pt = torch.FloatTensor(state.getCoordinate()).view(3)\n",
    "distance = torch.sum( (referenceLine[-1,:] - qry_pt)**2 )\n",
    "print(-distance)\n",
    "print(torch.tanh(-distance)+2)\n",
    "#print(torch.where(distance < env.maxL2dist_to_terminalState, 1, 0 ))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(-1.5 + 5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "qry_pt = torch.FloatTensor(state.getCoordinate()).view(3)\n",
    "distance = torch.sum( (referenceLine[-1,:] - qry_pt)**2 )\n",
    "print(round(-distance.item(),4))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Init agent\")\n",
    "#memory = ReplayMemory(size=replay_memory_size)\n",
    "state = env.reset()\n",
    "agent = Agent(n_actions=n_actions, inp_size=state.getValue().shape, device=device, hidden=256, agent_history_length=agent_history_length, memory_size=replay_memory_size, learning_rate=learning_rate)\n",
    "\n",
    "print(\"Init epsilon-greedy action scheduler\")\n",
    "action_scheduler = Action_Scheduler(num_actions=n_actions, max_steps=max_steps, eps_annealing_steps=100000, replay_memory_start_size=replay_memory_size, model=agent.main_dqn)\n",
    "\n",
    "step_counter = 0\n",
    "    \n",
    "eps_rewards = []\n",
    "\n",
    "print(\"Start training...\")\n",
    "while step_counter < max_steps:\n",
    "    epoch_step = 0\n",
    "\n",
    "######## fill memory begins here\n",
    "    while epoch_step < evaluate_every:  # To Do implement evaluation\n",
    "        state = env.reset()\n",
    "        episode_reward_sum = 0\n",
    "        \n",
    "        #fill replay memory while interacting with env\n",
    "        for episode_counter in range(max_episode_length):\n",
    "            # get action with epsilon-greedy strategy       \n",
    "            action = action_scheduler.get_action(step_counter, torch.FloatTensor(state.getValue()).to(device).unsqueeze(0))\n",
    "                    \n",
    "            next_state, reward, terminal = env.step(action)\n",
    "\n",
    "            if reward >= 1:\n",
    "                reward = 10\n",
    "            elif reward > -0.05:\n",
    "                reward = 1\n",
    "            \n",
    "            if episode_counter == max_episode_length-1:\n",
    "                reward = -100\n",
    "                terminal = True\n",
    "            # increase counter\n",
    "            step_counter += 1\n",
    "            epoch_step += 1\n",
    "\n",
    "            # accumulate reward for current episode\n",
    "            episode_reward_sum += reward\n",
    "\n",
    "\n",
    "            agent.replay_memory.add_experience(action=action,\n",
    "                                state=state.getValue(),\n",
    "                                reward=reward,\n",
    "                                new_state=next_state.getValue(),\n",
    "                                terminal=terminal)\n",
    "\n",
    "\n",
    "            state = next_state\n",
    "\n",
    "        \n",
    "\n",
    "            ####### optimization is happening here\n",
    "            if step_counter > replay_memory_size:\n",
    "                loss = agent.optimize()\n",
    "\n",
    "\n",
    "            ####### target network update\n",
    "            if step_counter > replay_memory_size and step_counter % network_update_every == 0:\n",
    "                agent.target_dqn.load_state_dict(agent.main_dqn.state_dict())\n",
    "            \n",
    "            # if episode ended before maximum step\n",
    "            if terminal:\n",
    "                terminal = False\n",
    "                state = env.reset()\n",
    "                break\n",
    "                \n",
    "        eps_rewards.append(episode_reward_sum)\n",
    "        \n",
    "        if len(eps_rewards) % 10 == 0:\n",
    "            with open(path+'/logs/rewards.dat', 'a') as reward_file:\n",
    "                print(\"[{}] {}, {}\".format(len(eps_rewards), step_counter, np.mean(eps_rewards[-100:])), file=reward_file)\n",
    "            print(\"[{}] {}, {}\".format(len(eps_rewards), step_counter, np.mean(eps_rewards[-100:])) )\n",
    "    torch.save(agent.main_dqn.state_dict(), path+'/checkpoints/fibre_agent_{}_reward_{:.2f}.pth'.format(step_counter, np.mean(eps_rewards[-100:])))\n",
    "########## evaluation starting here\n",
    "    eval_rewards = []\n",
    "    for _ in range(eval_runs):\n",
    "        eval_steps = 0\n",
    "        state = env.reset()\n",
    "        eval_episode_reward = 0\n",
    "        while eval_steps < max_episode_length:\n",
    "            action = action_scheduler.get_action(step_counter, torch.FloatTensor(state.getValue()).to(device).unsqueeze(0), evaluation=True)\n",
    "\n",
    "            next_state, reward, terminal = env.step(action)\n",
    "\n",
    "            eval_steps += 1\n",
    "            eval_episode_reward += reward\n",
    "            state = next_state\n",
    "\n",
    "            if terminal:\n",
    "                terminal = False\n",
    "                break\n",
    "\n",
    "        eval_rewards.append(eval_episode_reward)\n",
    "    \n",
    "    print(\"Evaluation score:\", np.mean(eval_rewards))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#!mkdir -p 'checkpoints/'\n",
    "#torch.save(agent.main_dqn.state_dict(), 'checkpoints/fiber_agent_{}_reward_{:.2f}.pth'.format(step_counter, np.mean(rewards[-100:])))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "CONDA (atari)",
   "language": "python",
   "name": "atari"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
