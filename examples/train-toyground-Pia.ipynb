{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import gym\n",
    "import numpy as np\n",
    "\n",
    "\n",
    "import os, sys\n",
    "sys.path.insert(0,'..')\n",
    "\n",
    "from collections import deque \n",
    "\n",
    "from dfibert.tracker.nn.rl import Agent, Action_Scheduler\n",
    "import dfibert.envs.RLtractEnvironment as RLTe\n",
    "from dfibert.envs._state import TractographyState"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test on Lunar Lander to check functionality of agent\n",
    "#env = gym.make('LunarLander-v2')\n",
    "#n_actions= env.action_space.n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "max_steps = 3000000\n",
    "replay_memory_size = 3000000\n",
    "agent_history_length = 1\n",
    "evaluate_every = 20000\n",
    "eval_runs = 5\n",
    "network_update_every = 1000\n",
    "start_learning = 5000\n",
    "\n",
    "max_episode_length = 200\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "\n",
    "learning_rate = 0.001"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading precomputed streamlines (data/HCP307200_DTI_smallSet.vtk) for ID 100307\n"
     ]
    }
   ],
   "source": [
    "env = RLTe.RLtractEnvironment(device = 'cpu')\n",
    "n_actions = env.action_space.n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def init_transition():\n",
    "    state = env.reset()\n",
    "    transition = deque(maxlen=12)\n",
    "    while len(transition) < 12:\n",
    "        for i in range(len(state.getCoordinate())):\n",
    "            transition.append(state.getCoordinate()[i].item())\n",
    "    return transition\n",
    "\n",
    "def add_to_transition(state, transition):\n",
    "    for i in range(len(state.getCoordinate())):\n",
    "            transition.append(state.getCoordinate()[i].item())\n",
    "    return transition"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "deque([73.6513442993164, 107.88105773925781, 93.29415130615234, 73.6513442993164, 107.88105773925781, 93.29415130615234, 73.6513442993164, 107.88105773925781, 93.29415130615234, 73.6513442993164, 107.88105773925781, 93.29415130615234], maxlen=12)\n",
      "[ 73.6513443  107.88105774  93.29415131  73.6513443  107.88105774\n",
      "  93.29415131  73.6513443  107.88105774  93.29415131  74.58926433\n",
      " 108.1431821   93.52130066]\n"
     ]
    }
   ],
   "source": [
    "transition = init_transition()\n",
    "print(transition)\n",
    "next_state, _, _ = env.step(42)\n",
    "next_transition = add_to_transition(next_state, transition)\n",
    "print(np.array(next_transition))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[-13.6672,  -7.8499,  -5.0823,  14.6562,  -2.7858,  -0.6165,  10.3545,\n",
      "          -2.1052,  -6.4893,  -6.9334,  -1.0502,  -5.7020, -10.8006,  -2.3180,\n",
      "         -11.9924,  -0.8486,   3.1842,  -3.2134,   2.1775,  -0.9403,   3.2331,\n",
      "           1.7278,  -3.3707, -10.6123,   8.4084, -17.0882,  -3.0332,  -3.0189,\n",
      "          13.1050,  -5.0179,   7.5423,   4.0707,  -8.9227,  -2.1233,  10.4102,\n",
      "         -17.7410,  12.1755,  -0.2614,   4.6796,   9.3646,   5.0021,  10.0463,\n",
      "          -2.7939,  -9.3681,  -5.5738,  -3.8558, -13.2895,   8.2217,   1.9178,\n",
      "           9.1176,  -4.2744,   8.5829,   9.8390,   4.5286,  -8.5778,   4.4940,\n",
      "          -2.8302,  18.6438,  -1.0051,   1.0747,  -9.0311,   2.8591,   9.1929,\n",
      "          -3.2381,  -1.0803,  -8.8236,  -7.3553, -10.1507, -11.5579,   7.1048,\n",
      "          -4.4199,   5.1859,  13.8964,   1.0838,  -7.0013,  -1.5684,   3.1538,\n",
      "          -3.0316,   8.9216,   7.6663,   3.3042,  -7.4507,  14.3557,  -6.6734,\n",
      "         -13.6536,  -1.9597,  -6.0354,  -0.6945,  -5.4558,  -7.2604,  -2.2367,\n",
      "           5.1702,   1.4439,  -1.3349, -13.6596,   1.7791,   7.1995,  -4.0517,\n",
      "          16.7861, -15.0391]], device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor([[-13.6672,  -7.8499,  -5.0823,  14.6562,  -2.7858,  -0.6165,  10.3545,\n",
      "          -2.1052,  -6.4893,  -6.9334,  -1.0502,  -5.7020, -10.8006,  -2.3180,\n",
      "         -11.9924,  -0.8486,   3.1842,  -3.2134,   2.1775,  -0.9403,   3.2331,\n",
      "           1.7278,  -3.3707, -10.6123,   8.4084, -17.0882,  -3.0332,  -3.0189,\n",
      "          13.1050,  -5.0179,   7.5423,   4.0707,  -8.9227,  -2.1233,  10.4102,\n",
      "         -17.7410,  12.1755,  -0.2614,   4.6796,   9.3646,   5.0021,  10.0463,\n",
      "          -2.7939,  -9.3681,  -5.5738,  -3.8558, -13.2895,   8.2217,   1.9178,\n",
      "           9.1176,  -4.2744,   8.5829,   9.8390,   4.5286,  -8.5778,   4.4940,\n",
      "          -2.8302,  18.6438,  -1.0051,   1.0747,  -9.0311,   2.8591,   9.1929,\n",
      "          -3.2381,  -1.0803,  -8.8236,  -7.3553, -10.1507, -11.5579,   7.1048,\n",
      "          -4.4199,   5.1859,  13.8964,   1.0838,  -7.0013,  -1.5684,   3.1538,\n",
      "          -3.0316,   8.9216,   7.6663,   3.3042,  -7.4507,  14.3557,  -6.6734,\n",
      "         -13.6536,  -1.9597,  -6.0354,  -0.6945,  -5.4558,  -7.2604,  -2.2367,\n",
      "           5.1702,   1.4439,  -1.3349, -13.6596,   1.7791,   7.1995,  -4.0517,\n",
      "          16.7861, -15.0391]], device='cuda:0', grad_fn=<AddBackward0>)\n"
     ]
    }
   ],
   "source": [
    "agent = Agent(n_actions=n_actions, inp_size=np.array(transition).shape, device=device, hidden=10, agent_history_length=agent_history_length, memory_size=replay_memory_size, batch_size=32, learning_rate=learning_rate)\n",
    "#print(agent.main_dqn(torch.FloatTensor([np.array(transition)]).to(device)))\n",
    "#print(agent.target_dqn(torch.FloatTensor([np.array(transition)]).to(device)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1, 8])\n",
      "tensor([[0.2314, 0.2480, 0.3690, 0.1016]], device='cuda:0',\n",
      "       grad_fn=<AddBackward0>)\n",
      "tensor([[0.2314, 0.2480, 0.3690, 0.1016]], device='cuda:0',\n",
      "       grad_fn=<AddBackward0>)\n",
      "[ 0.01214266  1.4017366   0.60866606 -0.2167907  -0.01216728 -0.1019486\n",
      "  0.          0.        ] 0.0867171307642434 False\n",
      "tensor([[0.2314, 0.2480, 0.3690, 0.1016]], device='cuda:0',\n",
      "       grad_fn=<AddBackward0>)\n",
      "tensor([0.2480], device='cuda:0', grad_fn=<IndexBackward>)\n",
      "tensor([2], device='cuda:0')\n",
      "tensor([0.3673], device='cuda:0', grad_fn=<IndexBackward>)\n",
      "tensor([0.3673], device='cuda:0', grad_fn=<IndexPutBackward>)\n",
      "tensor([0.4503], device='cuda:0')\n",
      "tensor(0.0205, device='cuda:0', grad_fn=<SmoothL1LossBackward>)\n",
      "tensor([[0.2505, 0.2896, 0.3830, 0.1175]], device='cuda:0',\n",
      "       grad_fn=<AddBackward0>)\n",
      "tensor([[0.2314, 0.2480, 0.3690, 0.1016]], device='cuda:0',\n",
      "       grad_fn=<AddBackward0>)\n"
     ]
    }
   ],
   "source": [
    "# Debugging the optimization of the agent\n",
    "\n",
    "state = env.reset()\n",
    "state = torch.tensor([state]).to(device).float()\n",
    "print(state.shape)\n",
    "print(agent.main_dqn(state))\n",
    "print(agent.target_dqn(state))\n",
    "\n",
    "action = 1\n",
    "\n",
    "next_state, reward, done, _ = env.step(action)\n",
    "print(next_state, reward, done)\n",
    "\n",
    "action = torch.tensor([action]).to(device)\n",
    "next_state = torch.tensor([next_state]).float().to(device)\n",
    "reward = torch.tensor([reward]).float().to(device)\n",
    "done = torch.BoolTensor([done]).to(device)\n",
    "state_action_values = agent.main_dqn(state)\n",
    "print(state_action_values)\n",
    "state_action_values = state_action_values[0][action]\n",
    "print(state_action_values)\n",
    "\n",
    "next_state_actions = agent.main_dqn(next_state).max(1)[1]\n",
    "print(next_state_actions)\n",
    "next_state_values = agent.target_dqn(next_state)[0][next_state_actions]\n",
    "print(next_state_values)\n",
    "next_state_values[done] = 0.0\n",
    "print(next_state_values)\n",
    "expected_state_action_values = next_state_values.detach() * 0.99 + reward\n",
    "print(expected_state_action_values)\n",
    "\n",
    "agent.optimizer.zero_grad()\n",
    "loss = torch.nn.SmoothL1Loss()(state_action_values, expected_state_action_values)\n",
    "print(loss)\n",
    "loss.backward()\n",
    "agent.optimizer.step()\n",
    "\n",
    "print(agent.main_dqn(state))\n",
    "print(agent.target_dqn(state))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Start training...\n",
      "2026, done 1000 episodes, -99.04863057134786, current eps 1 0\n",
      "4028, done 2000 episodes, -98.5193540741912, current eps 1 0\n",
      "6120, done 3000 episodes, -97.86870632963836, current eps 0.9992225333333332 0\n",
      "8228, done 4000 episodes, -96.509176463649, current eps 0.9854502666666666 0\n",
      "10312, done 5000 episodes, -97.61193305941072, current eps 0.9718347999999999 0\n",
      "12455, done 6000 episodes, -98.19855668857029, current eps 0.9578338666666666 0\n",
      "14558, done 7000 episodes, -98.57894256985429, current eps 0.9440942666666665 0\n",
      "16713, done 8000 episodes, -96.39045552559135, current eps 0.9300149333333332 0\n",
      "18971, done 9000 episodes, -97.50933823752725, current eps 0.9152626666666666 0\n",
      "Evaluation score: -88.40993203757138\n",
      "0 of 5 episodes ended close to / at the final state.\n",
      "21262, done 10000 episodes, -97.43829877726984, current eps 0.9002948 0\n",
      "23559, done 11000 episodes, -97.41985264422888, current eps 0.8852877333333332 0\n",
      "25931, done 12000 episodes, -97.62805719177561, current eps 0.8697906666666666 0\n",
      "28355, done 13000 episodes, -96.47361618476262, current eps 0.8539538666666666 0\n",
      "30823, done 14000 episodes, -95.66832908880976, current eps 0.8378295999999998 0\n",
      "33274, done 15000 episodes, -94.54199532657263, current eps 0.8218163999999999 0\n",
      "35804, done 16000 episodes, -96.23994030655622, current eps 0.8052870666666666 0\n",
      "38392, done 17000 episodes, -96.30560891244393, current eps 0.7883787999999999 0\n",
      "Evaluation score: -79.79649826249667\n",
      "0 of 5 episodes ended close to / at the final state.\n",
      "41126, done 18000 episodes, -94.80911674473678, current eps 0.7705166666666665 0\n",
      "43928, done 19000 episodes, -94.00499242552927, current eps 0.7522102666666666 0\n",
      "46765, done 20000 episodes, -92.66946101681502, current eps 0.7336752 0\n",
      "49635, done 21000 episodes, -93.83123092557368, current eps 0.7149245333333332 0\n",
      "52725, done 22000 episodes, -92.89820210264742, current eps 0.6947365333333333 0\n",
      "55738, done 23000 episodes, -93.90005723894765, current eps 0.6750516 0\n",
      "58980, done 24000 episodes, -93.19935821580742, current eps 0.6538705333333332 0\n",
      "Evaluation score: -78.00293923717577\n",
      "0 of 5 episodes ended close to / at the final state.\n",
      "62338, done 25000 episodes, -91.2569063566423, current eps 0.6319315999999999 0\n",
      "65561, done 26000 episodes, -93.94786386504634, current eps 0.6108746666666666 0\n",
      "69172, done 27000 episodes, -91.80526849378211, current eps 0.5872827999999999 0\n",
      "72858, done 28000 episodes, -87.80276129834867, current eps 0.5632009333333332 0\n",
      "76757, done 29000 episodes, -92.3108011463912, current eps 0.5377274666666666 0\n",
      "Evaluation score: -72.7982645931936\n",
      "0 of 5 episodes ended close to / at the final state.\n",
      "80802, done 30000 episodes, -89.26316701019574, current eps 0.5113001333333332 0\n",
      "85222, done 31000 episodes, -85.80979791691536, current eps 0.48242279999999993 0\n",
      "89814, done 32000 episodes, -86.5102092344835, current eps 0.45242173333333324 0\n",
      "94606, done 33000 episodes, -82.41132536583613, current eps 0.4211139999999999 0\n",
      "99656, done 34000 episodes, -86.57704597546122, current eps 0.38812066666666656 0\n",
      "Evaluation score: -79.2723645245321\n",
      "0 of 5 episodes ended close to / at the final state.\n",
      "104982, done 35000 episodes, -84.25249338997227, current eps 0.35332413333333323 0\n",
      "110664, done 36000 episodes, -85.70840837297001, current eps 0.31620173333333323 0\n",
      "116739, done 37000 episodes, -81.03236548657587, current eps 0.27651173333333323 0\n",
      "Evaluation score: -79.0298422010487\n",
      "0 of 5 episodes ended close to / at the final state.\n",
      "123383, done 38000 episodes, -80.44559089900085, current eps 0.23310426666666662 0\n",
      "130361, done 39000 episodes, -81.38651680132844, current eps 0.1875146666666666 0\n",
      "137865, done 40000 episodes, -81.28232027472582, current eps 0.13848853333333322 0\n",
      "Evaluation score: -77.85789459020899\n",
      "0 of 5 episodes ended close to / at the final state.\n",
      "145777, done 41000 episodes, -75.09089431662595, current eps 0.0867967999999999 0\n",
      "153788, done 42000 episodes, -77.96680891235532, current eps 0.034458266666666626 0\n",
      "Evaluation score: -73.31355673684966\n",
      "0 of 5 episodes ended close to / at the final state.\n",
      "162405, done 43000 episodes, -75.86470477163235, current eps 0.019977482419127987 0\n",
      "171305, done 44000 episodes, -70.45227207989039, current eps 0.01994618846694796 0\n",
      "Evaluation score: -74.25221158230734\n",
      "0 of 5 episodes ended close to / at the final state.\n",
      "180570, done 45000 episodes, -72.4315357532662, current eps 0.019913611111111108 0\n",
      "189935, done 46000 episodes, -70.12012253301877, current eps 0.019880682137834036 0\n",
      "198912, done 47000 episodes, -74.75772008755838, current eps 0.019849117440225033 0\n",
      "Evaluation score: -79.26760645617603\n",
      "0 of 5 episodes ended close to / at the final state.\n",
      "208323, done 48000 episodes, -73.78520862301872, current eps 0.019816026722925456 0\n",
      "217714, done 49000 episodes, -76.11347303889272, current eps 0.019783006329113922 0\n",
      "Evaluation score: -78.41017995282944\n",
      "0 of 5 episodes ended close to / at the final state.\n",
      "227083, done 50000 episodes, -73.87990497595591, current eps 0.01975006329113924 0\n",
      "236465, done 51000 episodes, -76.51159844741254, current eps 0.019717074542897325 0\n",
      "Evaluation score: -59.23299652499334\n",
      "0 of 5 episodes ended close to / at the final state.\n",
      "245900, done 52000 episodes, -72.15868115350173, current eps 0.019683899437412094 0\n",
      "255072, done 53000 episodes, -73.18793682032866, current eps 0.019651649085794653 0\n",
      "Evaluation score: -80.34398588057532\n",
      "0 of 5 episodes ended close to / at the final state.\n",
      "264719, done 54000 episodes, -69.87136266503846, current eps 0.019617728551336144 0\n",
      "274884, done 55000 episodes, -75.19116453820385, current eps 0.01958198663853727 0\n",
      "Evaluation score: -58.78186897380003\n",
      "0 of 5 episodes ended close to / at the final state.\n",
      "284791, done 56000 episodes, -73.5932375621403, current eps 0.019547151898734176 0\n",
      "294595, done 57000 episodes, -75.56321632158365, current eps 0.019512679324894512 0\n",
      "Evaluation score: -86.34031102096012\n",
      "0 of 5 episodes ended close to / at the final state.\n",
      "304318, done 58000 episodes, -76.62389029201705, current eps 0.019478491561181432 0\n",
      "314765, done 59000 episodes, -76.48186339871495, current eps 0.019441758087201125 0\n",
      "Evaluation score: -78.70926904382726\n",
      "0 of 5 episodes ended close to / at the final state.\n",
      "325351, done 60000 episodes, -74.98810828647319, current eps 0.0194045358649789 0\n",
      "335846, done 61000 episodes, -75.38539481370407, current eps 0.019367633614627282 0\n",
      "Evaluation score: -87.18022017160433\n",
      "0 of 5 episodes ended close to / at the final state.\n",
      "346460, done 62000 episodes, -71.91435579460484, current eps 0.0193303129395218 0\n",
      "357638, done 63000 episodes, -71.0539231134932, current eps 0.019291009142053443 0\n",
      "Evaluation score: -67.66212768621308\n",
      "0 of 5 episodes ended close to / at the final state.\n",
      "368870, done 64000 episodes, -66.64612375026401, current eps 0.01925151547116737 0\n"
     ]
    }
   ],
   "source": [
    "#state = env.reset()\n",
    "#agent = Agent(n_actions=n_actions, inp_size=state.shape, device=device, hidden=10, agent_history_length=agent_history_length, memory_size=replay_memory_size, batch_size=32, learning_rate=learning_rate)\n",
    "\n",
    "transition = init_transition()\n",
    "agent = Agent(n_actions=n_actions, inp_size=np.array(transition).shape, device=device, hidden=10, agent_history_length=agent_history_length, memory_size=replay_memory_size, batch_size=256)\n",
    "action_scheduler = Action_Scheduler(num_actions=n_actions, max_steps=max_steps, eps_annealing_steps=150000, eps_final=0.02, replay_memory_start_size=start_learning+1000, model=agent.main_dqn)\n",
    "\n",
    "step_counter = 0\n",
    "\n",
    "eps_rewards = []\n",
    "\n",
    "\n",
    "\n",
    "print(\"Start training...\")\n",
    "while step_counter < max_steps:\n",
    "    epoch_step = 0\n",
    "    #agent.main_dqn.train()\n",
    "######## fill memory begins here\n",
    "    while (epoch_step < evaluate_every) or (step_counter < start_learning):\n",
    "        #state = env.reset()\n",
    "        transition = init_transition()\n",
    "\n",
    "        episode_reward_sum = 0\n",
    "        terminal = False\n",
    "        #fill replay memory while interacting with env\n",
    "        #for episode_counter in range(max_episode_length):\n",
    "        episode_step_counter = 0\n",
    "        positive_run = 0\n",
    "\n",
    "        while not terminal:\n",
    "            # get action with epsilon-greedy strategy       \n",
    "            action = action_scheduler.get_action(step_counter, torch.FloatTensor([np.array(transition)]).to(device))\n",
    "            \n",
    "            next_state, reward, terminal = env.step(action)\n",
    "            next_transition = add_to_transition(next_state, transition)\n",
    "\n",
    "            step_counter += 1\n",
    "            epoch_step += 1\n",
    "            episode_step_counter += 1\n",
    "            \n",
    "\n",
    "            # accumulate reward for current episode\n",
    "            episode_reward_sum += reward\n",
    "\n",
    "\n",
    "            agent.replay_memory.add_experience(action=action,\n",
    "                                state=np.array(transition),\n",
    "                                reward=reward,\n",
    "                                new_state=np.array(next_transition),\n",
    "                                terminal=terminal)\n",
    "\n",
    "\n",
    "            #state = next_state\n",
    "            transition = next_transition\n",
    "\n",
    "\n",
    "\n",
    "            ####### optimization is happening here\n",
    "            if step_counter > start_learning:\n",
    "                #if reward > 0.:\n",
    "                #    print(\"reward was positive: \", reward)\n",
    "                loss = agent.optimize()\n",
    "\n",
    "\n",
    "            ####### target network update\n",
    "            if step_counter > start_learning and step_counter % network_update_every == 0:\n",
    "                #print(\"Update net\")\n",
    "                #print(agent.main_dqn(torch.tensor(state).to(device).unsqueeze(0)))\n",
    "                #print(agent.target_dqn(torch.tensor(state).to(device).unsqueeze(0)))\n",
    "                agent.target_dqn.load_state_dict(agent.main_dqn.state_dict())\n",
    "\n",
    "            # if episode ended before maximum step\n",
    "            if terminal:\n",
    "                terminal = False\n",
    "                #state = env.reset()\n",
    "                transition = init_transition()\n",
    "                #eps_steps[len(eps_rewards)%10] = episode_step_counter\n",
    "                #print(\"Positive rewards of this episode: \", positive_run)\n",
    "                break\n",
    "\n",
    "        eps_rewards.append(episode_reward_sum)\n",
    "\n",
    "        if len(eps_rewards) % 1000 == 0:\n",
    "            #with open(path+'/logs/rewards.dat', 'a') as reward_file:\n",
    "                #print(\"[{}] {}, {}\".format(len(eps_rewards), step_counter, np.mean(eps_rewards[-100:])), file=reward_file)\n",
    "            print(\"{}, done {} episodes, {}, current eps {}\".format(step_counter, len(eps_rewards), np.mean(eps_rewards[-100:]), action_scheduler.eps_current), env.points_visited)\n",
    "    #torch.save(agent.main_dqn.state_dict(), path+'/checkpoints/fibre_agent_{}_reward_{:.2f}.pth'.format(step_counter, np.mean(eps_rewards[-100:])))\n",
    "\n",
    "########## evaluation starting here\n",
    "    eval_rewards = []\n",
    "    #agent.main_dqn.eval()\n",
    "    for _ in range(eval_runs):\n",
    "        eval_steps = 0\n",
    "        #state = env.reset()\n",
    "        transition = init_transition()\n",
    "        eval_episode_reward = 0\n",
    "        episode_final = 0\n",
    "        while eval_steps < max_episode_length:\n",
    "            action = action_scheduler.get_action(step_counter, torch.FloatTensor([np.array(transition)]).to(device), evaluation=True)\n",
    "\n",
    "            next_state, reward, terminal = env.step(action)\n",
    "            #next_state = next_state\n",
    "            next_transition = add_to_transition(next_state, transition)\n",
    "\n",
    "            eval_steps += 1\n",
    "            eval_episode_reward += reward\n",
    "            #state = next_state\n",
    "            transition = next_transition\n",
    "            if terminal:\n",
    "                terminal = False\n",
    "                if reward == 100:\n",
    "                    episode_final += 1\n",
    "                break\n",
    "\n",
    "        eval_rewards.append(eval_episode_reward)\n",
    "\n",
    "    print(\"Evaluation score:\", np.mean(eval_rewards))\n",
    "    print(\"{} of {} episodes ended close to / at the final state.\".format(episode_final, eval_runs))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[74.9079, 68.6542,  6.6088],\n",
      "        [75.0415, 68.9379,  7.3448],\n",
      "        [75.1012, 69.2937,  8.0589],\n",
      "        [75.1610, 69.6495,  8.7729],\n",
      "        [75.2207, 70.0053,  9.4869],\n",
      "        [75.3279, 70.4488, 10.1440]])\n",
      "tensor([74.9079, 68.6542,  6.6088])\n",
      "0 76 [74.11087027 69.11205515  6.2149459 ] [74.90789   68.65422    6.6088324] -0.1\n",
      "1 66 [74.11087027 69.11205515  6.2149459 ] [75.04146  68.937874  7.344835] -100\n",
      "Evaluation score: -100.1\n"
     ]
    }
   ],
   "source": [
    "eval_rewards = []\n",
    "all_distances = []\n",
    "all_states = []\n",
    "#agent.main_dqn.eval()\n",
    "for _ in range(1):\n",
    "    eval_steps = 0\n",
    "    state = env.reset()\n",
    "    print(env.referenceStreamline_ijk[:6])\n",
    "    print(state.getCoordinate())\n",
    "    all_states.append(state.getCoordinate())\n",
    "    transition = init_transition()\n",
    "    eval_episode_reward = 0\n",
    "    episode_final = 0\n",
    "    \n",
    "    while eval_steps < max_episode_length:\n",
    "        action = action_scheduler.get_action(step_counter, torch.FloatTensor([np.array(transition)]).to(device), evaluation=True)\n",
    "\n",
    "        next_state, reward, terminal = env.step(action)\n",
    "        #next_state = next_state\n",
    "        next_transition = add_to_transition(next_state, transition)\n",
    "        #reward = 1 + (1+(reward/10))\n",
    "        #if reward > 1:\n",
    "        #    reward = 1\n",
    "        #elif reward > 0.:\n",
    "        #    reward = 0\n",
    "        #else:\n",
    "        #    reward = -1\n",
    "        eval_episode_reward += reward\n",
    "        print(eval_steps, action, next_state.getCoordinate().numpy(), env.referenceStreamline_ijk[np.min([eval_steps,len(env.referenceStreamline_ijk)-1])].numpy(), reward)\n",
    "        eval_steps += 1\n",
    "        all_distances.append(reward)\n",
    "        all_states.append(next_state.getCoordinate())\n",
    "        \n",
    "        #state = next_state\n",
    "        transition = next_transition\n",
    "        if terminal:\n",
    "            terminal = False\n",
    "            #if reward > 0.9:\n",
    "            #    episode_final += 1\n",
    "            break\n",
    "\n",
    "    eval_rewards.append(eval_episode_reward)\n",
    "\n",
    "print(\"Evaluation score:\", np.min(eval_rewards))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "71\n"
     ]
    }
   ],
   "source": [
    "optimal_steps =  [80, 88, 54, 96, 100, 67, 83, 75, 83, 75, 100, 83, 70, 67, 59, 100, 67, 59, 59, 59, 51, 100, 59, 56, 51, 61, 100, 66, 71, 66, 71, 71, 100, 71, 71, 71, 71, 100, 92, 84, 84, 38, 100, 97, 97, 97, 38, 100, 97, 30, 43, 43, 48, 100, 94, 81, 94, 35, 97, 100, 35, 22, 35, 35, 6, 100, 19, 3, 16, 3, 21, 100, 21, 16, 34, 21, 98, 34, 100, 39, 93, 39, 72, 72, 100, 69, 100]\n",
    "transition = init_transition()\n",
    "referenceLine = env.referenceStreamline_ijk\n",
    "print(len(referenceLine))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "80 -0.09999999999999964\n"
     ]
    }
   ],
   "source": [
    "#action = action_scheduler.get_action(step_counter, torch.FloatTensor([np.array(transition)]).to(device), evaluation=True)\n",
    "next_state, reward, terminal = env.step(88)\n",
    "next_transition = add_to_transition(next_state, transition)\n",
    "print(action, reward)\n",
    "transition = next_transition"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "State:  [ 73.651344 107.88106   93.29415 ]\n",
      "Next State:  [ 74.56195007 107.80595503  92.88775652]\n",
      "7.450580596923828e-09\n"
     ]
    }
   ],
   "source": [
    "# Debugging the reward function\n",
    "referenceLine = env.referenceStreamline_ijk\n",
    "stepCounter = 0\n",
    "maxSteps=200\n",
    "state = env.reset()\n",
    "print(\"State: \", state.getCoordinate().numpy())\n",
    "next_state, _, terminal = env.step(80)\n",
    "print(\"Next State: \", next_state.getCoordinate().numpy())\n",
    "\n",
    "def lineseg_dist(p, a, b):\n",
    "\n",
    "    # normalized tangent vector\n",
    "    d = np.divide(b - a, np.linalg.norm(b - a))\n",
    "\n",
    "    # signed parallel distance components\n",
    "    s = np.dot(a - p, d)\n",
    "    t = np.dot(p - b, d)\n",
    "\n",
    "    # clamped parallel distance\n",
    "    h = np.maximum.reduce([s, t, 0])\n",
    "\n",
    "    # perpendicular distance component\n",
    "    c = np.cross(p - a, d)\n",
    "\n",
    "    return np.hypot(h, np.linalg.norm(c))\n",
    "\n",
    "distance = lineseg_dist(referenceLine[86].numpy(), referenceLine[85].numpy(), referenceLine[86].numpy())\n",
    "print(distance)\n",
    "\n",
    "#print(\"Diff: \", next_state.getCoordinate().numpy()-state.getCoordinate().numpy())\n",
    "#qry_pt = next_state.getCoordinate().view(-1,3)\n",
    "#print(\"Reference next state: \", referenceLine[stepCounter+1])\n",
    "#print(\"Diff to reference state: \", referenceLine[stepCounter+1]-next_state.getCoordinate().numpy())\n",
    "#distance = torch.min(torch.sum((referenceLine[np.min([stepCounter+1, maxSteps-1])] - qry_pt)**2, dim=1))\n",
    "#print(distance)\n",
    "#reward = torch.tanh(-distance+5.3)\n",
    "\n",
    "#if distance == -1:\n",
    "#    reward = 0.5\n",
    "#elif distance < 0.8:\n",
    "#    reward = 1+ (1-distance)\n",
    "#else:\n",
    "#    reward = np.max([1 - distance, -1])\n",
    "#print(reward)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.19954145509142476\n",
      "0.03981679230000309\n",
      "0.07041062249999892\n",
      "True\n"
     ]
    }
   ],
   "source": [
    "state = np.array([ 75.6, 107.95,  92.22])\n",
    "line = np.array([ 75.78847, 107.96255,  92.28433])\n",
    "\n",
    "print(np.linalg.norm(line - state, 2))\n",
    "\n",
    "sphere_dist = ((state[0] - line[0])**2 + (state[1]-line[1])**2 + (state[2]-line[2])**2)\n",
    "print(sphere_dist)\n",
    "normal_diff = np.sum(state-line)**2\n",
    "print(normal_diff)\n",
    "if sphere_dist < 0.2**2:\n",
    "    print(True)\n",
    "else:\n",
    "    print(False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Action:  100 Reward:  -0.6400096416473389\n",
      "Action:  80 Reward:  -0.3780286503520091\n",
      "Action:  75 Reward:  -0.17094774926353554\n",
      "Action:  80 Reward:  -0.06020208127816557\n",
      "Action:  75 Reward:  -0.023724592605490286\n",
      "Action:  100 Reward:  -0.023724592605490286\n",
      "Action:  62 Reward:  -0.031680450691759385\n",
      "Action:  75 Reward:  -0.10966306950569177\n",
      "Action:  83 Reward:  -0.2621558822401104\n",
      "Action:  75 Reward:  -0.4853828474102172\n",
      "Action:  83 Reward:  -0.7713330234194417\n",
      "Action:  100 Reward:  -0.7713330234194417\n",
      "Action:  83 Reward:  -1.158927472394806\n",
      "Action:  62 Reward:  -1.6468544226974164\n",
      "Action:  67 Reward:  -2.2078664481054533\n",
      "Action:  51 Reward:  -2.459970885856384\n",
      "Action:  67 Reward:  -3.0430611441644246\n",
      "Action:  100 Reward:  -3.0430611441644246\n",
      "Action:  59 Reward:  -3.7319386628026487\n",
      "Action:  59 Reward:  -4.531517914723884\n",
      "Action:  59 Reward:  -5.427621034792285\n",
      "Action:  100 Reward:  -5.427621034792285\n",
      "Action:  59 Reward:  -6.420164664306009\n",
      "Action:  56 Reward:  -7.21012573500936\n",
      "Action:  51 Reward:  -8.185668593823168\n",
      "Action:  56 Reward:  -9.264514952082235\n",
      "Action:  66 Reward:  -9.504376152250732\n",
      "Action:  100 Reward:  -9.504376152250732\n",
      "Action:  66 Reward:  -10.878316642589324\n",
      "Action:  71 Reward:  -11.684246290994608\n",
      "Action:  71 Reward:  -13.482882171224585\n",
      "Action:  79 Reward:  -15.013766894750662\n",
      "Action:  58 Reward:  -16.29778288166172\n",
      "Action:  100 Reward:  -16.29778288166172\n",
      "Action:  71 Reward:  -17.927867464472456\n",
      "Action:  71 Reward:  -19.616943063578457\n",
      "Action:  84 Reward:  -20.74882253322799\n",
      "Action:  71 Reward:  -22.68542229369059\n",
      "Action:  100 Reward:  -22.68542229369059\n",
      "Action:  92 Reward:  -24.094491148196\n",
      "Action:  84 Reward:  -26.036910111309087\n",
      "Action:  92 Reward:  -27.894909786068872\n",
      "Action:  97 Reward:  -29.22946434143986\n",
      "Action:  100 Reward:  -29.22946434143986\n",
      "Action:  97 Reward:  -30.93770942329201\n",
      "Action:  38 Reward:  -33.06379059780991\n",
      "Action:  97 Reward:  -35.48076469151409\n",
      "Action:  43 Reward:  -37.24656758094286\n",
      "Action:  38 Reward:  -39.87506653295411\n",
      "Action:  100 Reward:  -39.87506653295411\n",
      "Action:  43 Reward:  -42.07728895704025\n",
      "Action:  43 Reward:  -44.59950388329224\n",
      "Action:  89 Reward:  -46.525702788416744\n",
      "Action:  48 Reward:  -46.51577793318299\n",
      "Action:  100 Reward:  -46.51577793318299\n",
      "Action:  94 Reward:  -44.74553361569235\n",
      "Action:  81 Reward:  -46.71395822922152\n",
      "Action:  48 Reward:  -50.26025222152221\n",
      "Action:  43 Reward:  -53.83576866536265\n",
      "Action:  100 Reward:  -53.83576866536265\n",
      "Action:  35 Reward:  -57.7679173101252\n",
      "Action:  43 Reward:  -61.07110670119785\n",
      "Action:  35 Reward:  -64.29611023518841\n",
      "Action:  22 Reward:  -64.69258594426614\n",
      "Action:  27 Reward:  -67.94753644296517\n",
      "Action:  100 Reward:  -67.94753644296517\n",
      "Action:  6 Reward:  -68.60859514506335\n",
      "Action:  11 Reward:  -70.03265506052335\n",
      "Action:  3 Reward:  -69.6074991211795\n",
      "Action:  16 Reward:  -66.45768588248448\n",
      "Action:  100 Reward:  -66.45768588248448\n",
      "Action:  8 Reward:  -63.980960033928525\n",
      "Action:  29 Reward:  -63.97912872209463\n",
      "Action:  21 Reward:  -65.2877329760679\n",
      "Action:  21 Reward:  -71.00622766156863\n",
      "Action:  100 Reward:  -71.00622766156863\n",
      "Action:  34 Reward:  -75.30646175774287\n",
      "Action:  26 Reward:  -79.7251625711022\n",
      "Action:  26 Reward:  -85.7736700190284\n",
      "Action:  93 Reward:  -86.29779314738443\n",
      "Action:  39 Reward:  -89.76066176762737\n",
      "Action:  100 Reward:  -89.76066176762737\n",
      "Action:  93 Reward:  -92.76729682665923\n",
      "Action:  72 Reward:  -91.66762326274807\n",
      "Action:  77 Reward:  -91.52645978577566\n",
      "Action:  77 Reward:  -94.77110103827272\n",
      "Action:  100 Reward:  -94.77110103827272\n",
      "-3134.679829616308\n"
     ]
    }
   ],
   "source": [
    "#optimal_steps = [80, 75, 80, 75, 62, 75, 83, 96, 51, 24, 62, 62, 62, 77, 65, 64, 67, 59, 56, 83, 82, 54, 56, 53, 56, 38, 56, 84, 66, 71, 71, 64, 97, 84, 71, 71, 38, 51, 30, 92, 97, 84, 43, 79, 27, 46, 89, 25, 81, 25, 48, 43, 86, 48, 57, 14, 89, 43, 43, 19, 92, 14, 27, 9, 78, 4, 16, 3, 29, 3, 47, 6, 42, 21, 39, 5, 72, 34, 98, 88, 90, 75, 77, 59, 49, 32, 82, 100]\n",
    "eps_reward = 0\n",
    "state = env.reset()\n",
    "for i in optimal_steps:\n",
    "    next_state, reward, terminal = env.step(i)\n",
    "    state = next_state\n",
    "    eps_reward += reward.item()\n",
    "    print(\"Action: \", i, \"Reward: \", reward.item())\n",
    "print(eps_reward)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Init environment..\n",
      "Loading precomputed streamlines (data/HCP307200_DTI_smallSet.vtk) for ID 100307\n",
      "..done!\n"
     ]
    }
   ],
   "source": [
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "print(\"Init environment..\")\n",
    "env = RLTe.RLtractEnvironment(device = 'cpu')\n",
    "print(\"..done!\")\n",
    "n_actions = env.action_space.n\n",
    "#print(n_actions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([87, 3])\n"
     ]
    }
   ],
   "source": [
    "referenceLine = env.referenceStreamline_ijk\n",
    "print(referenceLine.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([47.8702, 74.8030, 26.6401])\n",
      "tensor([47.8702, 74.8030, 26.6401])\n"
     ]
    }
   ],
   "source": [
    "print(referenceLine[0])\n",
    "state = TractographyState(referenceLine[0], env.interpolateDWIatState)\n",
    "print(state.getCoordinate())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Step:  0 Action:  41 Distance:  tensor(1.3545, dtype=torch.float64)\n",
      "Step:  0 Action:  66 Distance:  tensor(1.2187, dtype=torch.float64)\n",
      "Step:  0 Action:  74 Distance:  tensor(1.5895, dtype=torch.float64)\n",
      "Step:  0 Action:  79 Distance:  tensor(1.4856, dtype=torch.float64)\n",
      "Step:  0 Action:  82 Distance:  tensor(1.2496, dtype=torch.float64)\n",
      "Step:  0 Action:  87 Distance:  tensor(1.5944, dtype=torch.float64)\n",
      "Step:  0 Action:  95 Distance:  tensor(1.5184, dtype=torch.float64)\n",
      "0 []\n",
      "Step:  1 Action:  61 Distance:  tensor(1.3162, dtype=torch.float64)\n",
      "Step:  1 Action:  66 Distance:  tensor(1.2710, dtype=torch.float64)\n",
      "Step:  1 Action:  74 Distance:  tensor(1.6272, dtype=torch.float64)\n",
      "Step:  1 Action:  79 Distance:  tensor(1.3920, dtype=torch.float64)\n",
      "Step:  1 Action:  82 Distance:  tensor(1.4070, dtype=torch.float64)\n",
      "Step:  1 Action:  87 Distance:  tensor(1.4471, dtype=torch.float64)\n",
      "Step:  1 Action:  95 Distance:  tensor(1.5094, dtype=torch.float64)\n",
      "1 []\n",
      "Step:  2 Action:  41 Distance:  tensor(1.2821, dtype=torch.float64)\n",
      "Step:  2 Action:  61 Distance:  tensor(1.2315, dtype=torch.float64)\n",
      "Step:  2 Action:  74 Distance:  tensor(1.6046, dtype=torch.float64)\n",
      "Step:  2 Action:  79 Distance:  tensor(1.3549, dtype=torch.float64)\n",
      "Step:  2 Action:  82 Distance:  tensor(1.4040, dtype=torch.float64)\n",
      "Step:  2 Action:  87 Distance:  tensor(1.4843, dtype=torch.float64)\n",
      "Step:  2 Action:  95 Distance:  tensor(1.5651, dtype=torch.float64)\n",
      "2 []\n",
      "Step:  3 Action:  41 Distance:  tensor(1.2908, dtype=torch.float64)\n",
      "Step:  3 Action:  49 Distance:  tensor(1.2627, dtype=torch.float64)\n",
      "Step:  3 Action:  61 Distance:  tensor(1.2172, dtype=torch.float64)\n",
      "Step:  3 Action:  74 Distance:  tensor(1.5797, dtype=torch.float64)\n",
      "Step:  3 Action:  79 Distance:  tensor(1.2516, dtype=torch.float64)\n",
      "Step:  3 Action:  82 Distance:  tensor(1.4621, dtype=torch.float64)\n",
      "Step:  3 Action:  87 Distance:  tensor(1.4322, dtype=torch.float64)\n",
      "Step:  3 Action:  95 Distance:  tensor(1.6009, dtype=torch.float64)\n",
      "3 []\n",
      "Step:  4 Action:  49 Distance:  tensor(1.3226, dtype=torch.float64)\n",
      "Step:  4 Action:  61 Distance:  tensor(1.3563, dtype=torch.float64)\n",
      "Step:  4 Action:  74 Distance:  tensor(1.5702, dtype=torch.float64)\n",
      "Step:  4 Action:  82 Distance:  tensor(1.5784, dtype=torch.float64)\n",
      "Step:  4 Action:  87 Distance:  tensor(1.2502, dtype=torch.float64)\n",
      "Step:  4 Action:  95 Distance:  tensor(1.5545, dtype=torch.float64)\n",
      "4 []\n",
      "Step:  5 Action:  49 Distance:  tensor(1.2380, dtype=torch.float64)\n",
      "Step:  5 Action:  61 Distance:  tensor(1.4426, dtype=torch.float64)\n",
      "Step:  5 Action:  69 Distance:  tensor(1.2523, dtype=torch.float64)\n",
      "Step:  5 Action:  74 Distance:  tensor(1.5910, dtype=torch.float64)\n",
      "Step:  5 Action:  82 Distance:  tensor(1.5806, dtype=torch.float64)\n",
      "Step:  5 Action:  87 Distance:  tensor(1.2100, dtype=torch.float64)\n",
      "Step:  5 Action:  95 Distance:  tensor(1.4956, dtype=torch.float64)\n",
      "5 []\n",
      "Step:  6 Action:  61 Distance:  tensor(1.5273, dtype=torch.float64)\n",
      "Step:  6 Action:  66 Distance:  tensor(1.3657, dtype=torch.float64)\n",
      "Step:  6 Action:  69 Distance:  tensor(1.2500, dtype=torch.float64)\n",
      "Step:  6 Action:  74 Distance:  tensor(1.6194, dtype=torch.float64)\n",
      "Step:  6 Action:  79 Distance:  tensor(1.2759, dtype=torch.float64)\n",
      "Step:  6 Action:  82 Distance:  tensor(1.5115, dtype=torch.float64)\n",
      "Step:  6 Action:  87 Distance:  tensor(1.2051, dtype=torch.float64)\n",
      "Step:  6 Action:  95 Distance:  tensor(1.3869, dtype=torch.float64)\n",
      "6 []\n",
      "Step:  7 Action:  61 Distance:  tensor(1.5700, dtype=torch.float64)\n",
      "Step:  7 Action:  66 Distance:  tensor(1.4237, dtype=torch.float64)\n",
      "Step:  7 Action:  69 Distance:  tensor(1.2798, dtype=torch.float64)\n",
      "Step:  7 Action:  74 Distance:  tensor(1.5954, dtype=torch.float64)\n",
      "Step:  7 Action:  79 Distance:  tensor(1.2693, dtype=torch.float64)\n",
      "Step:  7 Action:  82 Distance:  tensor(1.4712, dtype=torch.float64)\n",
      "Step:  7 Action:  95 Distance:  tensor(1.2862, dtype=torch.float64)\n",
      "7 []\n",
      "Step:  8 Action:  53 Distance:  tensor(1.2474, dtype=torch.float64)\n",
      "Step:  8 Action:  61 Distance:  tensor(1.6099, dtype=torch.float64)\n",
      "Step:  8 Action:  66 Distance:  tensor(1.4011, dtype=torch.float64)\n",
      "Step:  8 Action:  69 Distance:  tensor(1.3809, dtype=torch.float64)\n",
      "Step:  8 Action:  74 Distance:  tensor(1.5549, dtype=torch.float64)\n",
      "Step:  8 Action:  82 Distance:  tensor(1.4958, dtype=torch.float64)\n",
      "Step:  8 Action:  95 Distance:  tensor(1.2269, dtype=torch.float64)\n",
      "8 []\n",
      "Step:  9 Action:  53 Distance:  tensor(1.2052, dtype=torch.float64)\n",
      "Step:  9 Action:  56 Distance:  tensor(1.2501, dtype=torch.float64)\n",
      "Step:  9 Action:  61 Distance:  tensor(1.6062, dtype=torch.float64)\n",
      "Step:  9 Action:  66 Distance:  tensor(1.2593, dtype=torch.float64)\n",
      "Step:  9 Action:  69 Distance:  tensor(1.5104, dtype=torch.float64)\n",
      "Step:  9 Action:  74 Distance:  tensor(1.4608, dtype=torch.float64)\n",
      "Step:  9 Action:  82 Distance:  tensor(1.5458, dtype=torch.float64)\n",
      "9 []\n",
      "Step:  10 Action:  56 Distance:  tensor(1.2257, dtype=torch.float64)\n",
      "Step:  10 Action:  61 Distance:  tensor(1.5655, dtype=torch.float64)\n",
      "Step:  10 Action:  69 Distance:  tensor(1.5418, dtype=torch.float64)\n",
      "Step:  10 Action:  74 Distance:  tensor(1.4100, dtype=torch.float64)\n",
      "Step:  10 Action:  82 Distance:  tensor(1.5741, dtype=torch.float64)\n",
      "Step:  10 Action:  90 Distance:  tensor(1.2631, dtype=torch.float64)\n",
      "10 []\n",
      "Step:  11 Action:  56 Distance:  tensor(1.2257, dtype=torch.float64)\n",
      "Step:  11 Action:  61 Distance:  tensor(1.5655, dtype=torch.float64)\n",
      "Step:  11 Action:  69 Distance:  tensor(1.5418, dtype=torch.float64)\n",
      "Step:  11 Action:  74 Distance:  tensor(1.4100, dtype=torch.float64)\n",
      "Step:  11 Action:  82 Distance:  tensor(1.5741, dtype=torch.float64)\n",
      "Step:  11 Action:  90 Distance:  tensor(1.2631, dtype=torch.float64)\n",
      "11 []\n",
      "Step:  12 Action:  56 Distance:  tensor(1.3080, dtype=torch.float64)\n",
      "Step:  12 Action:  61 Distance:  tensor(1.5581, dtype=torch.float64)\n",
      "Step:  12 Action:  69 Distance:  tensor(1.5947, dtype=torch.float64)\n",
      "Step:  12 Action:  74 Distance:  tensor(1.3253, dtype=torch.float64)\n",
      "Step:  12 Action:  77 Distance:  tensor(1.2564, dtype=torch.float64)\n",
      "Step:  12 Action:  82 Distance:  tensor(1.5506, dtype=torch.float64)\n",
      "Step:  12 Action:  90 Distance:  tensor(1.2967, dtype=torch.float64)\n",
      "12 []\n",
      "Step:  13 Action:  56 Distance:  tensor(1.3643, dtype=torch.float64)\n",
      "Step:  13 Action:  61 Distance:  tensor(1.5247, dtype=torch.float64)\n",
      "Step:  13 Action:  64 Distance:  tensor(1.2298, dtype=torch.float64)\n",
      "Step:  13 Action:  69 Distance:  tensor(1.6218, dtype=torch.float64)\n",
      "Step:  13 Action:  74 Distance:  tensor(1.2146, dtype=torch.float64)\n",
      "Step:  13 Action:  77 Distance:  tensor(1.3332, dtype=torch.float64)\n",
      "Step:  13 Action:  82 Distance:  tensor(1.5012, dtype=torch.float64)\n",
      "Step:  13 Action:  90 Distance:  tensor(1.3043, dtype=torch.float64)\n",
      "13 []\n",
      "Step:  14 Action:  56 Distance:  tensor(1.3236, dtype=torch.float64)\n",
      "Step:  14 Action:  61 Distance:  tensor(1.4642, dtype=torch.float64)\n",
      "Step:  14 Action:  64 Distance:  tensor(1.2667, dtype=torch.float64)\n",
      "Step:  14 Action:  69 Distance:  tensor(1.6333, dtype=torch.float64)\n",
      "Step:  14 Action:  77 Distance:  tensor(1.4185, dtype=torch.float64)\n",
      "Step:  14 Action:  82 Distance:  tensor(1.5103, dtype=torch.float64)\n",
      "Step:  14 Action:  90 Distance:  tensor(1.3923, dtype=torch.float64)\n",
      "14 []\n",
      "Step:  15 Action:  56 Distance:  tensor(1.2585, dtype=torch.float64)\n",
      "Step:  15 Action:  61 Distance:  tensor(1.3793, dtype=torch.float64)\n",
      "Step:  15 Action:  64 Distance:  tensor(1.2792, dtype=torch.float64)\n",
      "Step:  15 Action:  69 Distance:  tensor(1.6204, dtype=torch.float64)\n",
      "Step:  15 Action:  77 Distance:  tensor(1.4794, dtype=torch.float64)\n",
      "Step:  15 Action:  82 Distance:  tensor(1.4951, dtype=torch.float64)\n",
      "Step:  15 Action:  90 Distance:  tensor(1.4558, dtype=torch.float64)\n",
      "15 []\n",
      "Step:  16 Action:  61 Distance:  tensor(1.2885, dtype=torch.float64)\n",
      "Step:  16 Action:  64 Distance:  tensor(1.2906, dtype=torch.float64)\n",
      "Step:  16 Action:  69 Distance:  tensor(1.6013, dtype=torch.float64)\n",
      "Step:  16 Action:  77 Distance:  tensor(1.5375, dtype=torch.float64)\n",
      "Step:  16 Action:  82 Distance:  tensor(1.4737, dtype=torch.float64)\n",
      "Step:  16 Action:  90 Distance:  tensor(1.5160, dtype=torch.float64)\n",
      "16 []\n",
      "Step:  17 Action:  64 Distance:  tensor(1.2763, dtype=torch.float64)\n",
      "Step:  17 Action:  69 Distance:  tensor(1.5565, dtype=torch.float64)\n",
      "Step:  17 Action:  77 Distance:  tensor(1.5700, dtype=torch.float64)\n",
      "Step:  17 Action:  82 Distance:  tensor(1.4267, dtype=torch.float64)\n",
      "Step:  17 Action:  90 Distance:  tensor(1.5504, dtype=torch.float64)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Step:  17 Action:  98 Distance:  tensor(1.2671, dtype=torch.float64)\n",
      "17 []\n",
      "Step:  18 Action:  64 Distance:  tensor(1.2763, dtype=torch.float64)\n",
      "Step:  18 Action:  69 Distance:  tensor(1.5565, dtype=torch.float64)\n",
      "Step:  18 Action:  77 Distance:  tensor(1.5700, dtype=torch.float64)\n",
      "Step:  18 Action:  82 Distance:  tensor(1.4267, dtype=torch.float64)\n",
      "Step:  18 Action:  90 Distance:  tensor(1.5504, dtype=torch.float64)\n",
      "Step:  18 Action:  98 Distance:  tensor(1.2671, dtype=torch.float64)\n",
      "18 []\n",
      "Step:  19 Action:  64 Distance:  tensor(1.2807, dtype=torch.float64)\n",
      "Step:  19 Action:  69 Distance:  tensor(1.5051, dtype=torch.float64)\n",
      "Step:  19 Action:  77 Distance:  tensor(1.6072, dtype=torch.float64)\n",
      "Step:  19 Action:  82 Distance:  tensor(1.3555, dtype=torch.float64)\n",
      "Step:  19 Action:  85 Distance:  tensor(1.2477, dtype=torch.float64)\n",
      "Step:  19 Action:  90 Distance:  tensor(1.5722, dtype=torch.float64)\n",
      "Step:  19 Action:  98 Distance:  tensor(1.3832, dtype=torch.float64)\n",
      "19 []\n",
      "Step:  20 Action:  44 Distance:  tensor(1.3385, dtype=torch.float64)\n",
      "Step:  20 Action:  49 Distance:  tensor(1.2286, dtype=torch.float64)\n",
      "Step:  20 Action:  69 Distance:  tensor(1.3823, dtype=torch.float64)\n",
      "Step:  20 Action:  77 Distance:  tensor(1.5818, dtype=torch.float64)\n",
      "Step:  20 Action:  82 Distance:  tensor(1.2872, dtype=torch.float64)\n",
      "Step:  20 Action:  85 Distance:  tensor(1.2530, dtype=torch.float64)\n",
      "Step:  20 Action:  90 Distance:  tensor(1.6020, dtype=torch.float64)\n",
      "Step:  20 Action:  98 Distance:  tensor(1.4867, dtype=torch.float64)\n",
      "20 []\n",
      "Step:  21 Action:  44 Distance:  tensor(1.4217, dtype=torch.float64)\n",
      "Step:  21 Action:  49 Distance:  tensor(1.2387, dtype=torch.float64)\n",
      "Step:  21 Action:  69 Distance:  tensor(1.2773, dtype=torch.float64)\n",
      "Step:  21 Action:  77 Distance:  tensor(1.5501, dtype=torch.float64)\n",
      "Step:  21 Action:  82 Distance:  tensor(1.2059, dtype=torch.float64)\n",
      "Step:  21 Action:  85 Distance:  tensor(1.2581, dtype=torch.float64)\n",
      "Step:  21 Action:  90 Distance:  tensor(1.5947, dtype=torch.float64)\n",
      "Step:  21 Action:  98 Distance:  tensor(1.5446, dtype=torch.float64)\n",
      "21 []\n",
      "Step:  22 Action:  44 Distance:  tensor(1.4126, dtype=torch.float64)\n",
      "Step:  22 Action:  69 Distance:  tensor(1.2116, dtype=torch.float64)\n",
      "Step:  22 Action:  77 Distance:  tensor(1.5488, dtype=torch.float64)\n",
      "Step:  22 Action:  85 Distance:  tensor(1.3282, dtype=torch.float64)\n",
      "Step:  22 Action:  90 Distance:  tensor(1.5470, dtype=torch.float64)\n",
      "Step:  22 Action:  98 Distance:  tensor(1.5829, dtype=torch.float64)\n",
      "22 []\n",
      "Step:  23 Action:  31 Distance:  tensor(1.2443, dtype=torch.float64)\n",
      "Step:  23 Action:  39 Distance:  tensor(1.2866, dtype=torch.float64)\n",
      "Step:  23 Action:  44 Distance:  tensor(1.3997, dtype=torch.float64)\n",
      "Step:  23 Action:  77 Distance:  tensor(1.5426, dtype=torch.float64)\n",
      "Step:  23 Action:  85 Distance:  tensor(1.3959, dtype=torch.float64)\n",
      "Step:  23 Action:  90 Distance:  tensor(1.4943, dtype=torch.float64)\n",
      "Step:  23 Action:  98 Distance:  tensor(1.6163, dtype=torch.float64)\n",
      "23 []\n",
      "Step:  24 Action:  31 Distance:  tensor(1.2934, dtype=torch.float64)\n",
      "Step:  24 Action:  39 Distance:  tensor(1.3726, dtype=torch.float64)\n",
      "Step:  24 Action:  44 Distance:  tensor(1.3641, dtype=torch.float64)\n",
      "Step:  24 Action:  77 Distance:  tensor(1.5137, dtype=torch.float64)\n",
      "Step:  24 Action:  85 Distance:  tensor(1.4408, dtype=torch.float64)\n",
      "Step:  24 Action:  90 Distance:  tensor(1.4189, dtype=torch.float64)\n",
      "Step:  24 Action:  98 Distance:  tensor(1.6270, dtype=torch.float64)\n",
      "24 []\n",
      "Step:  25 Action:  31 Distance:  tensor(1.3955, dtype=torch.float64)\n",
      "Step:  25 Action:  39 Distance:  tensor(1.4232, dtype=torch.float64)\n",
      "Step:  25 Action:  44 Distance:  tensor(1.4189, dtype=torch.float64)\n",
      "Step:  25 Action:  77 Distance:  tensor(1.4476, dtype=torch.float64)\n",
      "Step:  25 Action:  85 Distance:  tensor(1.4018, dtype=torch.float64)\n",
      "Step:  25 Action:  90 Distance:  tensor(1.3865, dtype=torch.float64)\n",
      "Step:  25 Action:  98 Distance:  tensor(1.6444, dtype=torch.float64)\n",
      "25 []\n",
      "Step:  26 Action:  23 Distance:  tensor(1.2010, dtype=torch.float64)\n",
      "Step:  26 Action:  31 Distance:  tensor(1.5438, dtype=torch.float64)\n",
      "Step:  26 Action:  39 Distance:  tensor(1.4724, dtype=torch.float64)\n",
      "Step:  26 Action:  44 Distance:  tensor(1.4670, dtype=torch.float64)\n",
      "Step:  26 Action:  77 Distance:  tensor(1.2564, dtype=torch.float64)\n",
      "Step:  26 Action:  85 Distance:  tensor(1.2705, dtype=torch.float64)\n",
      "Step:  26 Action:  90 Distance:  tensor(1.2592, dtype=torch.float64)\n",
      "Step:  26 Action:  98 Distance:  tensor(1.6194, dtype=torch.float64)\n",
      "26 []\n",
      "Step:  27 Action:  23 Distance:  tensor(1.2617, dtype=torch.float64)\n",
      "Step:  27 Action:  26 Distance:  tensor(1.3512, dtype=torch.float64)\n",
      "Step:  27 Action:  31 Distance:  tensor(1.6077, dtype=torch.float64)\n",
      "Step:  27 Action:  39 Distance:  tensor(1.5253, dtype=torch.float64)\n",
      "Step:  27 Action:  44 Distance:  tensor(1.3890, dtype=torch.float64)\n",
      "Step:  27 Action:  98 Distance:  tensor(1.5487, dtype=torch.float64)\n",
      "27 []\n",
      "Step:  28 Action:  18 Distance:  tensor(1.2351, dtype=torch.float64)\n",
      "Step:  28 Action:  23 Distance:  tensor(1.2164, dtype=torch.float64)\n",
      "Step:  28 Action:  26 Distance:  tensor(1.4285, dtype=torch.float64)\n",
      "Step:  28 Action:  31 Distance:  tensor(1.6014, dtype=torch.float64)\n",
      "Step:  28 Action:  39 Distance:  tensor(1.5558, dtype=torch.float64)\n",
      "Step:  28 Action:  44 Distance:  tensor(1.2939, dtype=torch.float64)\n",
      "Step:  28 Action:  98 Distance:  tensor(1.4966, dtype=torch.float64)\n",
      "28 []\n",
      "Step:  29 Action:  18 Distance:  tensor(1.3395, dtype=torch.float64)\n",
      "Step:  29 Action:  23 Distance:  tensor(1.2725, dtype=torch.float64)\n",
      "Step:  29 Action:  26 Distance:  tensor(1.4920, dtype=torch.float64)\n",
      "Step:  29 Action:  31 Distance:  tensor(1.6207, dtype=torch.float64)\n",
      "Step:  29 Action:  39 Distance:  tensor(1.5335, dtype=torch.float64)\n",
      "Step:  29 Action:  44 Distance:  tensor(1.2629, dtype=torch.float64)\n",
      "Step:  29 Action:  98 Distance:  tensor(1.4319, dtype=torch.float64)\n",
      "29 []\n",
      "Step:  30 Action:  18 Distance:  tensor(1.4184, dtype=torch.float64)\n",
      "Step:  30 Action:  23 Distance:  tensor(1.3032, dtype=torch.float64)\n",
      "Step:  30 Action:  26 Distance:  tensor(1.5302, dtype=torch.float64)\n",
      "Step:  30 Action:  31 Distance:  tensor(1.6147, dtype=torch.float64)\n",
      "Step:  30 Action:  39 Distance:  tensor(1.4859, dtype=torch.float64)\n",
      "Step:  30 Action:  44 Distance:  tensor(1.2065, dtype=torch.float64)\n",
      "Step:  30 Action:  98 Distance:  tensor(1.3418, dtype=torch.float64)\n",
      "30 []\n",
      "Step:  31 Action:  13 Distance:  tensor(1.2379, dtype=torch.float64)\n",
      "Step:  31 Action:  18 Distance:  tensor(1.4916, dtype=torch.float64)\n",
      "Step:  31 Action:  23 Distance:  tensor(1.3284, dtype=torch.float64)\n",
      "Step:  31 Action:  26 Distance:  tensor(1.5638, dtype=torch.float64)\n",
      "Step:  31 Action:  31 Distance:  tensor(1.6021, dtype=torch.float64)\n",
      "Step:  31 Action:  39 Distance:  tensor(1.4352, dtype=torch.float64)\n",
      "Step:  31 Action:  98 Distance:  tensor(1.2489, dtype=torch.float64)\n",
      "31 []\n",
      "Step:  32 Action:  0 Distance:  tensor(1.2495, dtype=torch.float64)\n",
      "Step:  32 Action:  13 Distance:  tensor(1.4117, dtype=torch.float64)\n",
      "Step:  32 Action:  18 Distance:  tensor(1.5820, dtype=torch.float64)\n",
      "Step:  32 Action:  23 Distance:  tensor(1.3226, dtype=torch.float64)\n",
      "Step:  32 Action:  26 Distance:  tensor(1.5775, dtype=torch.float64)\n",
      "Step:  32 Action:  31 Distance:  tensor(1.5211, dtype=torch.float64)\n",
      "Step:  32 Action:  39 Distance:  tensor(1.2828, dtype=torch.float64)\n",
      "32 []\n",
      "Step:  33 Action:  0 Distance:  tensor(1.4203, dtype=torch.float64)\n",
      "Step:  33 Action:  5 Distance:  tensor(1.3761, dtype=torch.float64)\n",
      "Step:  33 Action:  10 Distance:  tensor(1.2212, dtype=torch.float64)\n",
      "Step:  33 Action:  13 Distance:  tensor(1.5318, dtype=torch.float64)\n",
      "Step:  33 Action:  18 Distance:  tensor(1.6109, dtype=torch.float64)\n",
      "Step:  33 Action:  23 Distance:  tensor(1.2563, dtype=torch.float64)\n",
      "Step:  33 Action:  26 Distance:  tensor(1.5325, dtype=torch.float64)\n",
      "Step:  33 Action:  31 Distance:  tensor(1.3783, dtype=torch.float64)\n",
      "33 []\n",
      "Step:  34 Action:  0 Distance:  tensor(1.5741, dtype=torch.float64)\n",
      "Step:  34 Action:  5 Distance:  tensor(1.4806, dtype=torch.float64)\n",
      "Step:  34 Action:  8 Distance:  tensor(1.2429, dtype=torch.float64)\n",
      "Step:  34 Action:  10 Distance:  tensor(1.2187, dtype=torch.float64)\n",
      "Step:  34 Action:  13 Distance:  tensor(1.6071, dtype=torch.float64)\n",
      "Step:  34 Action:  18 Distance:  tensor(1.5614, dtype=torch.float64)\n",
      "Step:  34 Action:  21 Distance:  tensor(1.2155, dtype=torch.float64)\n",
      "Step:  34 Action:  26 Distance:  tensor(1.4623, dtype=torch.float64)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Step:  34 Action:  34 Distance:  tensor(1.2363, dtype=torch.float64)\n",
      "34 []\n",
      "Step:  35 Action:  0 Distance:  tensor(1.6504, dtype=torch.float64)\n",
      "Step:  35 Action:  5 Distance:  tensor(1.4896, dtype=torch.float64)\n",
      "Step:  35 Action:  8 Distance:  tensor(1.3297, dtype=torch.float64)\n",
      "Step:  35 Action:  13 Distance:  tensor(1.6255, dtype=torch.float64)\n",
      "Step:  35 Action:  18 Distance:  tensor(1.5023, dtype=torch.float64)\n",
      "Step:  35 Action:  21 Distance:  tensor(1.3069, dtype=torch.float64)\n",
      "Step:  35 Action:  26 Distance:  tensor(1.4191, dtype=torch.float64)\n",
      "Step:  35 Action:  34 Distance:  tensor(1.2754, dtype=torch.float64)\n",
      "35 []\n",
      "Step:  36 Action:  0 Distance:  tensor(1.6504, dtype=torch.float64)\n",
      "Step:  36 Action:  5 Distance:  tensor(1.4574, dtype=torch.float64)\n",
      "Step:  36 Action:  8 Distance:  tensor(1.3736, dtype=torch.float64)\n",
      "Step:  36 Action:  13 Distance:  tensor(1.6424, dtype=torch.float64)\n",
      "Step:  36 Action:  18 Distance:  tensor(1.4433, dtype=torch.float64)\n",
      "Step:  36 Action:  21 Distance:  tensor(1.3961, dtype=torch.float64)\n",
      "Step:  36 Action:  26 Distance:  tensor(1.4171, dtype=torch.float64)\n",
      "Step:  36 Action:  34 Distance:  tensor(1.3541, dtype=torch.float64)\n",
      "36 []\n",
      "Step:  37 Action:  0 Distance:  tensor(1.6297, dtype=torch.float64)\n",
      "Step:  37 Action:  5 Distance:  tensor(1.3586, dtype=torch.float64)\n",
      "Step:  37 Action:  8 Distance:  tensor(1.3157, dtype=torch.float64)\n",
      "Step:  37 Action:  13 Distance:  tensor(1.6391, dtype=torch.float64)\n",
      "Step:  37 Action:  18 Distance:  tensor(1.3957, dtype=torch.float64)\n",
      "Step:  37 Action:  21 Distance:  tensor(1.4311, dtype=torch.float64)\n",
      "Step:  37 Action:  26 Distance:  tensor(1.4701, dtype=torch.float64)\n",
      "Step:  37 Action:  34 Distance:  tensor(1.4513, dtype=torch.float64)\n",
      "37 []\n",
      "Step:  38 Action:  0 Distance:  tensor(1.5064, dtype=torch.float64)\n",
      "Step:  38 Action:  5 Distance:  tensor(1.2675, dtype=torch.float64)\n",
      "Step:  38 Action:  8 Distance:  tensor(1.2816, dtype=torch.float64)\n",
      "Step:  38 Action:  13 Distance:  tensor(1.6227, dtype=torch.float64)\n",
      "Step:  38 Action:  18 Distance:  tensor(1.3224, dtype=torch.float64)\n",
      "Step:  38 Action:  21 Distance:  tensor(1.4697, dtype=torch.float64)\n",
      "Step:  38 Action:  26 Distance:  tensor(1.4794, dtype=torch.float64)\n",
      "Step:  38 Action:  34 Distance:  tensor(1.5213, dtype=torch.float64)\n",
      "Step:  38 Action:  47 Distance:  tensor(1.2133, dtype=torch.float64)\n",
      "38 []\n",
      "Step:  39 Action:  0 Distance:  tensor(1.5209, dtype=torch.float64)\n",
      "Step:  39 Action:  5 Distance:  tensor(1.2129, dtype=torch.float64)\n",
      "Step:  39 Action:  8 Distance:  tensor(1.3191, dtype=torch.float64)\n",
      "Step:  39 Action:  13 Distance:  tensor(1.5965, dtype=torch.float64)\n",
      "Step:  39 Action:  18 Distance:  tensor(1.2075, dtype=torch.float64)\n",
      "Step:  39 Action:  21 Distance:  tensor(1.5323, dtype=torch.float64)\n",
      "Step:  39 Action:  26 Distance:  tensor(1.4036, dtype=torch.float64)\n",
      "Step:  39 Action:  34 Distance:  tensor(1.5428, dtype=torch.float64)\n",
      "39 []\n",
      "Step:  40 Action:  0 Distance:  tensor(1.5209, dtype=torch.float64)\n",
      "Step:  40 Action:  5 Distance:  tensor(1.2129, dtype=torch.float64)\n",
      "Step:  40 Action:  8 Distance:  tensor(1.3191, dtype=torch.float64)\n",
      "Step:  40 Action:  13 Distance:  tensor(1.5965, dtype=torch.float64)\n",
      "Step:  40 Action:  18 Distance:  tensor(1.2075, dtype=torch.float64)\n",
      "Step:  40 Action:  21 Distance:  tensor(1.5323, dtype=torch.float64)\n",
      "Step:  40 Action:  26 Distance:  tensor(1.4036, dtype=torch.float64)\n",
      "Step:  40 Action:  34 Distance:  tensor(1.5428, dtype=torch.float64)\n",
      "40 []\n",
      "Step:  41 Action:  0 Distance:  tensor(1.5209, dtype=torch.float64)\n",
      "Step:  41 Action:  5 Distance:  tensor(1.2129, dtype=torch.float64)\n",
      "Step:  41 Action:  8 Distance:  tensor(1.3191, dtype=torch.float64)\n",
      "Step:  41 Action:  13 Distance:  tensor(1.5965, dtype=torch.float64)\n",
      "Step:  41 Action:  18 Distance:  tensor(1.2075, dtype=torch.float64)\n",
      "Step:  41 Action:  21 Distance:  tensor(1.5323, dtype=torch.float64)\n",
      "Step:  41 Action:  26 Distance:  tensor(1.4036, dtype=torch.float64)\n",
      "Step:  41 Action:  34 Distance:  tensor(1.5428, dtype=torch.float64)\n",
      "41 []\n",
      "Step:  42 Action:  0 Distance:  tensor(1.5209, dtype=torch.float64)\n",
      "Step:  42 Action:  5 Distance:  tensor(1.2129, dtype=torch.float64)\n",
      "Step:  42 Action:  8 Distance:  tensor(1.3191, dtype=torch.float64)\n",
      "Step:  42 Action:  13 Distance:  tensor(1.5965, dtype=torch.float64)\n",
      "Step:  42 Action:  18 Distance:  tensor(1.2075, dtype=torch.float64)\n",
      "Step:  42 Action:  21 Distance:  tensor(1.5323, dtype=torch.float64)\n",
      "Step:  42 Action:  26 Distance:  tensor(1.4036, dtype=torch.float64)\n",
      "Step:  42 Action:  34 Distance:  tensor(1.5428, dtype=torch.float64)\n",
      "42 []\n",
      "Step:  43 Action:  0 Distance:  tensor(1.5209, dtype=torch.float64)\n",
      "Step:  43 Action:  5 Distance:  tensor(1.2129, dtype=torch.float64)\n",
      "Step:  43 Action:  8 Distance:  tensor(1.3191, dtype=torch.float64)\n",
      "Step:  43 Action:  13 Distance:  tensor(1.5965, dtype=torch.float64)\n",
      "Step:  43 Action:  18 Distance:  tensor(1.2075, dtype=torch.float64)\n",
      "Step:  43 Action:  21 Distance:  tensor(1.5323, dtype=torch.float64)\n",
      "Step:  43 Action:  26 Distance:  tensor(1.4036, dtype=torch.float64)\n",
      "Step:  43 Action:  34 Distance:  tensor(1.5428, dtype=torch.float64)\n",
      "43 []\n",
      "Step:  44 Action:  0 Distance:  tensor(1.5209, dtype=torch.float64)\n",
      "Step:  44 Action:  5 Distance:  tensor(1.2129, dtype=torch.float64)\n",
      "Step:  44 Action:  8 Distance:  tensor(1.3191, dtype=torch.float64)\n",
      "Step:  44 Action:  13 Distance:  tensor(1.5965, dtype=torch.float64)\n",
      "Step:  44 Action:  18 Distance:  tensor(1.2075, dtype=torch.float64)\n",
      "Step:  44 Action:  21 Distance:  tensor(1.5323, dtype=torch.float64)\n",
      "Step:  44 Action:  26 Distance:  tensor(1.4036, dtype=torch.float64)\n",
      "Step:  44 Action:  34 Distance:  tensor(1.5428, dtype=torch.float64)\n",
      "44 []\n",
      "Step:  45 Action:  0 Distance:  tensor(1.5209, dtype=torch.float64)\n",
      "Step:  45 Action:  5 Distance:  tensor(1.2129, dtype=torch.float64)\n",
      "Step:  45 Action:  8 Distance:  tensor(1.3191, dtype=torch.float64)\n",
      "Step:  45 Action:  13 Distance:  tensor(1.5965, dtype=torch.float64)\n",
      "Step:  45 Action:  18 Distance:  tensor(1.2075, dtype=torch.float64)\n",
      "Step:  45 Action:  21 Distance:  tensor(1.5323, dtype=torch.float64)\n",
      "Step:  45 Action:  26 Distance:  tensor(1.4036, dtype=torch.float64)\n",
      "Step:  45 Action:  34 Distance:  tensor(1.5428, dtype=torch.float64)\n",
      "45 []\n",
      "Step:  46 Action:  0 Distance:  tensor(1.5209, dtype=torch.float64)\n",
      "Step:  46 Action:  5 Distance:  tensor(1.2129, dtype=torch.float64)\n",
      "Step:  46 Action:  8 Distance:  tensor(1.3191, dtype=torch.float64)\n",
      "Step:  46 Action:  13 Distance:  tensor(1.5965, dtype=torch.float64)\n",
      "Step:  46 Action:  18 Distance:  tensor(1.2075, dtype=torch.float64)\n",
      "Step:  46 Action:  21 Distance:  tensor(1.5323, dtype=torch.float64)\n",
      "Step:  46 Action:  26 Distance:  tensor(1.4036, dtype=torch.float64)\n",
      "Step:  46 Action:  34 Distance:  tensor(1.5428, dtype=torch.float64)\n",
      "46 []\n",
      "Step:  47 Action:  0 Distance:  tensor(1.5209, dtype=torch.float64)\n",
      "Step:  47 Action:  8 Distance:  tensor(1.2639, dtype=torch.float64)\n",
      "Step:  47 Action:  13 Distance:  tensor(1.5583, dtype=torch.float64)\n",
      "Step:  47 Action:  21 Distance:  tensor(1.5480, dtype=torch.float64)\n",
      "Step:  47 Action:  26 Distance:  tensor(1.3944, dtype=torch.float64)\n",
      "Step:  47 Action:  34 Distance:  tensor(1.5913, dtype=torch.float64)\n",
      "Step:  47 Action:  42 Distance:  tensor(1.2956, dtype=torch.float64)\n",
      "Step:  47 Action:  47 Distance:  tensor(1.2660, dtype=torch.float64)\n",
      "47 []\n",
      "Step:  48 Action:  0 Distance:  tensor(1.3885, dtype=torch.float64)\n",
      "Step:  48 Action:  8 Distance:  tensor(1.2964, dtype=torch.float64)\n",
      "Step:  48 Action:  13 Distance:  tensor(1.5198, dtype=torch.float64)\n",
      "Step:  48 Action:  21 Distance:  tensor(1.5907, dtype=torch.float64)\n",
      "Step:  48 Action:  26 Distance:  tensor(1.3027, dtype=torch.float64)\n",
      "Step:  48 Action:  29 Distance:  tensor(1.2582, dtype=torch.float64)\n",
      "Step:  48 Action:  34 Distance:  tensor(1.5862, dtype=torch.float64)\n",
      "Step:  48 Action:  42 Distance:  tensor(1.3674, dtype=torch.float64)\n",
      "Step:  48 Action:  47 Distance:  tensor(1.2157, dtype=torch.float64)\n",
      "48 []\n",
      "Step:  49 Action:  0 Distance:  tensor(1.5321, dtype=torch.float64)\n",
      "Step:  49 Action:  8 Distance:  tensor(1.3821, dtype=torch.float64)\n",
      "Step:  49 Action:  13 Distance:  tensor(1.5176, dtype=torch.float64)\n",
      "Step:  49 Action:  21 Distance:  tensor(1.6158, dtype=torch.float64)\n",
      "Step:  49 Action:  26 Distance:  tensor(1.2182, dtype=torch.float64)\n",
      "Step:  49 Action:  29 Distance:  tensor(1.3106, dtype=torch.float64)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Step:  49 Action:  34 Distance:  tensor(1.5309, dtype=torch.float64)\n",
      "Step:  49 Action:  42 Distance:  tensor(1.3322, dtype=torch.float64)\n",
      "49 []\n",
      "Step:  50 Action:  0 Distance:  tensor(1.5322, dtype=torch.float64)\n",
      "Step:  50 Action:  8 Distance:  tensor(1.3821, dtype=torch.float64)\n",
      "Step:  50 Action:  13 Distance:  tensor(1.5176, dtype=torch.float64)\n",
      "Step:  50 Action:  21 Distance:  tensor(1.6158, dtype=torch.float64)\n",
      "Step:  50 Action:  26 Distance:  tensor(1.2182, dtype=torch.float64)\n",
      "Step:  50 Action:  29 Distance:  tensor(1.3106, dtype=torch.float64)\n",
      "Step:  50 Action:  34 Distance:  tensor(1.5309, dtype=torch.float64)\n",
      "Step:  50 Action:  42 Distance:  tensor(1.3322, dtype=torch.float64)\n",
      "50 []\n",
      "Step:  51 Action:  0 Distance:  tensor(1.5321, dtype=torch.float64)\n",
      "Step:  51 Action:  5 Distance:  tensor(1.2367, dtype=torch.float64)\n",
      "Step:  51 Action:  8 Distance:  tensor(1.4490, dtype=torch.float64)\n",
      "Step:  51 Action:  13 Distance:  tensor(1.5675, dtype=torch.float64)\n",
      "Step:  51 Action:  21 Distance:  tensor(1.6079, dtype=torch.float64)\n",
      "Step:  51 Action:  26 Distance:  tensor(1.2407, dtype=torch.float64)\n",
      "Step:  51 Action:  29 Distance:  tensor(1.2570, dtype=torch.float64)\n",
      "Step:  51 Action:  34 Distance:  tensor(1.4905, dtype=torch.float64)\n",
      "Step:  51 Action:  42 Distance:  tensor(1.2329, dtype=torch.float64)\n",
      "51 []\n",
      "Step:  52 Action:  0 Distance:  tensor(1.6565, dtype=torch.float64)\n",
      "Step:  52 Action:  5 Distance:  tensor(1.3360, dtype=torch.float64)\n",
      "Step:  52 Action:  8 Distance:  tensor(1.4893, dtype=torch.float64)\n",
      "Step:  52 Action:  13 Distance:  tensor(1.5909, dtype=torch.float64)\n",
      "Step:  52 Action:  21 Distance:  tensor(1.5736, dtype=torch.float64)\n",
      "Step:  52 Action:  26 Distance:  tensor(1.2366, dtype=torch.float64)\n",
      "Step:  52 Action:  34 Distance:  tensor(1.4237, dtype=torch.float64)\n",
      "52 []\n",
      "Step:  53 Action:  0 Distance:  tensor(1.6565, dtype=torch.float64)\n",
      "Step:  53 Action:  5 Distance:  tensor(1.3360, dtype=torch.float64)\n",
      "Step:  53 Action:  8 Distance:  tensor(1.4893, dtype=torch.float64)\n",
      "Step:  53 Action:  13 Distance:  tensor(1.5909, dtype=torch.float64)\n",
      "Step:  53 Action:  21 Distance:  tensor(1.5736, dtype=torch.float64)\n",
      "Step:  53 Action:  26 Distance:  tensor(1.2366, dtype=torch.float64)\n",
      "Step:  53 Action:  34 Distance:  tensor(1.4237, dtype=torch.float64)\n",
      "53 []\n",
      "Step:  54 Action:  0 Distance:  tensor(1.6565, dtype=torch.float64)\n",
      "Step:  54 Action:  5 Distance:  tensor(1.4373, dtype=torch.float64)\n",
      "Step:  54 Action:  8 Distance:  tensor(1.5157, dtype=torch.float64)\n",
      "Step:  54 Action:  13 Distance:  tensor(1.6149, dtype=torch.float64)\n",
      "Step:  54 Action:  18 Distance:  tensor(1.2637, dtype=torch.float64)\n",
      "Step:  54 Action:  21 Distance:  tensor(1.5260, dtype=torch.float64)\n",
      "Step:  54 Action:  26 Distance:  tensor(1.2495, dtype=torch.float64)\n",
      "Step:  54 Action:  34 Distance:  tensor(1.3568, dtype=torch.float64)\n",
      "54 []\n",
      "Step:  55 Action:  0 Distance:  tensor(1.7441, dtype=torch.float64)\n",
      "Step:  55 Action:  5 Distance:  tensor(1.5640, dtype=torch.float64)\n",
      "Step:  55 Action:  8 Distance:  tensor(1.5016, dtype=torch.float64)\n",
      "Step:  55 Action:  13 Distance:  tensor(1.5992, dtype=torch.float64)\n",
      "Step:  55 Action:  18 Distance:  tensor(1.3915, dtype=torch.float64)\n",
      "Step:  55 Action:  21 Distance:  tensor(1.3772, dtype=torch.float64)\n",
      "Step:  55 Action:  26 Distance:  tensor(1.2197, dtype=torch.float64)\n",
      "55 []\n",
      "Step:  56 Action:  0 Distance:  tensor(1.7894, dtype=torch.float64)\n"
     ]
    },
    {
     "ename": "IndexError",
     "evalue": "index 58 is out of bounds for dimension 0 with size 58",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mIndexError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-6-a7dce26ea5fa>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      7\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0mz\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mn_actions\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m         \u001b[0menv\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstate\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mTractographyState\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mreferenceLine\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0menv\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minterpolateDWIatState\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 9\u001b[0;31m         \u001b[0mnext_state\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mreward\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0menv\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mz\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     10\u001b[0m         \u001b[0menv\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstepCounter\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mi\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     11\u001b[0m         \u001b[0;31m#if reward == -1:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/fibre_tracking/deepFibreTracking/dfibert/envs/RLtractEnvironment.py\u001b[0m in \u001b[0;36mstep\u001b[0;34m(self, action)\u001b[0m\n\u001b[1;32m    138\u001b[0m         \u001b[0;31m#else:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    139\u001b[0m         \u001b[0;31m#    rewardNextState = rewardDistance\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 140\u001b[0;31m         \u001b[0mrewardNextState\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrewardForState\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnextState\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    141\u001b[0m         \u001b[0;31m#if rewardNextState < 0.:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    142\u001b[0m         \u001b[0;31m#    rewardNextState = -1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/fibre_tracking/deepFibreTracking/dfibert/envs/RLtractEnvironment.py\u001b[0m in \u001b[0;36mrewardForState\u001b[0;34m(self, state)\u001b[0m\n\u001b[1;32m    160\u001b[0m         \u001b[0mqry_pt\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mstate\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgetCoordinate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mview\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m3\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    161\u001b[0m         \u001b[0;31m#distance = torch.min(torch.sum( (self.referenceStreamline_ijk[np.max([self.stepCounter-1-2,0]):np.min([self.stepCounter-1+1,self.maxSteps])] - qry_pt)**2, dim =1 ))\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 162\u001b[0;31m         \u001b[0mdistance\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msum\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreferenceStreamline_ijk\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstepCounter\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m86\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0mqry_pt\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m**\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdim\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    163\u001b[0m         \u001b[0;31m#reward = torch.tanh(-distance+5.3)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    164\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mdistance\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mIndexError\u001b[0m: index 58 is out of bounds for dimension 0 with size 58"
     ]
    }
   ],
   "source": [
    "possible_actions = []\n",
    "past_state = env.reset()\n",
    "all_next_states = []\n",
    "for i in range(len(referenceLine)):\n",
    "    best_actions = []\n",
    "    next_states = []\n",
    "    for z in range(n_actions):\n",
    "        env.state = TractographyState(referenceLine[i], env.interpolateDWIatState)\n",
    "        next_state, reward, _ = env.step(z)\n",
    "        env.stepCounter = i\n",
    "        #if reward == -1:\n",
    "        #    reward = 0\n",
    "        #elif reward < 0.2:\n",
    "        if reward > 1.0:\n",
    "            print(\"Step: \", i, \"Action: \", z, \"Distance: \", reward)\n",
    "        #    reward = 1\n",
    "        #elif reward < 1.:\n",
    "        #    reward = 0\n",
    "        #else:\n",
    "        #    reward = -1\n",
    "        #if reward == 1:\n",
    "        #    best_actions.append(z)\n",
    "            #print(i, z, referenceLine[i].numpy(), next_state.getCoordinate().numpy(), reward)\n",
    "    print(i, best_actions)\n",
    "    #print(i, reward)\n",
    "    #if reward > 0.9:\n",
    "    #    best_actions.append(i)\n",
    "    possible_actions.append(best_actions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "step_distance = []\n",
    "optimal_steps_58 = []#[100, 80, 75, 80, 75, 100, 62, 75, 83, 75, 83, 100, 83, 62, 67, 51, 67, 100, 59, 59, 59, 100, 59, 56, 51, 56, 66, 100, 66, 71, 71, 79, 58, 100, 71, 71, 84, 71, 100, 92, 84, 92, 97, 100, 97, 38, 97, 43, 38, 100, 43, 43, 89, 48]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "58\n"
     ]
    }
   ],
   "source": [
    "last_state = env.reset()\n",
    "print(len(env.referenceStreamline_ijk))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Hey, hey, hey we finally stopped at the terminal state! :D\n"
     ]
    },
    {
     "ename": "IndexError",
     "evalue": "index 58 is out of bounds for dimension 0 with size 58",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mIndexError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-10-c389f4e5c072>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      9\u001b[0m         \u001b[0mnext_state\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mterminal\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0menv\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     10\u001b[0m         \u001b[0;31m#distance = lineseg_dist(next_state.getCoordinate().numpy(), referenceLine[np.min([len(optimal_steps_58), 85])].numpy(), referenceLine[np.min([len(optimal_steps_58)+1, len(referenceLine)-1])].numpy())\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 11\u001b[0;31m         distance = ((next_state.getCoordinate()[0] - env.referenceStreamline_ijk[np.min([env.stepCounter, 58])][0])**2 \\\n\u001b[0m\u001b[1;32m     12\u001b[0m                       \u001b[0;34m+\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mnext_state\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgetCoordinate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0menv\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreferenceStreamline_ijk\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0menv\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstepCounter\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m58\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m**\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;31m \u001b[0m\u001b[0;31m\\\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     13\u001b[0m                       + (next_state.getCoordinate()[2] - env.referenceStreamline_ijk[np.min([env.stepCounter, 58])][2])**2)\n",
      "\u001b[0;31mIndexError\u001b[0m: index 58 is out of bounds for dimension 0 with size 58"
     ]
    }
   ],
   "source": [
    "steps = 0\n",
    "while len(optimal_steps_58) < 58:\n",
    "    step_distance = []\n",
    "    for i in range(n_actions):\n",
    "        env.reset()\n",
    "        if len(optimal_steps_58)>0:\n",
    "            for z in range(len(optimal_steps_58)):\n",
    "                _,_,_ = env.step(optimal_steps_58[z])\n",
    "        next_state, _, terminal = env.step(i)\n",
    "        #distance = lineseg_dist(next_state.getCoordinate().numpy(), referenceLine[np.min([len(optimal_steps_58), 85])].numpy(), referenceLine[np.min([len(optimal_steps_58)+1, len(referenceLine)-1])].numpy())\n",
    "        distance = ((next_state.getCoordinate()[0] - env.referenceStreamline_ijk[np.min([env.stepCounter, 58])][0])**2 \\\n",
    "                      + (next_state.getCoordinate()[1] - env.referenceStreamline_ijk[np.min([env.stepCounter, 58])][1])**2 \\\n",
    "                      + (next_state.getCoordinate()[2] - env.referenceStreamline_ijk[np.min([env.stepCounter, 58])][2])**2)\n",
    "        step_distance.append(distance)\n",
    "    optimal_steps_58.append(np.argmin(step_distance))\n",
    "print(optimal_steps_58)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# with line distance\n",
    "#optimal_steps = [80, 88, 54, 96, 46, 75, 75, 75, 83, 75, 83, 83, 62, 54, 1, 59, 54, 59, 59, 67, 56, 59, 51, 59, 61, 11, 53, 61, 66, 71, 71, 79, 58, 71, 71, 71, 21, 71, 84, 92, 84, 92, 97, 84, 43, 84, 30, 97, 47, 97, 43, 30, 89, 35, 94, 73, 48, 89, 22, 72, 43, 35, 22, 35, 35, 6, 19, 3, 16, 16, 66, 16, 8, 21, 29, 21, 26, 26, 93, 26, 93, 85, 35, 85, 72, 77, 100]\n",
    "optimal_steps = [100, 80, 75, 80, 75, 100, 62, 75, 83, 75, 83, 100, 83, 62, 67, 51, 67, 100, 59, 59, 59, 100, 59, 56, 51, 56, 66, 100, 66, 71, 71, 79, 58, 100, 71, 71, 84, 71, 100, 92, 84, 92, 97, 100, 97, 38, 97, 43, 38, 100, 43, 43, 89, 48, 100, 94, 81, 48, 43, 100, 35, 43, 35, 22, 27, 100, 6, 11, 3, 16, 100, 8, 29, 21, 21, 100, 34, 26, 26, 93, 39, 100, 93, 72, 77, 77, 101]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#optimal_steps = [80, 75, 80, 75, 62, 75, 83, 96, 51, 24, 62, 62, 62, 77, 65, 64, 67, 59, 56, 83, 82, 54, 56, 53, 56, 38, 56, 84, 66, 71, 71, 64, 97, 84, 71, 71, 38, 51, 30, 92, 97, 84, 43, 79, 27, 46, 89, 25, 81, 25, 48, 43, 86, 48, 57, 14, 89, 43, 43, 19, 92, 14, 27, 9, 78, 4, 16, 3, 29, 3, 47, 6, 42, 21, 39, 5, 72, 34, 98, 88, 90, 75, 77, 59, 49, 32, 82]\n",
    "print(optimal_steps) # <-- min of max distance reward streamline 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[80, 75, 80, 75, 62, 75, 83, 96, 51, 24, 62, 62, 62, 77, 65, 64, 67, 59, 56, 83, 82, 54, 56, 53, 56, 38, 56, 84, 66, 71, 71, 64, 97, 84, 71, 71, 38, 51, 30, 92, 97, 84, 43, 79, 27, 46, 89, 25, 81, 25, 48, 43, 86, 48, 57, 14, 89, 43, 43, 19, 92, 14, 27, 9, 78, 4, 16, 3, 29, 3, 47, 6, 42, 21, 39, 5, 72, 34, 98, 88, 90, 75, 77, 59, 49, 32, 82]\n"
     ]
    }
   ],
   "source": [
    "optimal_steps = [80, 75, 80, 75, 62, 75, 83, 96, 51, 24, 62, 62, 62, 77, 65, 64, 67, 59, 56, 83, 82, 54, 56, 53, 56, 38, 56, 84, 66, 71, 71, 64, 97, 84, 71, 71, 38, 51, 30, 92, 97, 84, 43, 79, 27, 46, 89, 25, 81, 25, 48, 43, 86, 48, 57, 14, 89, 43, 43, 19, 92, 14, 27, 9, 78, 4, 16, 3, 29, 3, 47, 6, 42, 21, 39, 5, 72, 34, 98, 88, 90, 75, 77, 59, 49, 32, 82]\n",
    "print(optimal_steps) # <-- min of max distance reward streamline 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[80, 88, 54, 96, 59, 37, 54, 37, 67, 91, 62, 78, 64, 70, 64, 62, 69, 83, 56, 59, 59, 53, 42, 53, 53, 56, 79, 58, 87, 60, 87, 58, 92, 52, 46, 58, 38, 58, 30, 58, 38, 84, 17, 55, 30, 76, 25, 76, 17, 76, 17, 81, 30, 86, 48, 65, 27, 97, 14, 84, 6, 97, 14, 89, 3, 27, 8, 19, 13, 19, 13, 29, 8, 96, 2, 88, 31, 47, 26, 59, 5, 72, 72, 85, 61, 39]\n"
     ]
    }
   ],
   "source": [
    "optimal_steps = [80, 88, 54, 96, 59, 37, 54, 37, 67, 91, 62, 78, 64, 70, 64, 62, 69, 83, 56, 59, 59, 53, 42, 53, 53, 56, 79, 58, 87, 60, 87, 58, 92, 52, 46, 58, 38, 58, 30, 58, 38, 84, 17, 55, 30, 76, 25, 76, 17, 76, 17, 81, 30, 86, 48, 65, 27, 97, 14, 84, 6, 97, 14, 89, 3, 27, 8, 19, 13, 19, 13, 29, 8, 96, 2, 88, 31, 47, 26, 59, 5, 72, 72, 85, 61, 39]\n",
    "print(optimal_steps) # <-- min reward"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[47.870224 74.80299  26.640089] tensor([47.8702, 74.8030, 26.6401])\n"
     ]
    },
    {
     "ename": "NameError",
     "evalue": "name 'optimal_steps_58' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-52-c95414681406>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0mlen_line\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0menv\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreferenceStreamline_ijk\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[0;31m#all_states.append(env.state.getCoordinate())\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 8\u001b[0;31m \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0moptimal_steps_58\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      9\u001b[0m     \u001b[0mnext_state\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mreward\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mterminal\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0menv\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     10\u001b[0m     \u001b[0;31m#distance = lineseg_dist(next_state.getCoordinate().numpy(), referenceLine[step-1].numpy(), referenceLine[np.min([step, len(referenceLine)-1])].numpy())\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'optimal_steps_58' is not defined"
     ]
    }
   ],
   "source": [
    "env.reset()\n",
    "print(env.state.getCoordinate().numpy(), env.referenceStreamline_ijk[0])\n",
    "step = 1\n",
    "all_distances = []\n",
    "all_states = []\n",
    "len_line = len(env.referenceStreamline_ijk)-1\n",
    "#all_states.append(env.state.getCoordinate())\n",
    "for i in optimal_steps_58:\n",
    "    next_state, reward, terminal = env.step(i)\n",
    "    #distance = lineseg_dist(next_state.getCoordinate().numpy(), referenceLine[step-1].numpy(), referenceLine[np.min([step, len(referenceLine)-1])].numpy())\n",
    "    #distance = 2 + (distance/10)\n",
    "    distance = ((next_state.getCoordinate()[0] - env.referenceStreamline_ijk[np.min([env.stepCounter, len_line])][0])**2 \\\n",
    "                      + (next_state.getCoordinate()[1] - env.referenceStreamline_ijk[np.min([env.stepCounter, len_line])][1])**2 \\\n",
    "                      + (next_state.getCoordinate()[2] - env.referenceStreamline_ijk[np.min([env.stepCounter, len_line])][2])**2)\n",
    "    print(step, i, next_state.getCoordinate().numpy(), env.referenceStreamline_ijk[np.min([env.stepCounter,len_line])].numpy(), reward, distance.item(), distance <= 0.55**2)\n",
    "    all_distances.append(distance)\n",
    "    all_states.append(next_state.getCoordinate())\n",
    "    #if distance < 0.71:\n",
    "    #    reward = 1 - distance\n",
    "    #    #print(reward)\n",
    "    #    if reward < 0.3:\n",
    "    #        reward = 1\n",
    "    step += 1\n",
    "\n",
    "print(np.min(all_distances), np.max(all_distances), np.sum(all_distances))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([ 76.4527, 108.1185,  91.8665])\n",
      "tensor(108.1185)\n"
     ]
    }
   ],
   "source": [
    "print(env.referenceStreamline_ijk[4])\n",
    "print(env.referenceStreamline_ijk.T[1][4])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([74.9079, 68.6542,  6.6088], dtype=torch.float64) tensor([47.8702, 74.8030, 26.6401])\n",
      "tensor(1170.0941, dtype=torch.float64)\n",
      "tensor([ 74.5620, 107.8060,  92.8878], dtype=torch.float64) tensor([47.2869, 74.2859, 26.4604])\n",
      "tensor(6280.1197, dtype=torch.float64)\n",
      "tensor([ 75.4726, 107.7309,  92.4814], dtype=torch.float64) tensor([46.8734, 73.6724, 26.1561])\n",
      "tensor(6376.9381, dtype=torch.float64)\n",
      "tensor([ 76.3832, 107.6557,  92.0750], dtype=torch.float64) tensor([46.4598, 73.0589, 25.8518])\n",
      "tensor(6477.8643, dtype=torch.float64)\n",
      "tensor([ 77.2392, 107.9117,  91.6260], dtype=torch.float64) tensor([46.0288, 72.4149, 25.6528])\n",
      "tensor(6586.5720, dtype=torch.float64)\n",
      "tensor([ 77.9332, 108.4815,  91.1857], dtype=torch.float64) tensor([45.6903, 71.7341, 25.4040])\n",
      "tensor(6717.2005, dtype=torch.float64)\n",
      "tensor([ 78.6165, 109.1998,  91.0555], dtype=torch.float64) tensor([45.4503, 71.0306, 25.1082])\n",
      "tensor(6905.9244, dtype=torch.float64)\n",
      "tensor([ 79.2999, 109.9182,  90.9252], dtype=torch.float64) tensor([45.1343, 70.3865, 24.7542])\n",
      "tensor(7108.6405, dtype=torch.float64)\n",
      "tensor([ 79.2999, 109.9182,  90.9252], dtype=torch.float64) tensor([44.8484, 69.7906, 24.3036])\n",
      "tensor(7235.5771, dtype=torch.float64)\n"
     ]
    },
    {
     "data": {
      "application/javascript": [
       "/* Put everything inside the global mpl namespace */\n",
       "window.mpl = {};\n",
       "\n",
       "\n",
       "mpl.get_websocket_type = function() {\n",
       "    if (typeof(WebSocket) !== 'undefined') {\n",
       "        return WebSocket;\n",
       "    } else if (typeof(MozWebSocket) !== 'undefined') {\n",
       "        return MozWebSocket;\n",
       "    } else {\n",
       "        alert('Your browser does not have WebSocket support. ' +\n",
       "              'Please try Chrome, Safari or Firefox  6. ' +\n",
       "              'Firefox 4 and 5 are also supported but you ' +\n",
       "              'have to enable WebSockets in about:config.');\n",
       "    };\n",
       "}\n",
       "\n",
       "mpl.figure = function(figure_id, websocket, ondownload, parent_element) {\n",
       "    this.id = figure_id;\n",
       "\n",
       "    this.ws = websocket;\n",
       "\n",
       "    this.supports_binary = (this.ws.binaryType != undefined);\n",
       "\n",
       "    if (!this.supports_binary) {\n",
       "        var warnings = document.getElementById(\"mpl-warnings\");\n",
       "        if (warnings) {\n",
       "            warnings.style.display = 'block';\n",
       "            warnings.textContent = (\n",
       "                \"This browser does not support binary websocket messages. \" +\n",
       "                    \"Performance may be slow.\");\n",
       "        }\n",
       "    }\n",
       "\n",
       "    this.imageObj = new Image();\n",
       "\n",
       "    this.context = undefined;\n",
       "    this.message = undefined;\n",
       "    this.canvas = undefined;\n",
       "    this.rubberband_canvas = undefined;\n",
       "    this.rubberband_context = undefined;\n",
       "    this.format_dropdown = undefined;\n",
       "\n",
       "    this.image_mode = 'full';\n",
       "\n",
       "    this.root = $('<div/>');\n",
       "    this._root_extra_style(this.root)\n",
       "    this.root.attr('style', 'display: inline-block');\n",
       "\n",
       "    $(parent_element).append(this.root);\n",
       "\n",
       "    this._init_header(this);\n",
       "    this._init_canvas(this);\n",
       "    this._init_toolbar(this);\n",
       "\n",
       "    var fig = this;\n",
       "\n",
       "    this.waiting = false;\n",
       "\n",
       "    this.ws.onopen =  function () {\n",
       "            fig.send_message(\"supports_binary\", {value: fig.supports_binary});\n",
       "            fig.send_message(\"send_image_mode\", {});\n",
       "            if (mpl.ratio != 1) {\n",
       "                fig.send_message(\"set_dpi_ratio\", {'dpi_ratio': mpl.ratio});\n",
       "            }\n",
       "            fig.send_message(\"refresh\", {});\n",
       "        }\n",
       "\n",
       "    this.imageObj.onload = function() {\n",
       "            if (fig.image_mode == 'full') {\n",
       "                // Full images could contain transparency (where diff images\n",
       "                // almost always do), so we need to clear the canvas so that\n",
       "                // there is no ghosting.\n",
       "                fig.context.clearRect(0, 0, fig.canvas.width, fig.canvas.height);\n",
       "            }\n",
       "            fig.context.drawImage(fig.imageObj, 0, 0);\n",
       "        };\n",
       "\n",
       "    this.imageObj.onunload = function() {\n",
       "        fig.ws.close();\n",
       "    }\n",
       "\n",
       "    this.ws.onmessage = this._make_on_message_function(this);\n",
       "\n",
       "    this.ondownload = ondownload;\n",
       "}\n",
       "\n",
       "mpl.figure.prototype._init_header = function() {\n",
       "    var titlebar = $(\n",
       "        '<div class=\"ui-dialog-titlebar ui-widget-header ui-corner-all ' +\n",
       "        'ui-helper-clearfix\"/>');\n",
       "    var titletext = $(\n",
       "        '<div class=\"ui-dialog-title\" style=\"width: 100%; ' +\n",
       "        'text-align: center; padding: 3px;\"/>');\n",
       "    titlebar.append(titletext)\n",
       "    this.root.append(titlebar);\n",
       "    this.header = titletext[0];\n",
       "}\n",
       "\n",
       "\n",
       "\n",
       "mpl.figure.prototype._canvas_extra_style = function(canvas_div) {\n",
       "\n",
       "}\n",
       "\n",
       "\n",
       "mpl.figure.prototype._root_extra_style = function(canvas_div) {\n",
       "\n",
       "}\n",
       "\n",
       "mpl.figure.prototype._init_canvas = function() {\n",
       "    var fig = this;\n",
       "\n",
       "    var canvas_div = $('<div/>');\n",
       "\n",
       "    canvas_div.attr('style', 'position: relative; clear: both; outline: 0');\n",
       "\n",
       "    function canvas_keyboard_event(event) {\n",
       "        return fig.key_event(event, event['data']);\n",
       "    }\n",
       "\n",
       "    canvas_div.keydown('key_press', canvas_keyboard_event);\n",
       "    canvas_div.keyup('key_release', canvas_keyboard_event);\n",
       "    this.canvas_div = canvas_div\n",
       "    this._canvas_extra_style(canvas_div)\n",
       "    this.root.append(canvas_div);\n",
       "\n",
       "    var canvas = $('<canvas/>');\n",
       "    canvas.addClass('mpl-canvas');\n",
       "    canvas.attr('style', \"left: 0; top: 0; z-index: 0; outline: 0\")\n",
       "\n",
       "    this.canvas = canvas[0];\n",
       "    this.context = canvas[0].getContext(\"2d\");\n",
       "\n",
       "    var backingStore = this.context.backingStorePixelRatio ||\n",
       "\tthis.context.webkitBackingStorePixelRatio ||\n",
       "\tthis.context.mozBackingStorePixelRatio ||\n",
       "\tthis.context.msBackingStorePixelRatio ||\n",
       "\tthis.context.oBackingStorePixelRatio ||\n",
       "\tthis.context.backingStorePixelRatio || 1;\n",
       "\n",
       "    mpl.ratio = (window.devicePixelRatio || 1) / backingStore;\n",
       "\n",
       "    var rubberband = $('<canvas/>');\n",
       "    rubberband.attr('style', \"position: absolute; left: 0; top: 0; z-index: 1;\")\n",
       "\n",
       "    var pass_mouse_events = true;\n",
       "\n",
       "    canvas_div.resizable({\n",
       "        start: function(event, ui) {\n",
       "            pass_mouse_events = false;\n",
       "        },\n",
       "        resize: function(event, ui) {\n",
       "            fig.request_resize(ui.size.width, ui.size.height);\n",
       "        },\n",
       "        stop: function(event, ui) {\n",
       "            pass_mouse_events = true;\n",
       "            fig.request_resize(ui.size.width, ui.size.height);\n",
       "        },\n",
       "    });\n",
       "\n",
       "    function mouse_event_fn(event) {\n",
       "        if (pass_mouse_events)\n",
       "            return fig.mouse_event(event, event['data']);\n",
       "    }\n",
       "\n",
       "    rubberband.mousedown('button_press', mouse_event_fn);\n",
       "    rubberband.mouseup('button_release', mouse_event_fn);\n",
       "    // Throttle sequential mouse events to 1 every 20ms.\n",
       "    rubberband.mousemove('motion_notify', mouse_event_fn);\n",
       "\n",
       "    rubberband.mouseenter('figure_enter', mouse_event_fn);\n",
       "    rubberband.mouseleave('figure_leave', mouse_event_fn);\n",
       "\n",
       "    canvas_div.on(\"wheel\", function (event) {\n",
       "        event = event.originalEvent;\n",
       "        event['data'] = 'scroll'\n",
       "        if (event.deltaY < 0) {\n",
       "            event.step = 1;\n",
       "        } else {\n",
       "            event.step = -1;\n",
       "        }\n",
       "        mouse_event_fn(event);\n",
       "    });\n",
       "\n",
       "    canvas_div.append(canvas);\n",
       "    canvas_div.append(rubberband);\n",
       "\n",
       "    this.rubberband = rubberband;\n",
       "    this.rubberband_canvas = rubberband[0];\n",
       "    this.rubberband_context = rubberband[0].getContext(\"2d\");\n",
       "    this.rubberband_context.strokeStyle = \"#000000\";\n",
       "\n",
       "    this._resize_canvas = function(width, height) {\n",
       "        // Keep the size of the canvas, canvas container, and rubber band\n",
       "        // canvas in synch.\n",
       "        canvas_div.css('width', width)\n",
       "        canvas_div.css('height', height)\n",
       "\n",
       "        canvas.attr('width', width * mpl.ratio);\n",
       "        canvas.attr('height', height * mpl.ratio);\n",
       "        canvas.attr('style', 'width: ' + width + 'px; height: ' + height + 'px;');\n",
       "\n",
       "        rubberband.attr('width', width);\n",
       "        rubberband.attr('height', height);\n",
       "    }\n",
       "\n",
       "    // Set the figure to an initial 600x600px, this will subsequently be updated\n",
       "    // upon first draw.\n",
       "    this._resize_canvas(600, 600);\n",
       "\n",
       "    // Disable right mouse context menu.\n",
       "    $(this.rubberband_canvas).bind(\"contextmenu\",function(e){\n",
       "        return false;\n",
       "    });\n",
       "\n",
       "    function set_focus () {\n",
       "        canvas.focus();\n",
       "        canvas_div.focus();\n",
       "    }\n",
       "\n",
       "    window.setTimeout(set_focus, 100);\n",
       "}\n",
       "\n",
       "mpl.figure.prototype._init_toolbar = function() {\n",
       "    var fig = this;\n",
       "\n",
       "    var nav_element = $('<div/>');\n",
       "    nav_element.attr('style', 'width: 100%');\n",
       "    this.root.append(nav_element);\n",
       "\n",
       "    // Define a callback function for later on.\n",
       "    function toolbar_event(event) {\n",
       "        return fig.toolbar_button_onclick(event['data']);\n",
       "    }\n",
       "    function toolbar_mouse_event(event) {\n",
       "        return fig.toolbar_button_onmouseover(event['data']);\n",
       "    }\n",
       "\n",
       "    for(var toolbar_ind in mpl.toolbar_items) {\n",
       "        var name = mpl.toolbar_items[toolbar_ind][0];\n",
       "        var tooltip = mpl.toolbar_items[toolbar_ind][1];\n",
       "        var image = mpl.toolbar_items[toolbar_ind][2];\n",
       "        var method_name = mpl.toolbar_items[toolbar_ind][3];\n",
       "\n",
       "        if (!name) {\n",
       "            // put a spacer in here.\n",
       "            continue;\n",
       "        }\n",
       "        var button = $('<button/>');\n",
       "        button.addClass('ui-button ui-widget ui-state-default ui-corner-all ' +\n",
       "                        'ui-button-icon-only');\n",
       "        button.attr('role', 'button');\n",
       "        button.attr('aria-disabled', 'false');\n",
       "        button.click(method_name, toolbar_event);\n",
       "        button.mouseover(tooltip, toolbar_mouse_event);\n",
       "\n",
       "        var icon_img = $('<span/>');\n",
       "        icon_img.addClass('ui-button-icon-primary ui-icon');\n",
       "        icon_img.addClass(image);\n",
       "        icon_img.addClass('ui-corner-all');\n",
       "\n",
       "        var tooltip_span = $('<span/>');\n",
       "        tooltip_span.addClass('ui-button-text');\n",
       "        tooltip_span.html(tooltip);\n",
       "\n",
       "        button.append(icon_img);\n",
       "        button.append(tooltip_span);\n",
       "\n",
       "        nav_element.append(button);\n",
       "    }\n",
       "\n",
       "    var fmt_picker_span = $('<span/>');\n",
       "\n",
       "    var fmt_picker = $('<select/>');\n",
       "    fmt_picker.addClass('mpl-toolbar-option ui-widget ui-widget-content');\n",
       "    fmt_picker_span.append(fmt_picker);\n",
       "    nav_element.append(fmt_picker_span);\n",
       "    this.format_dropdown = fmt_picker[0];\n",
       "\n",
       "    for (var ind in mpl.extensions) {\n",
       "        var fmt = mpl.extensions[ind];\n",
       "        var option = $(\n",
       "            '<option/>', {selected: fmt === mpl.default_extension}).html(fmt);\n",
       "        fmt_picker.append(option);\n",
       "    }\n",
       "\n",
       "    // Add hover states to the ui-buttons\n",
       "    $( \".ui-button\" ).hover(\n",
       "        function() { $(this).addClass(\"ui-state-hover\");},\n",
       "        function() { $(this).removeClass(\"ui-state-hover\");}\n",
       "    );\n",
       "\n",
       "    var status_bar = $('<span class=\"mpl-message\"/>');\n",
       "    nav_element.append(status_bar);\n",
       "    this.message = status_bar[0];\n",
       "}\n",
       "\n",
       "mpl.figure.prototype.request_resize = function(x_pixels, y_pixels) {\n",
       "    // Request matplotlib to resize the figure. Matplotlib will then trigger a resize in the client,\n",
       "    // which will in turn request a refresh of the image.\n",
       "    this.send_message('resize', {'width': x_pixels, 'height': y_pixels});\n",
       "}\n",
       "\n",
       "mpl.figure.prototype.send_message = function(type, properties) {\n",
       "    properties['type'] = type;\n",
       "    properties['figure_id'] = this.id;\n",
       "    this.ws.send(JSON.stringify(properties));\n",
       "}\n",
       "\n",
       "mpl.figure.prototype.send_draw_message = function() {\n",
       "    if (!this.waiting) {\n",
       "        this.waiting = true;\n",
       "        this.ws.send(JSON.stringify({type: \"draw\", figure_id: this.id}));\n",
       "    }\n",
       "}\n",
       "\n",
       "\n",
       "mpl.figure.prototype.handle_save = function(fig, msg) {\n",
       "    var format_dropdown = fig.format_dropdown;\n",
       "    var format = format_dropdown.options[format_dropdown.selectedIndex].value;\n",
       "    fig.ondownload(fig, format);\n",
       "}\n",
       "\n",
       "\n",
       "mpl.figure.prototype.handle_resize = function(fig, msg) {\n",
       "    var size = msg['size'];\n",
       "    if (size[0] != fig.canvas.width || size[1] != fig.canvas.height) {\n",
       "        fig._resize_canvas(size[0], size[1]);\n",
       "        fig.send_message(\"refresh\", {});\n",
       "    };\n",
       "}\n",
       "\n",
       "mpl.figure.prototype.handle_rubberband = function(fig, msg) {\n",
       "    var x0 = msg['x0'] / mpl.ratio;\n",
       "    var y0 = (fig.canvas.height - msg['y0']) / mpl.ratio;\n",
       "    var x1 = msg['x1'] / mpl.ratio;\n",
       "    var y1 = (fig.canvas.height - msg['y1']) / mpl.ratio;\n",
       "    x0 = Math.floor(x0) + 0.5;\n",
       "    y0 = Math.floor(y0) + 0.5;\n",
       "    x1 = Math.floor(x1) + 0.5;\n",
       "    y1 = Math.floor(y1) + 0.5;\n",
       "    var min_x = Math.min(x0, x1);\n",
       "    var min_y = Math.min(y0, y1);\n",
       "    var width = Math.abs(x1 - x0);\n",
       "    var height = Math.abs(y1 - y0);\n",
       "\n",
       "    fig.rubberband_context.clearRect(\n",
       "        0, 0, fig.canvas.width / mpl.ratio, fig.canvas.height / mpl.ratio);\n",
       "\n",
       "    fig.rubberband_context.strokeRect(min_x, min_y, width, height);\n",
       "}\n",
       "\n",
       "mpl.figure.prototype.handle_figure_label = function(fig, msg) {\n",
       "    // Updates the figure title.\n",
       "    fig.header.textContent = msg['label'];\n",
       "}\n",
       "\n",
       "mpl.figure.prototype.handle_cursor = function(fig, msg) {\n",
       "    var cursor = msg['cursor'];\n",
       "    switch(cursor)\n",
       "    {\n",
       "    case 0:\n",
       "        cursor = 'pointer';\n",
       "        break;\n",
       "    case 1:\n",
       "        cursor = 'default';\n",
       "        break;\n",
       "    case 2:\n",
       "        cursor = 'crosshair';\n",
       "        break;\n",
       "    case 3:\n",
       "        cursor = 'move';\n",
       "        break;\n",
       "    }\n",
       "    fig.rubberband_canvas.style.cursor = cursor;\n",
       "}\n",
       "\n",
       "mpl.figure.prototype.handle_message = function(fig, msg) {\n",
       "    fig.message.textContent = msg['message'];\n",
       "}\n",
       "\n",
       "mpl.figure.prototype.handle_draw = function(fig, msg) {\n",
       "    // Request the server to send over a new figure.\n",
       "    fig.send_draw_message();\n",
       "}\n",
       "\n",
       "mpl.figure.prototype.handle_image_mode = function(fig, msg) {\n",
       "    fig.image_mode = msg['mode'];\n",
       "}\n",
       "\n",
       "mpl.figure.prototype.updated_canvas_event = function() {\n",
       "    // Called whenever the canvas gets updated.\n",
       "    this.send_message(\"ack\", {});\n",
       "}\n",
       "\n",
       "// A function to construct a web socket function for onmessage handling.\n",
       "// Called in the figure constructor.\n",
       "mpl.figure.prototype._make_on_message_function = function(fig) {\n",
       "    return function socket_on_message(evt) {\n",
       "        if (evt.data instanceof Blob) {\n",
       "            /* FIXME: We get \"Resource interpreted as Image but\n",
       "             * transferred with MIME type text/plain:\" errors on\n",
       "             * Chrome.  But how to set the MIME type?  It doesn't seem\n",
       "             * to be part of the websocket stream */\n",
       "            evt.data.type = \"image/png\";\n",
       "\n",
       "            /* Free the memory for the previous frames */\n",
       "            if (fig.imageObj.src) {\n",
       "                (window.URL || window.webkitURL).revokeObjectURL(\n",
       "                    fig.imageObj.src);\n",
       "            }\n",
       "\n",
       "            fig.imageObj.src = (window.URL || window.webkitURL).createObjectURL(\n",
       "                evt.data);\n",
       "            fig.updated_canvas_event();\n",
       "            fig.waiting = false;\n",
       "            return;\n",
       "        }\n",
       "        else if (typeof evt.data === 'string' && evt.data.slice(0, 21) == \"data:image/png;base64\") {\n",
       "            fig.imageObj.src = evt.data;\n",
       "            fig.updated_canvas_event();\n",
       "            fig.waiting = false;\n",
       "            return;\n",
       "        }\n",
       "\n",
       "        var msg = JSON.parse(evt.data);\n",
       "        var msg_type = msg['type'];\n",
       "\n",
       "        // Call the  \"handle_{type}\" callback, which takes\n",
       "        // the figure and JSON message as its only arguments.\n",
       "        try {\n",
       "            var callback = fig[\"handle_\" + msg_type];\n",
       "        } catch (e) {\n",
       "            console.log(\"No handler for the '\" + msg_type + \"' message type: \", msg);\n",
       "            return;\n",
       "        }\n",
       "\n",
       "        if (callback) {\n",
       "            try {\n",
       "                // console.log(\"Handling '\" + msg_type + \"' message: \", msg);\n",
       "                callback(fig, msg);\n",
       "            } catch (e) {\n",
       "                console.log(\"Exception inside the 'handler_\" + msg_type + \"' callback:\", e, e.stack, msg);\n",
       "            }\n",
       "        }\n",
       "    };\n",
       "}\n",
       "\n",
       "// from http://stackoverflow.com/questions/1114465/getting-mouse-location-in-canvas\n",
       "mpl.findpos = function(e) {\n",
       "    //this section is from http://www.quirksmode.org/js/events_properties.html\n",
       "    var targ;\n",
       "    if (!e)\n",
       "        e = window.event;\n",
       "    if (e.target)\n",
       "        targ = e.target;\n",
       "    else if (e.srcElement)\n",
       "        targ = e.srcElement;\n",
       "    if (targ.nodeType == 3) // defeat Safari bug\n",
       "        targ = targ.parentNode;\n",
       "\n",
       "    // jQuery normalizes the pageX and pageY\n",
       "    // pageX,Y are the mouse positions relative to the document\n",
       "    // offset() returns the position of the element relative to the document\n",
       "    var x = e.pageX - $(targ).offset().left;\n",
       "    var y = e.pageY - $(targ).offset().top;\n",
       "\n",
       "    return {\"x\": x, \"y\": y};\n",
       "};\n",
       "\n",
       "/*\n",
       " * return a copy of an object with only non-object keys\n",
       " * we need this to avoid circular references\n",
       " * http://stackoverflow.com/a/24161582/3208463\n",
       " */\n",
       "function simpleKeys (original) {\n",
       "  return Object.keys(original).reduce(function (obj, key) {\n",
       "    if (typeof original[key] !== 'object')\n",
       "        obj[key] = original[key]\n",
       "    return obj;\n",
       "  }, {});\n",
       "}\n",
       "\n",
       "mpl.figure.prototype.mouse_event = function(event, name) {\n",
       "    var canvas_pos = mpl.findpos(event)\n",
       "\n",
       "    if (name === 'button_press')\n",
       "    {\n",
       "        this.canvas.focus();\n",
       "        this.canvas_div.focus();\n",
       "    }\n",
       "\n",
       "    var x = canvas_pos.x * mpl.ratio;\n",
       "    var y = canvas_pos.y * mpl.ratio;\n",
       "\n",
       "    this.send_message(name, {x: x, y: y, button: event.button,\n",
       "                             step: event.step,\n",
       "                             guiEvent: simpleKeys(event)});\n",
       "\n",
       "    /* This prevents the web browser from automatically changing to\n",
       "     * the text insertion cursor when the button is pressed.  We want\n",
       "     * to control all of the cursor setting manually through the\n",
       "     * 'cursor' event from matplotlib */\n",
       "    event.preventDefault();\n",
       "    return false;\n",
       "}\n",
       "\n",
       "mpl.figure.prototype._key_event_extra = function(event, name) {\n",
       "    // Handle any extra behaviour associated with a key event\n",
       "}\n",
       "\n",
       "mpl.figure.prototype.key_event = function(event, name) {\n",
       "\n",
       "    // Prevent repeat events\n",
       "    if (name == 'key_press')\n",
       "    {\n",
       "        if (event.which === this._key)\n",
       "            return;\n",
       "        else\n",
       "            this._key = event.which;\n",
       "    }\n",
       "    if (name == 'key_release')\n",
       "        this._key = null;\n",
       "\n",
       "    var value = '';\n",
       "    if (event.ctrlKey && event.which != 17)\n",
       "        value += \"ctrl+\";\n",
       "    if (event.altKey && event.which != 18)\n",
       "        value += \"alt+\";\n",
       "    if (event.shiftKey && event.which != 16)\n",
       "        value += \"shift+\";\n",
       "\n",
       "    value += 'k';\n",
       "    value += event.which.toString();\n",
       "\n",
       "    this._key_event_extra(event, name);\n",
       "\n",
       "    this.send_message(name, {key: value,\n",
       "                             guiEvent: simpleKeys(event)});\n",
       "    return false;\n",
       "}\n",
       "\n",
       "mpl.figure.prototype.toolbar_button_onclick = function(name) {\n",
       "    if (name == 'download') {\n",
       "        this.handle_save(this, null);\n",
       "    } else {\n",
       "        this.send_message(\"toolbar_button\", {name: name});\n",
       "    }\n",
       "};\n",
       "\n",
       "mpl.figure.prototype.toolbar_button_onmouseover = function(tooltip) {\n",
       "    this.message.textContent = tooltip;\n",
       "};\n",
       "mpl.toolbar_items = [[\"Home\", \"Reset original view\", \"fa fa-home icon-home\", \"home\"], [\"Back\", \"Back to previous view\", \"fa fa-arrow-left icon-arrow-left\", \"back\"], [\"Forward\", \"Forward to next view\", \"fa fa-arrow-right icon-arrow-right\", \"forward\"], [\"\", \"\", \"\", \"\"], [\"Pan\", \"Pan axes with left mouse, zoom with right\", \"fa fa-arrows icon-move\", \"pan\"], [\"Zoom\", \"Zoom to rectangle\", \"fa fa-square-o icon-check-empty\", \"zoom\"], [\"\", \"\", \"\", \"\"], [\"Download\", \"Download plot\", \"fa fa-floppy-o icon-save\", \"download\"]];\n",
       "\n",
       "mpl.extensions = [\"eps\", \"jpeg\", \"pdf\", \"png\", \"ps\", \"raw\", \"svg\", \"tif\"];\n",
       "\n",
       "mpl.default_extension = \"png\";var comm_websocket_adapter = function(comm) {\n",
       "    // Create a \"websocket\"-like object which calls the given IPython comm\n",
       "    // object with the appropriate methods. Currently this is a non binary\n",
       "    // socket, so there is still some room for performance tuning.\n",
       "    var ws = {};\n",
       "\n",
       "    ws.close = function() {\n",
       "        comm.close()\n",
       "    };\n",
       "    ws.send = function(m) {\n",
       "        //console.log('sending', m);\n",
       "        comm.send(m);\n",
       "    };\n",
       "    // Register the callback with on_msg.\n",
       "    comm.on_msg(function(msg) {\n",
       "        //console.log('receiving', msg['content']['data'], msg);\n",
       "        // Pass the mpl event to the overridden (by mpl) onmessage function.\n",
       "        ws.onmessage(msg['content']['data'])\n",
       "    });\n",
       "    return ws;\n",
       "}\n",
       "\n",
       "mpl.mpl_figure_comm = function(comm, msg) {\n",
       "    // This is the function which gets called when the mpl process\n",
       "    // starts-up an IPython Comm through the \"matplotlib\" channel.\n",
       "\n",
       "    var id = msg.content.data.id;\n",
       "    // Get hold of the div created by the display call when the Comm\n",
       "    // socket was opened in Python.\n",
       "    var element = $(\"#\" + id);\n",
       "    var ws_proxy = comm_websocket_adapter(comm)\n",
       "\n",
       "    function ondownload(figure, format) {\n",
       "        window.open(figure.imageObj.src);\n",
       "    }\n",
       "\n",
       "    var fig = new mpl.figure(id, ws_proxy,\n",
       "                           ondownload,\n",
       "                           element.get(0));\n",
       "\n",
       "    // Call onopen now - mpl needs it, as it is assuming we've passed it a real\n",
       "    // web socket which is closed, not our websocket->open comm proxy.\n",
       "    ws_proxy.onopen();\n",
       "\n",
       "    fig.parent_element = element.get(0);\n",
       "    fig.cell_info = mpl.find_output_cell(\"<div id='\" + id + \"'></div>\");\n",
       "    if (!fig.cell_info) {\n",
       "        console.error(\"Failed to find cell for figure\", id, fig);\n",
       "        return;\n",
       "    }\n",
       "\n",
       "    var output_index = fig.cell_info[2]\n",
       "    var cell = fig.cell_info[0];\n",
       "\n",
       "};\n",
       "\n",
       "mpl.figure.prototype.handle_close = function(fig, msg) {\n",
       "    var width = fig.canvas.width/mpl.ratio\n",
       "    fig.root.unbind('remove')\n",
       "\n",
       "    // Update the output cell to use the data from the current canvas.\n",
       "    fig.push_to_output();\n",
       "    var dataURL = fig.canvas.toDataURL();\n",
       "    // Re-enable the keyboard manager in IPython - without this line, in FF,\n",
       "    // the notebook keyboard shortcuts fail.\n",
       "    IPython.keyboard_manager.enable()\n",
       "    $(fig.parent_element).html('<img src=\"' + dataURL + '\" width=\"' + width + '\">');\n",
       "    fig.close_ws(fig, msg);\n",
       "}\n",
       "\n",
       "mpl.figure.prototype.close_ws = function(fig, msg){\n",
       "    fig.send_message('closing', msg);\n",
       "    // fig.ws.close()\n",
       "}\n",
       "\n",
       "mpl.figure.prototype.push_to_output = function(remove_interactive) {\n",
       "    // Turn the data on the canvas into data in the output cell.\n",
       "    var width = this.canvas.width/mpl.ratio\n",
       "    var dataURL = this.canvas.toDataURL();\n",
       "    this.cell_info[1]['text/html'] = '<img src=\"' + dataURL + '\" width=\"' + width + '\">';\n",
       "}\n",
       "\n",
       "mpl.figure.prototype.updated_canvas_event = function() {\n",
       "    // Tell IPython that the notebook contents must change.\n",
       "    IPython.notebook.set_dirty(true);\n",
       "    this.send_message(\"ack\", {});\n",
       "    var fig = this;\n",
       "    // Wait a second, then push the new image to the DOM so\n",
       "    // that it is saved nicely (might be nice to debounce this).\n",
       "    setTimeout(function () { fig.push_to_output() }, 1000);\n",
       "}\n",
       "\n",
       "mpl.figure.prototype._init_toolbar = function() {\n",
       "    var fig = this;\n",
       "\n",
       "    var nav_element = $('<div/>');\n",
       "    nav_element.attr('style', 'width: 100%');\n",
       "    this.root.append(nav_element);\n",
       "\n",
       "    // Define a callback function for later on.\n",
       "    function toolbar_event(event) {\n",
       "        return fig.toolbar_button_onclick(event['data']);\n",
       "    }\n",
       "    function toolbar_mouse_event(event) {\n",
       "        return fig.toolbar_button_onmouseover(event['data']);\n",
       "    }\n",
       "\n",
       "    for(var toolbar_ind in mpl.toolbar_items){\n",
       "        var name = mpl.toolbar_items[toolbar_ind][0];\n",
       "        var tooltip = mpl.toolbar_items[toolbar_ind][1];\n",
       "        var image = mpl.toolbar_items[toolbar_ind][2];\n",
       "        var method_name = mpl.toolbar_items[toolbar_ind][3];\n",
       "\n",
       "        if (!name) { continue; };\n",
       "\n",
       "        var button = $('<button class=\"btn btn-default\" href=\"#\" title=\"' + name + '\"><i class=\"fa ' + image + ' fa-lg\"></i></button>');\n",
       "        button.click(method_name, toolbar_event);\n",
       "        button.mouseover(tooltip, toolbar_mouse_event);\n",
       "        nav_element.append(button);\n",
       "    }\n",
       "\n",
       "    // Add the status bar.\n",
       "    var status_bar = $('<span class=\"mpl-message\" style=\"text-align:right; float: right;\"/>');\n",
       "    nav_element.append(status_bar);\n",
       "    this.message = status_bar[0];\n",
       "\n",
       "    // Add the close button to the window.\n",
       "    var buttongrp = $('<div class=\"btn-group inline pull-right\"></div>');\n",
       "    var button = $('<button class=\"btn btn-mini btn-primary\" href=\"#\" title=\"Stop Interaction\"><i class=\"fa fa-power-off icon-remove icon-large\"></i></button>');\n",
       "    button.click(function (evt) { fig.handle_close(fig, {}); } );\n",
       "    button.mouseover('Stop Interaction', toolbar_mouse_event);\n",
       "    buttongrp.append(button);\n",
       "    var titlebar = this.root.find($('.ui-dialog-titlebar'));\n",
       "    titlebar.prepend(buttongrp);\n",
       "}\n",
       "\n",
       "mpl.figure.prototype._root_extra_style = function(el){\n",
       "    var fig = this\n",
       "    el.on(\"remove\", function(){\n",
       "\tfig.close_ws(fig, {});\n",
       "    });\n",
       "}\n",
       "\n",
       "mpl.figure.prototype._canvas_extra_style = function(el){\n",
       "    // this is important to make the div 'focusable\n",
       "    el.attr('tabindex', 0)\n",
       "    // reach out to IPython and tell the keyboard manager to turn it's self\n",
       "    // off when our div gets focus\n",
       "\n",
       "    // location in version 3\n",
       "    if (IPython.notebook.keyboard_manager) {\n",
       "        IPython.notebook.keyboard_manager.register_events(el);\n",
       "    }\n",
       "    else {\n",
       "        // location in version 2\n",
       "        IPython.keyboard_manager.register_events(el);\n",
       "    }\n",
       "\n",
       "}\n",
       "\n",
       "mpl.figure.prototype._key_event_extra = function(event, name) {\n",
       "    var manager = IPython.notebook.keyboard_manager;\n",
       "    if (!manager)\n",
       "        manager = IPython.keyboard_manager;\n",
       "\n",
       "    // Check for shift+enter\n",
       "    if (event.shiftKey && event.which == 13) {\n",
       "        this.canvas_div.blur();\n",
       "        // select the cell after this one\n",
       "        var index = IPython.notebook.find_cell_index(this.cell_info[0]);\n",
       "        IPython.notebook.select(index + 1);\n",
       "    }\n",
       "}\n",
       "\n",
       "mpl.figure.prototype.handle_save = function(fig, msg) {\n",
       "    fig.ondownload(fig, null);\n",
       "}\n",
       "\n",
       "\n",
       "mpl.find_output_cell = function(html_output) {\n",
       "    // Return the cell and output element which can be found *uniquely* in the notebook.\n",
       "    // Note - this is a bit hacky, but it is done because the \"notebook_saving.Notebook\"\n",
       "    // IPython event is triggered only after the cells have been serialised, which for\n",
       "    // our purposes (turning an active figure into a static one), is too late.\n",
       "    var cells = IPython.notebook.get_cells();\n",
       "    var ncells = cells.length;\n",
       "    for (var i=0; i<ncells; i++) {\n",
       "        var cell = cells[i];\n",
       "        if (cell.cell_type === 'code'){\n",
       "            for (var j=0; j<cell.output_area.outputs.length; j++) {\n",
       "                var data = cell.output_area.outputs[j];\n",
       "                if (data.data) {\n",
       "                    // IPython >= 3 moved mimebundle to data attribute of output\n",
       "                    data = data.data;\n",
       "                }\n",
       "                if (data['text/html'] == html_output) {\n",
       "                    return [cell, data, j];\n",
       "                }\n",
       "            }\n",
       "        }\n",
       "    }\n",
       "}\n",
       "\n",
       "// Register the function which deals with the matplotlib target/channel.\n",
       "// The kernel may be null if the page has been refreshed.\n",
       "if (IPython.notebook.kernel != null) {\n",
       "    IPython.notebook.kernel.comm_manager.register_target('matplotlib', mpl.mpl_figure_comm);\n",
       "}\n"
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<img src=\"data:image/png;base64,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\" width=\"640\">"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "[<mpl_toolkits.mplot3d.art3d.Line3D at 0x2aac5b89ec40>]"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%matplotlib notebook\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "for i in range(len(states)):\n",
    "    print(states[i], env.referenceStreamline_ijk[i])\n",
    "    distance = ((states.T[0][i] - env.referenceStreamline_ijk.T[0][i])**2 \\\n",
    "                      + (states.T[1][i] - env.referenceStreamline_ijk.T[1][i] )**2 \\\n",
    "                      + (states.T[2][i] - env.referenceStreamline_ijk.T[2][i])**2)\n",
    "    print(distance)\n",
    "\n",
    "\n",
    "fig = plt.figure()\n",
    "ax = plt.axes(projection='3d')\n",
    "ax.plot3D(env.referenceStreamline_ijk.T[0], env.referenceStreamline_ijk.T[1], env.referenceStreamline_ijk.T[2])\n",
    "ax.plot3D(states.T[0][:3], states.T[1][:3], states.T[2][:3])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([74.9079, 74.5620, 75.4726], dtype=torch.float64)\n"
     ]
    }
   ],
   "source": [
    "states = torch.stack(all_states)\n",
    "print(states.T[0][:3])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([ 71.7731, 113.9662,  79.6186])\n"
     ]
    }
   ],
   "source": [
    "print(referenceLine[86])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 73.651344 107.88106   93.29415 ] tensor([ 73.6513, 107.8811,  93.2942])\n",
      "tensor(66.2049, dtype=torch.float64)\n"
     ]
    }
   ],
   "source": [
    "env.reset()\n",
    "print(env.state.getCoordinate().numpy(), referenceLine[0])\n",
    "step = 0\n",
    "#all_rewards = []\n",
    "eps_reward = 0\n",
    "for i in optimal_steps:\n",
    "    next_state, distance, terminal = env.step(i)\n",
    "    if distance < 0.71:\n",
    "        reward = 1 - distance\n",
    "        #print(reward)\n",
    "        if reward < 0.3:\n",
    "            reward = 1\n",
    "    eps_reward += reward\n",
    "    #all_rewards.append(reward)\n",
    "    step += 1\n",
    "print(eps_reward)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(n_actions):\n",
    "    \n",
    "    next_state, distance, terminal = env.step(i)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Action:  100 Step:  1 Coordinates:  [ 73.651344 107.88106   93.29415 ] [ 74.42344 107.87124  93.08491]\n",
      "Action:  67 Step:  2 Coordinates:  [ 74.34808267 107.88351105  92.57683017] [ 75.16057  107.88882   92.774536]\n",
      "Action:  100 Step:  3 Coordinates:  [ 74.34808267 107.88351105  92.57683017] [ 75.78847 107.96255  92.28433]\n",
      "Action:  100 Step:  4 Coordinates:  [ 74.34808267 107.88351105  92.57683017] [ 76.45265  108.118454  91.86654 ]\n",
      "Action:  100 Step:  5 Coordinates:  [ 74.34808267 107.88351105  92.57683017] [ 77.116844 108.27435   91.448746]\n",
      "Action:  100 Step:  6 Coordinates:  [ 74.34808267 107.88351105  92.57683017] [ 77.739716 108.54131   91.02359 ]\n",
      "Action:  100 Step:  7 Coordinates:  [ 74.34808267 107.88351105  92.57683017] [ 78.36259  108.80828   90.598434]\n",
      "Action:  100 Step:  8 Coordinates:  [ 74.34808267 107.88351105  92.57683017] [ 78.996666 109.15176   90.25207 ]\n",
      "Action:  100 Step:  9 Coordinates:  [ 74.34808267 107.88351105  92.57683017] [ 79.630745 109.495224  89.9057  ]\n",
      "Action:  100 Step:  10 Coordinates:  [ 74.34808267 107.88351105  92.57683017] [ 80.264824 109.8387    89.55933 ]\n",
      "Action:  100 Step:  11 Coordinates:  [ 74.34808267 107.88351105  92.57683017] [ 80.833374 110.28288   89.21371 ]\n",
      "Action:  100 Step:  12 Coordinates:  [ 74.34808267 107.88351105  92.57683017] [ 81.32385 110.75597  88.79464]\n",
      "Action:  100 Step:  13 Coordinates:  [ 74.34808267 107.88351105  92.57683017] [ 81.78852 111.07612  88.22755]\n",
      "Action:  100 Step:  14 Coordinates:  [ 74.34808267 107.88351105  92.57683017] [ 82.26274  111.20639   87.596565]\n",
      "Action:  100 Step:  15 Coordinates:  [ 74.34808267 107.88351105  92.57683017] [ 82.764885 111.12094   86.97968 ]\n",
      "Action:  100 Step:  16 Coordinates:  [ 74.34808267 107.88351105  92.57683017] [ 83.17989 111.072    86.2975 ]\n",
      "Action:  100 Step:  17 Coordinates:  [ 74.34808267 107.88351105  92.57683017] [ 83.60093  110.91725   85.635086]\n",
      "Action:  100 Step:  18 Coordinates:  [ 74.34808267 107.88351105  92.57683017] [ 84.02196  110.762505  84.97268 ]\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-8-9b9d7b386c25>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[0;32mwhile\u001b[0m \u001b[0mterminal\u001b[0m \u001b[0;34m!=\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m     \u001b[0maction\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrandom\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrandint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mn_actions\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 9\u001b[0;31m     \u001b[0mnext_state\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mreward\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mterminal\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0menv\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0maction\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     10\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mreward\u001b[0m \u001b[0;34m<\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     11\u001b[0m         \u001b[0mactions\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0maction\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/fibre_tracking/deepFibreTracking/dfibert/envs/RLtractEnvironment.py\u001b[0m in \u001b[0;36mstep\u001b[0;34m(self, action)\u001b[0m\n\u001b[1;32m    110\u001b[0m         \u001b[0mpositionNextState\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstate\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgetCoordinate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstepWidth\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0maction_vector\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    111\u001b[0m         \u001b[0mnextState\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mTractographyState\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpositionNextState\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minterpolateDWIatState\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 112\u001b[0;31m         \u001b[0;32mif\u001b[0m \u001b[0mnextState\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgetValue\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    113\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstate\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m-\u001b[0m\u001b[0;36m10\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    114\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/fibre_tracking/deepFibreTracking/dfibert/envs/_state.py\u001b[0m in \u001b[0;36mgetValue\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m     14\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minterpolatedDWI\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     15\u001b[0m         \u001b[0;31m# interpolate DWI value at self.coordinate\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 16\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minterpolatedDWI\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minterpolFuncHandle\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcoordinate\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     17\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minterpolatedDWI\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/fibre_tracking/deepFibreTracking/dfibert/envs/RLtractEnvironment.py\u001b[0m in \u001b[0;36minterpolateDWIatState\u001b[0;34m(self, stateCoordinates)\u001b[0m\n\u001b[1;32m     51\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     52\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 53\u001b[0;31m             \u001b[0minterpolated_dwi\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_interpolated_dwi\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mras_points\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpostprocessing\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdwi_postprocessor\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     54\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mValueError\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     55\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/fibre_tracking/deepFibreTracking/dfibert/data/__init__.py\u001b[0m in \u001b[0;36mget_interpolated_dwi\u001b[0;34m(self, points, postprocessing, ignore_outside_points)\u001b[0m\n\u001b[1;32m    286\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    287\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mpostprocessing\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 288\u001b[0;31m             result = postprocessing(result, self.data.b0, \n\u001b[0m\u001b[1;32m    289\u001b[0m                                  \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbvecs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    290\u001b[0m                                  self.data.bvals)\n",
      "\u001b[0;32m~/fibre_tracking/deepFibreTracking/dfibert/data/postprocessing.py\u001b[0m in \u001b[0;36m_wrapper\u001b[0;34m(dwi, b0, bvecs, bvals)\u001b[0m\n\u001b[1;32m     91\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     92\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_wrapper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdwi\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mb0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbvecs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbvals\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 93\u001b[0;31m         \u001b[0mdata_sh\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mspherical_harmonics\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msh_order\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msh_order\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msmooth\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msmooth\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdwi\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mb0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbvecs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbvals\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     94\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     95\u001b[0m         \u001b[0mdata_resampled\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdot\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata_sh\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mreal_sh\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mT\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/fibre_tracking/deepFibreTracking/dfibert/data/postprocessing.py\u001b[0m in \u001b[0;36m_wrapper\u001b[0;34m(dwi, _b0, bvecs, _bvals)\u001b[0m\n\u001b[1;32m     53\u001b[0m         \u001b[0mreal_sh\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mn\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mreal_sym_sh_mrtrix\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msh_order\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mraw_sphere\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtheta\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mraw_sphere\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mphi\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     54\u001b[0m         \u001b[0ml\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m-\u001b[0m\u001b[0mn\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mn\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 55\u001b[0;31m         \u001b[0minv_b\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msmooth_pinv\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mreal_sh\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msqrt\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msmooth\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0ml\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     56\u001b[0m         \u001b[0mdata_sh\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdot\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdwi\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minv_b\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mT\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     57\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.conda/envs/atari/lib/python3.8/site-packages/dipy/reconst/shm.py\u001b[0m in \u001b[0;36msmooth_pinv\u001b[0;34m(B, L)\u001b[0m\n\u001b[1;32m    661\u001b[0m     \"\"\"\n\u001b[1;32m    662\u001b[0m     \u001b[0mL\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdiag\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mL\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 663\u001b[0;31m     \u001b[0minv\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlinalg\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpinv\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconcatenate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mB\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mL\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    664\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0minv\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m:\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mB\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    665\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<__array_function__ internals>\u001b[0m in \u001b[0;36mpinv\u001b[0;34m(*args, **kwargs)\u001b[0m\n",
      "\u001b[0;32m~/.conda/envs/atari/lib/python3.8/site-packages/numpy/linalg/linalg.py\u001b[0m in \u001b[0;36mpinv\u001b[0;34m(a, rcond, hermitian)\u001b[0m\n\u001b[1;32m   1959\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mwrap\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mres\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1960\u001b[0m     \u001b[0ma\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0ma\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconjugate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1961\u001b[0;31m     \u001b[0mu\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0ms\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvt\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msvd\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0ma\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfull_matrices\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhermitian\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mhermitian\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1962\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1963\u001b[0m     \u001b[0;31m# discard small singular values\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<__array_function__ internals>\u001b[0m in \u001b[0;36msvd\u001b[0;34m(*args, **kwargs)\u001b[0m\n",
      "\u001b[0;32m~/.conda/envs/atari/lib/python3.8/site-packages/numpy/linalg/linalg.py\u001b[0m in \u001b[0;36msvd\u001b[0;34m(a, full_matrices, compute_uv, hermitian)\u001b[0m\n\u001b[1;32m   1624\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1625\u001b[0m         \u001b[0msignature\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m'D->DdD'\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0misComplexType\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mt\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0;34m'd->ddd'\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1626\u001b[0;31m         \u001b[0mu\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0ms\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvh\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mgufunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0ma\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msignature\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msignature\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mextobj\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mextobj\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1627\u001b[0m         \u001b[0mu\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mu\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mastype\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mresult_t\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcopy\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1628\u001b[0m         \u001b[0ms\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0ms\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mastype\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0m_realType\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mresult_t\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcopy\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "env.reset()\n",
    "terminal = False\n",
    "step = 0\n",
    "actions = []\n",
    "past_state = env.state\n",
    "step = 1\n",
    "while terminal != True:\n",
    "    for i in range(n_actions)\n",
    "    action = np.random.randint(n_actions)\n",
    "    next_state, reward, terminal = env.step(action)\n",
    "    if reward < 1:\n",
    "        actions.append(action)\n",
    "        past_state = next_state\n",
    "        print(\"Action: \", action, \"Step: \",step, \"Coordinates: \", next_state.getCoordinate().numpy(), referenceLine[step].numpy())\n",
    "        step += 1\n",
    "    else:\n",
    "        env.state = past_state\n",
    "        env.stepCounter = step\n",
    "    #action = np.random.choice(possible_actions[step])\n",
    "    #next_state, reward, terminal = env.step(action)\n",
    "    #step += 1\n",
    "\n",
    "print(actions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([ 77.7397, 108.5413,  91.0236])\n",
      "tensor([ 78.3626, 108.8083,  90.5984])\n"
     ]
    }
   ],
   "source": [
    "print(referenceLine[6])\n",
    "print(referenceLine[7])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([ 78.1077, 108.7354,  91.6977], dtype=torch.float64)\n",
      "tensor([ 77.7615, 108.8643,  91.6973], dtype=torch.float64)\n",
      "tensor([ 77.8808, 108.4698,  91.6927], dtype=torch.float64)\n",
      "tensor([ 78.0768, 109.0850,  91.6268], dtype=torch.float64)\n",
      "tensor([ 77.5148, 108.5987,  91.6375], dtype=torch.float64)\n",
      "tensor([ 78.3125, 108.4477,  91.5947], dtype=torch.float64)\n",
      "tensor([ 77.7489, 109.2253,  91.5590], dtype=torch.float64)\n",
      "tensor([ 77.6419, 108.2420,  91.5700], dtype=torch.float64)\n",
      "tensor([ 78.4297, 108.8083,  91.5614], dtype=torch.float64)\n",
      "tensor([ 77.4379, 108.9717,  91.5654], dtype=torch.float64)\n",
      "tensor([ 78.0813, 108.1849,  91.5566], dtype=torch.float64)\n",
      "tensor([ 78.1025, 109.3932,  91.4139], dtype=torch.float64)\n",
      "tensor([ 77.3094, 108.3452,  91.4445], dtype=torch.float64)\n",
      "tensor([ 78.6147, 108.4838,  91.3841], dtype=torch.float64)\n",
      "tensor([ 77.4417, 109.2998,  91.3783], dtype=torch.float64)\n",
      "tensor([ 77.8415, 107.9787,  91.4083], dtype=torch.float64)\n",
      "tensor([ 78.3907, 109.1557,  91.4638], dtype=torch.float64)\n",
      "tensor([ 77.2027, 108.6996,  91.4375], dtype=torch.float64)\n",
      "tensor([ 78.4256, 108.1555,  91.3717], dtype=torch.float64)\n",
      "tensor([ 77.7865, 109.5055,  91.3048], dtype=torch.float64)\n",
      "tensor([ 77.4984, 108.0024,  91.3116], dtype=torch.float64)\n",
      "tensor([ 78.6872, 108.8408,  91.3203], dtype=torch.float64)\n",
      "tensor([ 77.1729, 109.0570,  91.3086], dtype=torch.float64)\n",
      "tensor([ 78.1746, 107.9095,  91.2645], dtype=torch.float64)\n",
      "tensor([ 78.3889, 109.4422,  91.1813], dtype=torch.float64)\n",
      "tensor([ 77.0434, 108.4461,  91.1692], dtype=torch.float64)\n",
      "tensor([ 78.6965, 108.2442,  91.1141], dtype=torch.float64)\n",
      "tensor([ 77.5030, 109.5370,  91.1019], dtype=torch.float64)\n",
      "tensor([ 77.5000, 107.8270,  90.9938], dtype=torch.float64)\n",
      "tensor([ 78.6388, 109.1633,  91.2107], dtype=torch.float64)\n",
      "tensor([ 76.9888, 108.7771,  91.1266], dtype=torch.float64)\n",
      "tensor([ 78.4668, 107.9465,  91.0478], dtype=torch.float64)\n",
      "tensor([ 78.0655, 109.6183,  91.0848], dtype=torch.float64)\n",
      "tensor([ 77.2055, 108.1323,  91.1605], dtype=torch.float64)\n",
      "tensor([ 78.8286, 108.6225,  91.0812], dtype=torch.float64)\n",
      "tensor([ 77.2105, 109.3476,  91.0498], dtype=torch.float64)\n",
      "tensor([ 77.8390, 107.7826,  91.1087], dtype=torch.float64)\n",
      "tensor([ 78.6632, 109.3198,  90.9072], dtype=torch.float64)\n",
      "tensor([ 76.9030, 108.6561,  90.7911], dtype=torch.float64)\n",
      "tensor([ 78.6834, 108.0832,  90.7689], dtype=torch.float64)\n",
      "tensor([ 77.7496, 109.6751,  90.8953], dtype=torch.float64)\n",
      "tensor([ 77.2161, 107.9836,  90.8505], dtype=torch.float64)\n",
      "tensor([ 78.8374, 108.9642,  90.9474], dtype=torch.float64)\n",
      "tensor([ 77.0033, 109.0777,  90.9567], dtype=torch.float64)\n",
      "tensor([ 78.1431, 107.7515,  90.9129], dtype=torch.float64)\n",
      "tensor([ 78.3585, 109.5817,  90.8446], dtype=torch.float64)\n",
      "tensor([ 76.9926, 108.2972,  90.8376], dtype=torch.float64)\n",
      "tensor([ 78.8549, 108.4211,  90.8108], dtype=torch.float64)\n",
      "tensor([ 77.3852, 109.5591,  90.7525], dtype=torch.float64)\n",
      "tensor([ 77.7615, 107.7120,  90.7482], dtype=torch.float64)\n",
      "tensor([ 77.6912, 108.6687,  89.7427], dtype=torch.float64)\n",
      "tensor([ 78.0374, 108.5397,  89.7432], dtype=torch.float64)\n",
      "tensor([ 77.9181, 108.9343,  89.7477], dtype=torch.float64)\n",
      "tensor([ 77.7221, 108.3191,  89.8136], dtype=torch.float64)\n",
      "tensor([ 78.2841, 108.8053,  89.8029], dtype=torch.float64)\n",
      "tensor([ 77.4863, 108.9563,  89.8458], dtype=torch.float64)\n",
      "tensor([ 78.0500, 108.1788,  89.8814], dtype=torch.float64)\n",
      "tensor([ 78.1570, 109.1620,  89.8705], dtype=torch.float64)\n",
      "tensor([ 77.3692, 108.5958,  89.8791], dtype=torch.float64)\n",
      "tensor([ 78.3610, 108.4323,  89.8751], dtype=torch.float64)\n",
      "tensor([ 77.7176, 109.2191,  89.8838], dtype=torch.float64)\n",
      "tensor([ 77.6964, 108.0109,  90.0266], dtype=torch.float64)\n",
      "tensor([ 78.4895, 109.0588,  89.9960], dtype=torch.float64)\n",
      "tensor([ 77.1842, 108.9202,  90.0563], dtype=torch.float64)\n",
      "tensor([ 78.3572, 108.1042,  90.0621], dtype=torch.float64)\n",
      "tensor([ 77.9574, 109.4254,  90.0322], dtype=torch.float64)\n",
      "tensor([ 77.4082, 108.2484,  89.9767], dtype=torch.float64)\n",
      "tensor([ 78.5962, 108.7045,  90.0029], dtype=torch.float64)\n",
      "tensor([ 77.3733, 109.2486,  90.0688], dtype=torch.float64)\n",
      "tensor([ 78.0123, 107.8986,  90.1357], dtype=torch.float64)\n",
      "tensor([ 78.3005, 109.4017,  90.1289], dtype=torch.float64)\n",
      "tensor([ 77.1116, 108.5632,  90.1201], dtype=torch.float64)\n",
      "tensor([ 78.6259, 108.3471,  90.1318], dtype=torch.float64)\n",
      "tensor([ 77.6242, 109.4945,  90.1760], dtype=torch.float64)\n",
      "tensor([ 77.4100, 107.9618,  90.2592], dtype=torch.float64)\n",
      "tensor([ 78.7555, 108.9580,  90.2712], dtype=torch.float64)\n",
      "75 [ 78.7555186  108.95801267  90.27122457] [ 78.36259  108.80828   90.598434] 0.2838811622505798\n",
      "tensor([ 77.1024, 109.1599,  90.3263], dtype=torch.float64)\n",
      "tensor([ 78.2959, 107.8671,  90.3386], dtype=torch.float64)\n",
      "tensor([ 78.2988, 109.5771,  90.4467], dtype=torch.float64)\n",
      "tensor([ 77.1600, 108.2408,  90.2298], dtype=torch.float64)\n",
      "tensor([ 78.8100, 108.6269,  90.3138], dtype=torch.float64)\n",
      "tensor([ 77.3321, 109.4575,  90.3926], dtype=torch.float64)\n",
      "tensor([ 77.7333, 107.7858,  90.3557], dtype=torch.float64)\n",
      "tensor([ 78.5934, 109.2718,  90.2799], dtype=torch.float64)\n",
      "tensor([ 76.9703, 108.7816,  90.3592], dtype=torch.float64)\n",
      "tensor([ 78.5884, 108.0565,  90.3906], dtype=torch.float64)\n",
      "tensor([ 77.9598, 109.6215,  90.3317], dtype=torch.float64)\n",
      "tensor([ 77.1356, 108.0842,  90.5333], dtype=torch.float64)\n",
      "tensor([ 78.8959, 108.7480,  90.6493], dtype=torch.float64)\n",
      "88 [ 78.89586077 108.74800996  90.64932975] [ 78.36259  108.80828   90.598434] 0.2906038664155419\n",
      "tensor([ 77.1154, 109.3209,  90.6715], dtype=torch.float64)\n",
      "tensor([ 78.0493, 107.7290,  90.5451], dtype=torch.float64)\n",
      "tensor([ 78.5828, 109.4204,  90.5900], dtype=torch.float64)\n",
      "tensor([ 76.9615, 108.4399,  90.4931], dtype=torch.float64)\n",
      "tensor([ 78.7955, 108.3264,  90.4838], dtype=torch.float64)\n",
      "tensor([ 77.6558, 109.6526,  90.5275], dtype=torch.float64)\n",
      "tensor([ 77.4404, 107.8224,  90.5959], dtype=torch.float64)\n",
      "tensor([ 78.8063, 109.1069,  90.6029], dtype=torch.float64)\n",
      "96 [ 78.80625982 109.10688665  90.60289128] [ 78.36259  108.80828   90.598434] 0.28603082585170475\n",
      "tensor([ 76.9440, 108.9829,  90.6297], dtype=torch.float64)\n",
      "tensor([ 78.4137, 107.8450,  90.6879], dtype=torch.float64)\n",
      "tensor([ 78.0373, 109.6921,  90.6923], dtype=torch.float64)\n",
      "100 [ 77.89944  108.702034  90.72022 ] [ 78.36259  108.80828   90.598434] 0.24062869\n"
     ]
    }
   ],
   "source": [
    "state = TractographyState(torch.Tensor([ 77.8994346, 108.7020324, 90.72022516]), env.interpolateDWIatState)\n",
    "for i in range(n_actions):\n",
    "    env.state = state\n",
    "    env.stepCounter -= 1\n",
    "    next_state, _, terminal = env.step(i)\n",
    "    qry_pt = next_state.getCoordinate().view(-1,3)\n",
    "    distance = torch.min(torch.sum((referenceLine[7] - qry_pt)**2, dim=1))\n",
    "    if distance < 0.3:\n",
    "        print(i, next_state.getCoordinate().numpy(), referenceLine[7].numpy(), distance.numpy())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(187.0214)\n",
      "[ 73.651344 107.88106   93.29415 ]\n",
      "-1\n",
      "True\n"
     ]
    }
   ],
   "source": [
    "env.reset()\n",
    "next_state, reward, terminal = env.step(100)\n",
    "print(next_state.getCoordinate().numpy())\n",
    "print(reward)\n",
    "print(terminal)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[47, 75, 80, 88, 93, 96], [67, 75, 80, 88, 93], [62, 67, 75, 80], [62, 67, 75, 80, 83], [62, 67, 75, 80, 83], [62, 67, 75, 83, 96], [62, 67, 75, 83, 96], [62, 75, 83, 91, 96], [62, 75, 83, 91, 96], [62, 75, 83, 91, 96], [62, 70, 75, 83, 91, 96], [62, 70, 75, 78, 83, 91], [54, 57, 62, 67, 70, 75, 83], [54, 62, 67, 75], [54, 59, 67, 72], [51, 54, 59, 62, 67, 72], [51, 54, 59, 64, 67, 72], [51, 54, 59, 64, 67, 72], [51, 54, 59, 64, 67, 72], [51, 54, 56, 59, 64, 67, 72], [51, 54, 56, 59, 64, 67, 72], [51, 56, 59, 64], [51, 56, 59, 64], [51, 56, 59, 64], [50, 51, 53, 56, 59], [50, 51, 53, 56, 61, 66], [53, 58, 61, 66, 74, 79], [58, 66, 71, 74, 79], [58, 66, 71, 79], [58, 63, 66, 71, 79], [58, 63, 66, 71, 79], [58, 63, 66, 71, 79], [58, 63, 66, 71, 79], [58, 63, 66, 71, 79, 84], [58, 63, 71, 79, 84, 92], [58, 63, 71, 79, 84, 92], [63, 71, 79, 84, 92], [63, 71, 79, 84, 92], [38, 71, 79, 84, 92], [38, 63, 71, 84, 92, 97], [38, 71, 84, 92, 97], [38, 84, 92, 97], [38, 76, 84, 92, 97], [38, 76, 84, 92, 97], [38, 43, 84, 89, 97], [38, 43, 84, 89, 97], [30, 38, 43, 97], [30, 38, 43, 97], [30, 38, 43, 97], [22, 30, 38, 43, 97], [22, 30, 38, 43, 97], [22, 35, 43, 89, 97], [35, 43, 48, 89], [40, 48, 81, 89, 94], [40, 48, 73, 81, 86, 94], [73, 81, 86, 94], [40, 48, 81, 89, 94], [35, 43, 48, 89], [22, 35, 43, 89, 97], [22, 35, 43, 89, 97], [22, 30, 35, 43, 89], [22, 30, 35, 43, 89], [14, 22, 27, 35, 43], [14, 22, 27, 35], [6, 14, 19, 22, 27, 35], [6, 11, 14, 19, 27], [3, 6, 11, 19], [3, 6, 11, 16], [3, 8, 11, 16], [3, 8, 11, 16, 24, 29], [3, 8, 16, 21, 29], [8, 16, 21, 29], [8, 13, 16, 21, 29], [8, 13, 16, 21, 29], [21, 29, 34, 42], [13, 21, 26, 34, 47], [13, 18, 26, 31, 34, 39, 47], [26, 34, 39, 47, 93], [26, 34, 39, 47, 93], [26, 39, 47, 85, 93], [26, 39, 47, 85, 93], [39, 47, 72, 85, 93], [64, 72, 80, 85, 93], [64, 72, 77, 85, 93], [56, 64, 69, 72, 77, 85], [64, 69, 77, 85, 90, 98], [100]]\n"
     ]
    }
   ],
   "source": [
    "print(possible_actions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([ 71.5173, 114.6476,  79.9506])\n",
      "tensor([ 71.7731, 113.9662,  79.6186])\n",
      "[64, 69, 77, 85, 90, 98]\n",
      "tensor([ 71.5173, 114.6476,  79.9506]) tensor(0.4643)\n",
      "tensor([ 71.5173, 114.6476,  79.9506]) tensor(0.4643)\n",
      "tensor([ 71.5173, 114.6476,  79.9506]) tensor(0.4643)\n",
      "tensor([ 71.5173, 114.6476,  79.9506]) tensor(0.4643)\n",
      "tensor([ 71.5173, 114.6476,  79.9506]) tensor(0.4643)\n",
      "tensor([ 71.5173, 114.6476,  79.9506]) tensor(0.4643)\n"
     ]
    }
   ],
   "source": [
    "env.state = TractographyState(referenceLine[85], env.interpolateDWIatState)\n",
    "print(env.state.getCoordinate())\n",
    "print(referenceLine[86])\n",
    "print(possible_actions[85])\n",
    "for i in possible_actions[85]:\n",
    "    env.state = TractographyState(referenceLine[85], env.interpolateDWIatState)\n",
    "    env.stepCounter = 84\n",
    "    next_state, reward, _ = env.step(z)\n",
    "    print(next_state.getCoordinate(), reward)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 71.773056 113.966225  79.618576] [ 72.30127204 114.02878755  79.99932066] 0.27901215525974304\n",
      "[ 71.773056 113.966225  79.618576] [ 71.7609279  113.6971063   80.14330044] 0.2753356828217112\n",
      "[ 71.773056 113.966225  79.618576] [ 71.37937604 113.65758474  79.97858924] 0.15498393104601757\n",
      "[ 71.773056 113.966225  79.618576] [ 71.66780472 114.12438903  79.11184227] 0.2567791198339029\n",
      "[ 71.773056 113.966225  79.618576] [ 71.97880832 114.37794723  79.10548775] 0.26325960220840583\n",
      "[ 71.773056 113.966225  79.618576] [ 71.31423388 113.95652005  79.25698482] 0.2105177635246191\n",
      "[ 71.773056 113.966225  79.618576] [ 71.97504289 114.04982978  79.29253904] 0.10630013104166292\n",
      "[ 71.773056 113.966225  79.618576] [ 71.63016002 113.84417747  79.3660627 ] 0.06376299386222199\n",
      "[ 71.773056 113.966225  79.618576] [ 72.24376411 114.29266559  79.36222956] 0.2215660937612901\n",
      "[ 71.773056 113.966225  79.618576] [ 71.91375289 113.81268975  79.56895814] 0.023572970787664616\n",
      "[ 71.773056 113.966225  79.618576] [ 71.35118583 113.73139254  79.58605126] 0.1779744651043897\n",
      "[ 71.773056 113.966225  79.618576] [ 72.20619251 114.00206886  79.62102829] 0.18760720625139998\n",
      "[ 71.773056 113.966225  79.618576] [ 71.66712842 113.67455586  79.7755295 ] 0.08507069391326497\n",
      "[ 71.773056 113.966225  79.618576] [ 72.03154546 113.7906186   79.91830767] 0.0898390464981324\n"
     ]
    }
   ],
   "source": [
    "#env.state = TractographyState(referenceLine[85], env.interpolateDWIatState)\n",
    "for i in range(n_actions):\n",
    "    env.reset()\n",
    "    env.state = TractographyState(referenceLine[85], env.interpolateDWIatState)\n",
    "    next_state, reward, _ = env.step(i)\n",
    "    distance = env.rewardForTerminalState(next_state)\n",
    "    if distance < 0.3:\n",
    "        print(referenceLine[86].numpy(), next_state.getCoordinate().numpy(), distance.item())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([ 71.7731, 113.9662,  79.6186])\n",
      "tensor(122.0777, dtype=torch.float64)\n"
     ]
    }
   ],
   "source": [
    "distance = env.rewardForTerminalState(next_state)\n",
    "print(referenceLine[86])\n",
    "print(distance)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(n_actions):\n",
    "    env.state = TractographyState(torch.FloatTensor([ 74.64776812, 107.9270337, 93.22325858]), env.interpolateDWIatState)\n",
    "    next_state, reward, _ = env.step(i)\n",
    "    env.stepCounter = 2\n",
    "    if reward < 0.1:\n",
    "        reward = 1\n",
    "    elif reward < 0.5:\n",
    "        reward = 0\n",
    "    else:\n",
    "        reward = -1\n",
    "    if reward == 1:\n",
    "        #best_actions.append(i)\n",
    "        print(\"[{}]\".format(i), referenceLine[2].numpy(), next_state.getCoordinate().numpy(), reward)\n",
    "#print(best_actions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "state = TractographyState(torch.FloatTensor(referenceLine[0]), env.interpolateDWIatState)\n",
    "coordinates = state.getCoordinate()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(referenceLine[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(referenceLine[0])\n",
    "print(referenceLine[70])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "state = TractographyState(referenceLine[69], env.interpolateDWIatState)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "shape = env.reset().getValue().reshape(-1).shape[0]\n",
    "print(shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "state = torch.FloatTensor(state.getValue()).unsqueeze(0).to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "q_vals = agent.main_dqn(state)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(state.getValue().shape)\n",
    "shape = state.getValue().shape\n",
    "shape = np.prod(np.array(shape))\n",
    "print(shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "state = TractographyState(referenceLine[70], env.interpolateDWIatState)\n",
    "qry_pt = torch.FloatTensor(state.getCoordinate()).view(-1,3)\n",
    "distance = torch.min(torch.sum( (referenceLine - qry_pt)**2, dim =1 ))\n",
    "qry_pt = torch.FloatTensor(state.getCoordinate()).view(3)\n",
    "distance_terminal = torch.sum( (referenceLine[-1,:] - qry_pt)**2 )\n",
    "\n",
    "#print(distance)\n",
    "#print(distance_terminal)\n",
    "reward = (torch.tanh(-distance+5.3) + 2*torch.tanh(-distance_terminal+5.3))/2\n",
    "print(reward)\n",
    "\n",
    "print(torch.tanh(-distance+5.3))\n",
    "print(torch.tanh(-distance_terminal+5.3))\n",
    "\n",
    "reward += 200/20 * reward.sign()\n",
    "print(reward)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(torch.tanh(-distance_terminal+5.3)+2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "state = TractographyState([32., 84., 94.], env.interpolateDWIatState)\n",
    "qry_pt = torch.FloatTensor(state.getCoordinate()).view(-1,3)\n",
    "distance = torch.min(torch.sum( (referenceLine - qry_pt)**2, dim =1 ))\n",
    "print(torch.tanh(-distance+5.3))\n",
    "qry_pt = torch.FloatTensor(state.getCoordinate()).view(3)\n",
    "distance = torch.sum( (referenceLine[-1,:] - qry_pt)**2 )\n",
    "print(-distance)\n",
    "print(torch.tanh(-distance)+2)\n",
    "#print(torch.where(distance < env.maxL2dist_to_terminalState, 1, 0 ))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(-1.5 + 5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "qry_pt = torch.FloatTensor(state.getCoordinate()).view(3)\n",
    "distance = torch.sum( (referenceLine[-1,:] - qry_pt)**2 )\n",
    "print(round(-distance.item(),4))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Init agent\")\n",
    "#memory = ReplayMemory(size=replay_memory_size)\n",
    "state = env.reset()\n",
    "agent = Agent(n_actions=n_actions, inp_size=state.getValue().shape, device=device, hidden=256, agent_history_length=agent_history_length, memory_size=replay_memory_size, learning_rate=learning_rate)\n",
    "\n",
    "print(\"Init epsilon-greedy action scheduler\")\n",
    "action_scheduler = Action_Scheduler(num_actions=n_actions, max_steps=max_steps, eps_annealing_steps=100000, replay_memory_start_size=replay_memory_size, model=agent.main_dqn)\n",
    "\n",
    "step_counter = 0\n",
    "    \n",
    "eps_rewards = []\n",
    "\n",
    "print(\"Start training...\")\n",
    "while step_counter < max_steps:\n",
    "    epoch_step = 0\n",
    "\n",
    "######## fill memory begins here\n",
    "    while epoch_step < evaluate_every:  # To Do implement evaluation\n",
    "        state = env.reset()\n",
    "        episode_reward_sum = 0\n",
    "        \n",
    "        #fill replay memory while interacting with env\n",
    "        for episode_counter in range(max_episode_length):\n",
    "            # get action with epsilon-greedy strategy       \n",
    "            action = action_scheduler.get_action(step_counter, torch.FloatTensor(state.getValue()).to(device).unsqueeze(0))\n",
    "                    \n",
    "            next_state, reward, terminal = env.step(action)\n",
    "\n",
    "            if reward >= 1:\n",
    "                reward = 10\n",
    "            elif reward > -0.05:\n",
    "                reward = 1\n",
    "            \n",
    "            if episode_counter == max_episode_length-1:\n",
    "                reward = -100\n",
    "                terminal = True\n",
    "            # increase counter\n",
    "            step_counter += 1\n",
    "            epoch_step += 1\n",
    "\n",
    "            # accumulate reward for current episode\n",
    "            episode_reward_sum += reward\n",
    "\n",
    "\n",
    "            agent.replay_memory.add_experience(action=action,\n",
    "                                state=state.getValue(),\n",
    "                                reward=reward,\n",
    "                                new_state=next_state.getValue(),\n",
    "                                terminal=terminal)\n",
    "\n",
    "\n",
    "            state = next_state\n",
    "\n",
    "        \n",
    "\n",
    "            ####### optimization is happening here\n",
    "            if step_counter > replay_memory_size:\n",
    "                loss = agent.optimize()\n",
    "\n",
    "\n",
    "            ####### target network update\n",
    "            if step_counter > replay_memory_size and step_counter % network_update_every == 0:\n",
    "                agent.target_dqn.load_state_dict(agent.main_dqn.state_dict())\n",
    "            \n",
    "            # if episode ended before maximum step\n",
    "            if terminal:\n",
    "                terminal = False\n",
    "                state = env.reset()\n",
    "                break\n",
    "                \n",
    "        eps_rewards.append(episode_reward_sum)\n",
    "        \n",
    "        if len(eps_rewards) % 10 == 0:\n",
    "            with open(path+'/logs/rewards.dat', 'a') as reward_file:\n",
    "                print(\"[{}] {}, {}\".format(len(eps_rewards), step_counter, np.mean(eps_rewards[-100:])), file=reward_file)\n",
    "            print(\"[{}] {}, {}\".format(len(eps_rewards), step_counter, np.mean(eps_rewards[-100:])) )\n",
    "    torch.save(agent.main_dqn.state_dict(), path+'/checkpoints/fibre_agent_{}_reward_{:.2f}.pth'.format(step_counter, np.mean(eps_rewards[-100:])))\n",
    "########## evaluation starting here\n",
    "    eval_rewards = []\n",
    "    for _ in range(eval_runs):\n",
    "        eval_steps = 0\n",
    "        state = env.reset()\n",
    "        eval_episode_reward = 0\n",
    "        while eval_steps < max_episode_length:\n",
    "            action = action_scheduler.get_action(step_counter, torch.FloatTensor(state.getValue()).to(device).unsqueeze(0), evaluation=True)\n",
    "\n",
    "            next_state, reward, terminal = env.step(action)\n",
    "\n",
    "            eval_steps += 1\n",
    "            eval_episode_reward += reward\n",
    "            state = next_state\n",
    "\n",
    "            if terminal:\n",
    "                terminal = False\n",
    "                break\n",
    "\n",
    "        eval_rewards.append(eval_episode_reward)\n",
    "    \n",
    "    print(\"Evaluation score:\", np.mean(eval_rewards))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#!mkdir -p 'checkpoints/'\n",
    "#torch.save(agent.main_dqn.state_dict(), 'checkpoints/fiber_agent_{}_reward_{:.2f}.pth'.format(step_counter, np.mean(rewards[-100:])))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "CONDA (atari)",
   "language": "python",
   "name": "atari"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
