{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import gym\n",
    "import numpy as np\n",
    "\n",
    "\n",
    "import os, sys\n",
    "sys.path.insert(0,'..')\n",
    "\n",
    "from collections import deque \n",
    "\n",
    "from dfibert.tracker.nn.rl import Agent, Action_Scheduler\n",
    "import dfibert.envs.RLtractEnvironment as RLTe\n",
    "from dfibert.envs._state import TractographyState"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test on Lunar Lander to check functionality of agent\n",
    "#env = gym.make('LunarLander-v2')\n",
    "#n_actions= env.action_space.n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "max_steps = 3000000\n",
    "replay_memory_size = 3000000\n",
    "agent_history_length = 1\n",
    "evaluate_every = 20000\n",
    "eval_runs = 5\n",
    "network_update_every = 1000\n",
    "start_learning = 10000\n",
    "\n",
    "max_episode_length = 200\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "\n",
    "learning_rate = 0.0001"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading precomputed streamlines (data/HCP307200_DTI_smallSet.vtk) for ID 100307\n"
     ]
    }
   ],
   "source": [
    "env = RLTe.RLtractEnvironment(device = 'cpu')\n",
    "n_actions = env.action_space.n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def init_transition():\n",
    "    state = env.reset()\n",
    "    transition = deque(maxlen=12)\n",
    "    while len(transition) < 12:\n",
    "        for i in range(len(state.getCoordinate())):\n",
    "            transition.append(state.getCoordinate()[i].item())\n",
    "    return transition\n",
    "\n",
    "def add_to_transition(state, transition):\n",
    "    for i in range(len(state.getCoordinate())):\n",
    "            transition.append(state.getCoordinate()[i].item())\n",
    "    return transition"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "deque([73.6513442993164, 107.88105773925781, 93.29415130615234, 73.6513442993164, 107.88105773925781, 93.29415130615234, 73.6513442993164, 107.88105773925781, 93.29415130615234, 73.6513442993164, 107.88105773925781, 93.29415130615234], maxlen=12)\n",
      "[ 73.6513443  107.88105774  93.29415131  73.6513443  107.88105774\n",
      "  93.29415131  73.6513443  107.88105774  93.29415131  74.58926433\n",
      " 108.1431821   93.52130066]\n"
     ]
    }
   ],
   "source": [
    "transition = init_transition()\n",
    "print(transition)\n",
    "next_state, _, _ = env.step(42)\n",
    "next_transition = add_to_transition(next_state, transition)\n",
    "print(np.array(next_transition))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[-13.6672,  -7.8499,  -5.0823,  14.6562,  -2.7858,  -0.6165,  10.3545,\n",
      "          -2.1052,  -6.4893,  -6.9334,  -1.0502,  -5.7020, -10.8006,  -2.3180,\n",
      "         -11.9924,  -0.8486,   3.1842,  -3.2134,   2.1775,  -0.9403,   3.2331,\n",
      "           1.7278,  -3.3707, -10.6123,   8.4084, -17.0882,  -3.0332,  -3.0189,\n",
      "          13.1050,  -5.0179,   7.5423,   4.0707,  -8.9227,  -2.1233,  10.4102,\n",
      "         -17.7410,  12.1755,  -0.2614,   4.6796,   9.3646,   5.0021,  10.0463,\n",
      "          -2.7939,  -9.3681,  -5.5738,  -3.8558, -13.2895,   8.2217,   1.9178,\n",
      "           9.1176,  -4.2744,   8.5829,   9.8390,   4.5286,  -8.5778,   4.4940,\n",
      "          -2.8302,  18.6438,  -1.0051,   1.0747,  -9.0311,   2.8591,   9.1929,\n",
      "          -3.2381,  -1.0803,  -8.8236,  -7.3553, -10.1507, -11.5579,   7.1048,\n",
      "          -4.4199,   5.1859,  13.8964,   1.0838,  -7.0013,  -1.5684,   3.1538,\n",
      "          -3.0316,   8.9216,   7.6663,   3.3042,  -7.4507,  14.3557,  -6.6734,\n",
      "         -13.6536,  -1.9597,  -6.0354,  -0.6945,  -5.4558,  -7.2604,  -2.2367,\n",
      "           5.1702,   1.4439,  -1.3349, -13.6596,   1.7791,   7.1995,  -4.0517,\n",
      "          16.7861, -15.0391]], device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor([[-13.6672,  -7.8499,  -5.0823,  14.6562,  -2.7858,  -0.6165,  10.3545,\n",
      "          -2.1052,  -6.4893,  -6.9334,  -1.0502,  -5.7020, -10.8006,  -2.3180,\n",
      "         -11.9924,  -0.8486,   3.1842,  -3.2134,   2.1775,  -0.9403,   3.2331,\n",
      "           1.7278,  -3.3707, -10.6123,   8.4084, -17.0882,  -3.0332,  -3.0189,\n",
      "          13.1050,  -5.0179,   7.5423,   4.0707,  -8.9227,  -2.1233,  10.4102,\n",
      "         -17.7410,  12.1755,  -0.2614,   4.6796,   9.3646,   5.0021,  10.0463,\n",
      "          -2.7939,  -9.3681,  -5.5738,  -3.8558, -13.2895,   8.2217,   1.9178,\n",
      "           9.1176,  -4.2744,   8.5829,   9.8390,   4.5286,  -8.5778,   4.4940,\n",
      "          -2.8302,  18.6438,  -1.0051,   1.0747,  -9.0311,   2.8591,   9.1929,\n",
      "          -3.2381,  -1.0803,  -8.8236,  -7.3553, -10.1507, -11.5579,   7.1048,\n",
      "          -4.4199,   5.1859,  13.8964,   1.0838,  -7.0013,  -1.5684,   3.1538,\n",
      "          -3.0316,   8.9216,   7.6663,   3.3042,  -7.4507,  14.3557,  -6.6734,\n",
      "         -13.6536,  -1.9597,  -6.0354,  -0.6945,  -5.4558,  -7.2604,  -2.2367,\n",
      "           5.1702,   1.4439,  -1.3349, -13.6596,   1.7791,   7.1995,  -4.0517,\n",
      "          16.7861, -15.0391]], device='cuda:0', grad_fn=<AddBackward0>)\n"
     ]
    }
   ],
   "source": [
    "agent = Agent(n_actions=n_actions, inp_size=np.array(transition).shape, device=device, hidden=10, agent_history_length=agent_history_length, memory_size=replay_memory_size, batch_size=32, learning_rate=learning_rate)\n",
    "#print(agent.main_dqn(torch.FloatTensor([np.array(transition)]).to(device)))\n",
    "#print(agent.target_dqn(torch.FloatTensor([np.array(transition)]).to(device)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1, 8])\n",
      "tensor([[0.2314, 0.2480, 0.3690, 0.1016]], device='cuda:0',\n",
      "       grad_fn=<AddBackward0>)\n",
      "tensor([[0.2314, 0.2480, 0.3690, 0.1016]], device='cuda:0',\n",
      "       grad_fn=<AddBackward0>)\n",
      "[ 0.01214266  1.4017366   0.60866606 -0.2167907  -0.01216728 -0.1019486\n",
      "  0.          0.        ] 0.0867171307642434 False\n",
      "tensor([[0.2314, 0.2480, 0.3690, 0.1016]], device='cuda:0',\n",
      "       grad_fn=<AddBackward0>)\n",
      "tensor([0.2480], device='cuda:0', grad_fn=<IndexBackward>)\n",
      "tensor([2], device='cuda:0')\n",
      "tensor([0.3673], device='cuda:0', grad_fn=<IndexBackward>)\n",
      "tensor([0.3673], device='cuda:0', grad_fn=<IndexPutBackward>)\n",
      "tensor([0.4503], device='cuda:0')\n",
      "tensor(0.0205, device='cuda:0', grad_fn=<SmoothL1LossBackward>)\n",
      "tensor([[0.2505, 0.2896, 0.3830, 0.1175]], device='cuda:0',\n",
      "       grad_fn=<AddBackward0>)\n",
      "tensor([[0.2314, 0.2480, 0.3690, 0.1016]], device='cuda:0',\n",
      "       grad_fn=<AddBackward0>)\n"
     ]
    }
   ],
   "source": [
    "# Debugging the optimization of the agent\n",
    "\n",
    "state = env.reset()\n",
    "state = torch.tensor([state]).to(device).float()\n",
    "print(state.shape)\n",
    "print(agent.main_dqn(state))\n",
    "print(agent.target_dqn(state))\n",
    "\n",
    "action = 1\n",
    "\n",
    "next_state, reward, done, _ = env.step(action)\n",
    "print(next_state, reward, done)\n",
    "\n",
    "action = torch.tensor([action]).to(device)\n",
    "next_state = torch.tensor([next_state]).float().to(device)\n",
    "reward = torch.tensor([reward]).float().to(device)\n",
    "done = torch.BoolTensor([done]).to(device)\n",
    "state_action_values = agent.main_dqn(state)\n",
    "print(state_action_values)\n",
    "state_action_values = state_action_values[0][action]\n",
    "print(state_action_values)\n",
    "\n",
    "next_state_actions = agent.main_dqn(next_state).max(1)[1]\n",
    "print(next_state_actions)\n",
    "next_state_values = agent.target_dqn(next_state)[0][next_state_actions]\n",
    "print(next_state_values)\n",
    "next_state_values[done] = 0.0\n",
    "print(next_state_values)\n",
    "expected_state_action_values = next_state_values.detach() * 0.99 + reward\n",
    "print(expected_state_action_values)\n",
    "\n",
    "agent.optimizer.zero_grad()\n",
    "loss = torch.nn.SmoothL1Loss()(state_action_values, expected_state_action_values)\n",
    "print(loss)\n",
    "loss.backward()\n",
    "agent.optimizer.step()\n",
    "\n",
    "print(agent.main_dqn(state))\n",
    "print(agent.target_dqn(state))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Start training...\n",
      "2010, done 10 games, -117.70114942528735, current eps 1\n",
      "4020, done 20 games, -118.85057471264368, current eps 1\n",
      "6030, done 30 games, -118.85057471264368, current eps 1\n",
      "8040, done 40 games, -119.13793103448276, current eps 1\n",
      "10050, done 50 games, -119.08045977011494, current eps 1\n",
      "12060, done 60 games, -119.23371647509579, current eps 1\n",
      "14070, done 70 games, -119.3431855500821, current eps 1\n",
      "16080, done 80 games, -119.42528735632186, current eps 1\n",
      "18090, done 90 games, -119.48914431673055, current eps 0.9991278000000001\n",
      "20100, done 100 games, -119.54022988505749, current eps 0.9794298000000001\n",
      "Evaluation score: -20.000000000000014\n",
      "0 of 5 episodes ended close to / at the final state.\n",
      "22110, done 110 games, -119.65517241379311, current eps 0.9597318000000001\n",
      "24120, done 120 games, -119.54022988505749, current eps 0.9400338000000001\n",
      "26130, done 130 games, -119.65517241379311, current eps 0.9203358000000001\n",
      "28140, done 140 games, -119.65517241379311, current eps 0.9006378000000002\n",
      "30150, done 150 games, -119.77011494252875, current eps 0.8809398000000002\n",
      "32160, done 160 games, -119.77011494252875, current eps 0.8612418000000002\n",
      "34170, done 170 games, -119.65517241379311, current eps 0.8415438000000002\n",
      "36180, done 180 games, -119.54022988505749, current eps 0.8218458000000002\n",
      "38190, done 190 games, -119.54022988505749, current eps 0.8021478000000002\n",
      "40200, done 200 games, -119.54022988505749, current eps 0.7824498000000002\n",
      "Evaluation score: -114.79999999999997\n",
      "0 of 5 episodes ended close to / at the final state.\n",
      "42210, done 210 games, -119.65517241379311, current eps 0.7627518000000002\n",
      "44220, done 220 games, -119.77011494252875, current eps 0.7430538000000002\n",
      "46230, done 230 games, -119.77011494252875, current eps 0.7233558000000002\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-5-9b5a1e40d25a>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     98\u001b[0m                 \u001b[0;31m#if reward > 0.:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     99\u001b[0m                 \u001b[0;31m#    print(\"reward was positive: \", reward)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 100\u001b[0;31m                 \u001b[0mloss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0magent\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moptimize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    101\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    102\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/fibre_tracking/deepFibreTracking/dfibert/tracker/nn/rl.py\u001b[0m in \u001b[0;36moptimize\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    194\u001b[0m         \u001b[0mloss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mMSELoss\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstate_action_values\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mexpected_state_action_values\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    195\u001b[0m         \u001b[0;31m#loss = torch.nn.SmoothL1Loss()(state_action_values, expected_state_action_values)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 196\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moptimizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mzero_grad\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    197\u001b[0m         \u001b[0mloss\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    198\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moptimizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.conda/envs/atari/lib/python3.8/site-packages/torch/optim/optimizer.py\u001b[0m in \u001b[0;36mzero_grad\u001b[0;34m(self, set_to_none)\u001b[0m\n\u001b[1;32m    186\u001b[0m                         \u001b[0mp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgrad\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    187\u001b[0m                     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 188\u001b[0;31m                         \u001b[0;32mif\u001b[0m \u001b[0mp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgrad\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgrad_fn\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    189\u001b[0m                             \u001b[0mp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgrad\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdetach_\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    190\u001b[0m                         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.conda/envs/atari/lib/python3.8/site-packages/torch/tensor.py\u001b[0m in \u001b[0;36mgrad\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    951\u001b[0m                           \u001b[0;34m\"non-leaf Tensor by mistake, make sure you access the leaf Tensor instead. See \"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    952\u001b[0m                           \"github.com/pytorch/pytorch/pull/30531 for more informations.\", stacklevel=2)\n\u001b[0;32m--> 953\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_grad\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    954\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    955\u001b[0m     \u001b[0;34m@\u001b[0m\u001b[0mgrad\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msetter\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "#state = env.reset()\n",
    "#agent = Agent(n_actions=n_actions, inp_size=state.shape, device=device, hidden=10, agent_history_length=agent_history_length, memory_size=replay_memory_size, batch_size=32, learning_rate=learning_rate)\n",
    "\n",
    "transition = init_transition()\n",
    "agent = Agent(n_actions=n_actions, inp_size=np.array(transition).shape, device=device, hidden=10, agent_history_length=agent_history_length, memory_size=replay_memory_size, batch_size=256)\n",
    "action_scheduler = Action_Scheduler(num_actions=n_actions, max_steps=max_steps, eps_annealing_steps=100000, eps_final=0.02, replay_memory_start_size=18000, model=agent.main_dqn)\n",
    "\n",
    "step_counter = 0\n",
    "\n",
    "eps_rewards = []\n",
    "\n",
    "\n",
    "\n",
    "print(\"Start training...\")\n",
    "while step_counter < max_steps:\n",
    "    epoch_step = 0\n",
    "    #agent.main_dqn.train()\n",
    "######## fill memory begins here\n",
    "    while (epoch_step < evaluate_every) or (step_counter < start_learning):\n",
    "        #state = env.reset()\n",
    "        transition = init_transition()\n",
    "\n",
    "        episode_reward_sum = 0\n",
    "        terminal = False\n",
    "        #fill replay memory while interacting with env\n",
    "        #for episode_counter in range(max_episode_length):\n",
    "        episode_step_counter = 0\n",
    "        positive_run = 0\n",
    "        #actions = [0] *n_actions\n",
    "        #past_reward = 0\n",
    "        #current_reward = 0\n",
    "        #points_near_line = 0\n",
    "        while not terminal:\n",
    "            # get action with epsilon-greedy strategy       \n",
    "            action = action_scheduler.get_action(step_counter, torch.FloatTensor([np.array(transition)]).to(device))\n",
    "            \n",
    "            next_state, reward, terminal = env.step(action)\n",
    "            next_transition = add_to_transition(next_state, transition)\n",
    "            #actions[action] += reward\n",
    "\n",
    "            step_counter += 1\n",
    "            epoch_step += 1\n",
    "            episode_step_counter += 1\n",
    "            \n",
    "            #if not terminal: \n",
    "           # \n",
    "           #     current_reward -= 0.1\n",
    "\n",
    "                #reward -= 0.1\n",
    "           #     sphere_dist = ((next_state.getCoordinate()[0] - env.referenceStreamline_ijk[np.min([env.stepCounter, 86])][0])**2 \\\n",
    "           #                    + (next_state.getCoordinate()[1] - env.referenceStreamline_ijk[np.min([env.stepCounter, 86])][1])**2 \\\n",
    "           #                    + (next_state.getCoordinate()[2] - env.referenceStreamline_ijk[np.min([env.stepCounter, 86])][2])**2)\n",
    "                #print(sphere_dist)\n",
    "           #     if sphere_dist < 0.2**2:\n",
    "           #         current_reward += 1000 / len(referenceLine)\n",
    "           #         points_near_line += 1\n",
    "                    #print(True)\n",
    "\n",
    "           #     reward = current_reward - past_reward\n",
    "           #     past_reward = current_reward\n",
    "\n",
    "           #     if points_near_line == len(env.referenceStreamline_ijk):\n",
    "           #         terminal = True\n",
    "            \n",
    "            #else:\n",
    "                #print(False)\n",
    "            \n",
    "            #reward = 1 + (1+(reward/10))\n",
    "            #if reward > 1:\n",
    "            #    reward = 1\n",
    "            #elif reward > 0.:\n",
    "            #    reward = 0\n",
    "            #else:\n",
    "            #    reward = -1\n",
    "            \n",
    "            #if action == 100:\n",
    "            #    reward = 0.5\n",
    "\n",
    "\n",
    "            # accumulate reward for current episode\n",
    "            episode_reward_sum += reward\n",
    "\n",
    "\n",
    "            agent.replay_memory.add_experience(action=action,\n",
    "                                state=np.array(transition),\n",
    "                                reward=reward,\n",
    "                                new_state=np.array(next_transition),\n",
    "                                terminal=terminal)\n",
    "\n",
    "\n",
    "            #state = next_state\n",
    "            transition = next_transition\n",
    "\n",
    "\n",
    "\n",
    "            ####### optimization is happening here\n",
    "            if step_counter > start_learning:\n",
    "                #if reward > 0.:\n",
    "                #    print(\"reward was positive: \", reward)\n",
    "                loss = agent.optimize()\n",
    "\n",
    "\n",
    "            ####### target network update\n",
    "            if step_counter > start_learning and step_counter % network_update_every == 0:\n",
    "                #print(\"Update net\")\n",
    "                #print(agent.main_dqn(torch.tensor(state).to(device).unsqueeze(0)))\n",
    "                #print(agent.target_dqn(torch.tensor(state).to(device).unsqueeze(0)))\n",
    "                agent.target_dqn.load_state_dict(agent.main_dqn.state_dict())\n",
    "\n",
    "            # if episode ended before maximum step\n",
    "            if terminal:\n",
    "                terminal = False\n",
    "                #state = env.reset()\n",
    "                transition = init_transition()\n",
    "                #eps_steps[len(eps_rewards)%10] = episode_step_counter\n",
    "                #print(\"Positive rewards of this episode: \", positive_run)\n",
    "                break\n",
    "\n",
    "        eps_rewards.append(episode_reward_sum)\n",
    "\n",
    "        if len(eps_rewards) % 10 == 0:\n",
    "            #with open(path+'/logs/rewards.dat', 'a') as reward_file:\n",
    "                #print(\"[{}] {}, {}\".format(len(eps_rewards), step_counter, np.mean(eps_rewards[-100:])), file=reward_file)\n",
    "            print(\"{}, done {} games, {}, current eps {}\".format(step_counter, len(eps_rewards), np.mean(eps_rewards[-100:]), action_scheduler.eps_current) )\n",
    "    #torch.save(agent.main_dqn.state_dict(), path+'/checkpoints/fibre_agent_{}_reward_{:.2f}.pth'.format(step_counter, np.mean(eps_rewards[-100:])))\n",
    "\n",
    "########## evaluation starting here\n",
    "    eval_rewards = []\n",
    "    #agent.main_dqn.eval()\n",
    "    for _ in range(eval_runs):\n",
    "        eval_steps = 0\n",
    "        #state = env.reset()\n",
    "        transition = init_transition()\n",
    "        eval_episode_reward = 0\n",
    "        episode_final = 0\n",
    "        while eval_steps < max_episode_length:\n",
    "            action = action_scheduler.get_action(step_counter, torch.FloatTensor([np.array(transition)]).to(device), evaluation=True)\n",
    "\n",
    "            next_state, reward, terminal = env.step(action)\n",
    "            #next_state = next_state\n",
    "            next_transition = add_to_transition(next_state, transition)\n",
    "\n",
    "            eval_steps += 1\n",
    "            eval_episode_reward += reward\n",
    "            #state = next_state\n",
    "            transition = next_transition\n",
    "            if terminal:\n",
    "                terminal = False\n",
    "                if reward == 100:\n",
    "                    episode_final += 1\n",
    "                break\n",
    "\n",
    "        eval_rewards.append(eval_episode_reward)\n",
    "\n",
    "    print(\"Evaluation score:\", np.min(eval_rewards))\n",
    "    print(\"{} of {} episodes ended close to / at the final state.\".format(episode_final, eval_runs))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1 0 [ 73.85957396 107.914416    94.27166224] [ 74.42344 107.87124  93.08491] 1\n",
      "2 0 [ 74.06780362 107.94777426  95.24917318] [ 75.16057  107.88882   92.774536] 1\n",
      "3 1 [ 73.92988477 108.11007721  96.22622802] [ 75.78847 107.96255  92.28433] 1\n",
      "4 1 [ 73.79196592 108.27238015  97.20328285] [ 76.45265  108.118454  91.86654 ] 1\n",
      "5 1 [ 73.65404707 108.4346831   98.18033768] [ 77.116844 108.27435   91.448746] 1\n",
      "6 1 [ 73.51612822 108.59698604  99.15739251] [ 77.739716 108.54131   91.02359 ] 1\n",
      "7 1 [ 73.37820938 108.75928899 100.13444734] [ 78.36259  108.80828   90.598434] 0\n",
      "8 34 [ 74.30736787 108.67975499 100.49547204] [ 78.996666 109.15176   90.25207 ] 0\n",
      "9 34 [ 75.23652637 108.600221   100.85649674] [ 79.630745 109.495224  89.9057  ] 0\n",
      "10 34 [ 76.16568487 108.52068701 101.21752144] [ 80.264824 109.8387    89.55933 ] 0\n",
      "11 34 [ 77.09484336 108.44115301 101.57854613] [ 80.833374 110.28288   89.21371 ] 0\n",
      "12 34 [ 78.02400186 108.36161902 101.93957083] [ 81.32385 110.75597  88.79464] 0\n",
      "13 34 [ 78.95316035 108.28208503 102.30059553] [ 81.78852 111.07612  88.22755] 0\n",
      "14 19 [ 78.84027328 109.08554397 102.88515539] [ 82.26274  111.20639   87.596565] 0\n",
      "15 19 [ 78.72738621 109.88900292 103.46971526] [ 82.764885 111.12094   86.97968 ] 0\n",
      "16 19 [ 78.61449914 110.69246186 104.05427512] [ 83.17989 111.072    86.2975 ] 0\n",
      "17 101 [ 78.61449914 110.69246186 104.05427512] [ 83.60093  110.91725   85.635086] 1\n",
      "Evaluation score: 7\n"
     ]
    }
   ],
   "source": [
    "referenceLine = env.referenceStreamline_ijk\n",
    "eval_rewards = []\n",
    "all_distances = []\n",
    "all_states = []\n",
    "#agent.main_dqn.eval()\n",
    "for _ in range(1):\n",
    "    eval_steps = 0\n",
    "    state = env.reset()\n",
    "    all_states.append(state.getCoordinate())\n",
    "    transition = init_transition()\n",
    "    eval_episode_reward = 0\n",
    "    episode_final = 0\n",
    "    while eval_steps < max_episode_length:\n",
    "        action = action_scheduler.get_action(step_counter, torch.FloatTensor([np.array(transition)]).to(device), evaluation=True)\n",
    "\n",
    "        next_state, reward, terminal = env.step(action)\n",
    "        #next_state = next_state\n",
    "        next_transition = add_to_transition(next_state, transition)\n",
    "        reward = 1 + (1+(reward/10))\n",
    "        if reward > 1:\n",
    "            reward = 1\n",
    "        elif reward > 0.:\n",
    "            reward = 0\n",
    "        else:\n",
    "            reward = -1\n",
    "        eval_steps += 1\n",
    "        eval_episode_reward += reward\n",
    "        print(eval_steps, action, next_state.getCoordinate().numpy(), env.referenceStreamline_ijk[np.min([eval_steps,86])].numpy(), reward)\n",
    "        all_distances.append(reward)\n",
    "        all_states.append(next_state.getCoordinate())\n",
    "        \n",
    "        #state = next_state\n",
    "        transition = next_transition\n",
    "        if terminal:\n",
    "            terminal = False\n",
    "            #if reward > 0.9:\n",
    "            #    episode_final += 1\n",
    "            break\n",
    "\n",
    "    eval_rewards.append(eval_episode_reward)\n",
    "\n",
    "print(\"Evaluation score:\", np.min(eval_rewards))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "State:  [ 73.651344 107.88106   93.29415 ]\n",
      "Next State:  [ 74.56195007 107.80595503  92.88775652]\n",
      "7.450580596923828e-09\n"
     ]
    }
   ],
   "source": [
    "# Debugging the reward function\n",
    "referenceLine = env.referenceStreamline_ijk\n",
    "stepCounter = 0\n",
    "maxSteps=200\n",
    "state = env.reset()\n",
    "print(\"State: \", state.getCoordinate().numpy())\n",
    "next_state, _, terminal = env.step(80)\n",
    "print(\"Next State: \", next_state.getCoordinate().numpy())\n",
    "\n",
    "def lineseg_dist(p, a, b):\n",
    "\n",
    "    # normalized tangent vector\n",
    "    d = np.divide(b - a, np.linalg.norm(b - a))\n",
    "\n",
    "    # signed parallel distance components\n",
    "    s = np.dot(a - p, d)\n",
    "    t = np.dot(p - b, d)\n",
    "\n",
    "    # clamped parallel distance\n",
    "    h = np.maximum.reduce([s, t, 0])\n",
    "\n",
    "    # perpendicular distance component\n",
    "    c = np.cross(p - a, d)\n",
    "\n",
    "    return np.hypot(h, np.linalg.norm(c))\n",
    "\n",
    "distance = lineseg_dist(referenceLine[86].numpy(), referenceLine[85].numpy(), referenceLine[86].numpy())\n",
    "print(distance)\n",
    "\n",
    "#print(\"Diff: \", next_state.getCoordinate().numpy()-state.getCoordinate().numpy())\n",
    "#qry_pt = next_state.getCoordinate().view(-1,3)\n",
    "#print(\"Reference next state: \", referenceLine[stepCounter+1])\n",
    "#print(\"Diff to reference state: \", referenceLine[stepCounter+1]-next_state.getCoordinate().numpy())\n",
    "#distance = torch.min(torch.sum((referenceLine[np.min([stepCounter+1, maxSteps-1])] - qry_pt)**2, dim=1))\n",
    "#print(distance)\n",
    "#reward = torch.tanh(-distance+5.3)\n",
    "\n",
    "#if distance == -1:\n",
    "#    reward = 0.5\n",
    "#elif distance < 0.8:\n",
    "#    reward = 1+ (1-distance)\n",
    "#else:\n",
    "#    reward = np.max([1 - distance, -1])\n",
    "#print(reward)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.19954145509142476\n",
      "0.03981679230000309\n",
      "0.07041062249999892\n",
      "True\n"
     ]
    }
   ],
   "source": [
    "state = np.array([ 75.6, 107.95,  92.22])\n",
    "line = np.array([ 75.78847, 107.96255,  92.28433])\n",
    "\n",
    "print(np.linalg.norm(line - state, 2))\n",
    "\n",
    "sphere_dist = ((state[0] - line[0])**2 + (state[1]-line[1])**2 + (state[2]-line[2])**2)\n",
    "print(sphere_dist)\n",
    "normal_diff = np.sum(state-line)**2\n",
    "print(normal_diff)\n",
    "if sphere_dist < 0.2**2:\n",
    "    print(True)\n",
    "else:\n",
    "    print(False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Action:  100 Reward:  -0.6400096416473389\n",
      "Action:  80 Reward:  -0.3780286503520091\n",
      "Action:  75 Reward:  -0.17094774926353554\n",
      "Action:  80 Reward:  -0.06020208127816557\n",
      "Action:  75 Reward:  -0.023724592605490286\n",
      "Action:  100 Reward:  -0.023724592605490286\n",
      "Action:  62 Reward:  -0.031680450691759385\n",
      "Action:  75 Reward:  -0.10966306950569177\n",
      "Action:  83 Reward:  -0.2621558822401104\n",
      "Action:  75 Reward:  -0.4853828474102172\n",
      "Action:  83 Reward:  -0.7713330234194417\n",
      "Action:  100 Reward:  -0.7713330234194417\n",
      "Action:  83 Reward:  -1.158927472394806\n",
      "Action:  62 Reward:  -1.6468544226974164\n",
      "Action:  67 Reward:  -2.2078664481054533\n",
      "Action:  51 Reward:  -2.459970885856384\n",
      "Action:  67 Reward:  -3.0430611441644246\n",
      "Action:  100 Reward:  -3.0430611441644246\n",
      "Action:  59 Reward:  -3.7319386628026487\n",
      "Action:  59 Reward:  -4.531517914723884\n",
      "Action:  59 Reward:  -5.427621034792285\n",
      "Action:  100 Reward:  -5.427621034792285\n",
      "Action:  59 Reward:  -6.420164664306009\n",
      "Action:  56 Reward:  -7.21012573500936\n",
      "Action:  51 Reward:  -8.185668593823168\n",
      "Action:  56 Reward:  -9.264514952082235\n",
      "Action:  66 Reward:  -9.504376152250732\n",
      "Action:  100 Reward:  -9.504376152250732\n",
      "Action:  66 Reward:  -10.878316642589324\n",
      "Action:  71 Reward:  -11.684246290994608\n",
      "Action:  71 Reward:  -13.482882171224585\n",
      "Action:  79 Reward:  -15.013766894750662\n",
      "Action:  58 Reward:  -16.29778288166172\n",
      "Action:  100 Reward:  -16.29778288166172\n",
      "Action:  71 Reward:  -17.927867464472456\n",
      "Action:  71 Reward:  -19.616943063578457\n",
      "Action:  84 Reward:  -20.74882253322799\n",
      "Action:  71 Reward:  -22.68542229369059\n",
      "Action:  100 Reward:  -22.68542229369059\n",
      "Action:  92 Reward:  -24.094491148196\n",
      "Action:  84 Reward:  -26.036910111309087\n",
      "Action:  92 Reward:  -27.894909786068872\n",
      "Action:  97 Reward:  -29.22946434143986\n",
      "Action:  100 Reward:  -29.22946434143986\n",
      "Action:  97 Reward:  -30.93770942329201\n",
      "Action:  38 Reward:  -33.06379059780991\n",
      "Action:  97 Reward:  -35.48076469151409\n",
      "Action:  43 Reward:  -37.24656758094286\n",
      "Action:  38 Reward:  -39.87506653295411\n",
      "Action:  100 Reward:  -39.87506653295411\n",
      "Action:  43 Reward:  -42.07728895704025\n",
      "Action:  43 Reward:  -44.59950388329224\n",
      "Action:  89 Reward:  -46.525702788416744\n",
      "Action:  48 Reward:  -46.51577793318299\n",
      "Action:  100 Reward:  -46.51577793318299\n",
      "Action:  94 Reward:  -44.74553361569235\n",
      "Action:  81 Reward:  -46.71395822922152\n",
      "Action:  48 Reward:  -50.26025222152221\n",
      "Action:  43 Reward:  -53.83576866536265\n",
      "Action:  100 Reward:  -53.83576866536265\n",
      "Action:  35 Reward:  -57.7679173101252\n",
      "Action:  43 Reward:  -61.07110670119785\n",
      "Action:  35 Reward:  -64.29611023518841\n",
      "Action:  22 Reward:  -64.69258594426614\n",
      "Action:  27 Reward:  -67.94753644296517\n",
      "Action:  100 Reward:  -67.94753644296517\n",
      "Action:  6 Reward:  -68.60859514506335\n",
      "Action:  11 Reward:  -70.03265506052335\n",
      "Action:  3 Reward:  -69.6074991211795\n",
      "Action:  16 Reward:  -66.45768588248448\n",
      "Action:  100 Reward:  -66.45768588248448\n",
      "Action:  8 Reward:  -63.980960033928525\n",
      "Action:  29 Reward:  -63.97912872209463\n",
      "Action:  21 Reward:  -65.2877329760679\n",
      "Action:  21 Reward:  -71.00622766156863\n",
      "Action:  100 Reward:  -71.00622766156863\n",
      "Action:  34 Reward:  -75.30646175774287\n",
      "Action:  26 Reward:  -79.7251625711022\n",
      "Action:  26 Reward:  -85.7736700190284\n",
      "Action:  93 Reward:  -86.29779314738443\n",
      "Action:  39 Reward:  -89.76066176762737\n",
      "Action:  100 Reward:  -89.76066176762737\n",
      "Action:  93 Reward:  -92.76729682665923\n",
      "Action:  72 Reward:  -91.66762326274807\n",
      "Action:  77 Reward:  -91.52645978577566\n",
      "Action:  77 Reward:  -94.77110103827272\n",
      "Action:  100 Reward:  -94.77110103827272\n",
      "-3134.679829616308\n"
     ]
    }
   ],
   "source": [
    "#optimal_steps = [80, 75, 80, 75, 62, 75, 83, 96, 51, 24, 62, 62, 62, 77, 65, 64, 67, 59, 56, 83, 82, 54, 56, 53, 56, 38, 56, 84, 66, 71, 71, 64, 97, 84, 71, 71, 38, 51, 30, 92, 97, 84, 43, 79, 27, 46, 89, 25, 81, 25, 48, 43, 86, 48, 57, 14, 89, 43, 43, 19, 92, 14, 27, 9, 78, 4, 16, 3, 29, 3, 47, 6, 42, 21, 39, 5, 72, 34, 98, 88, 90, 75, 77, 59, 49, 32, 82, 100]\n",
    "eps_reward = 0\n",
    "state = env.reset()\n",
    "for i in optimal_steps:\n",
    "    next_state, reward, terminal = env.step(i)\n",
    "    state = next_state\n",
    "    eps_reward += reward.item()\n",
    "    print(\"Action: \", i, \"Reward: \", reward.item())\n",
    "print(eps_reward)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Init environment..\n",
      "Loading precomputed streamlines (data/HCP307200_DTI_smallSet.vtk) for ID 100307\n",
      "..done!\n"
     ]
    }
   ],
   "source": [
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "print(\"Init environment..\")\n",
    "env = RLTe.RLtractEnvironment(device = 'cpu')\n",
    "print(\"..done!\")\n",
    "n_actions = env.action_space.n\n",
    "#print(n_actions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([87, 3])\n"
     ]
    }
   ],
   "source": [
    "referenceLine = env.referenceStreamline_ijk\n",
    "print(referenceLine.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([47.8702, 74.8030, 26.6401])\n",
      "tensor([47.8702, 74.8030, 26.6401])\n"
     ]
    }
   ],
   "source": [
    "print(referenceLine[0])\n",
    "state = TractographyState(referenceLine[0], env.interpolateDWIatState)\n",
    "print(state.getCoordinate())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Step:  0 Action:  41 Distance:  tensor(1.3545, dtype=torch.float64)\n",
      "Step:  0 Action:  66 Distance:  tensor(1.2187, dtype=torch.float64)\n",
      "Step:  0 Action:  74 Distance:  tensor(1.5895, dtype=torch.float64)\n",
      "Step:  0 Action:  79 Distance:  tensor(1.4856, dtype=torch.float64)\n",
      "Step:  0 Action:  82 Distance:  tensor(1.2496, dtype=torch.float64)\n",
      "Step:  0 Action:  87 Distance:  tensor(1.5944, dtype=torch.float64)\n",
      "Step:  0 Action:  95 Distance:  tensor(1.5184, dtype=torch.float64)\n",
      "0 []\n",
      "Step:  1 Action:  61 Distance:  tensor(1.3162, dtype=torch.float64)\n",
      "Step:  1 Action:  66 Distance:  tensor(1.2710, dtype=torch.float64)\n",
      "Step:  1 Action:  74 Distance:  tensor(1.6272, dtype=torch.float64)\n",
      "Step:  1 Action:  79 Distance:  tensor(1.3920, dtype=torch.float64)\n",
      "Step:  1 Action:  82 Distance:  tensor(1.4070, dtype=torch.float64)\n",
      "Step:  1 Action:  87 Distance:  tensor(1.4471, dtype=torch.float64)\n",
      "Step:  1 Action:  95 Distance:  tensor(1.5094, dtype=torch.float64)\n",
      "1 []\n",
      "Step:  2 Action:  41 Distance:  tensor(1.2821, dtype=torch.float64)\n",
      "Step:  2 Action:  61 Distance:  tensor(1.2315, dtype=torch.float64)\n",
      "Step:  2 Action:  74 Distance:  tensor(1.6046, dtype=torch.float64)\n",
      "Step:  2 Action:  79 Distance:  tensor(1.3549, dtype=torch.float64)\n",
      "Step:  2 Action:  82 Distance:  tensor(1.4040, dtype=torch.float64)\n",
      "Step:  2 Action:  87 Distance:  tensor(1.4843, dtype=torch.float64)\n",
      "Step:  2 Action:  95 Distance:  tensor(1.5651, dtype=torch.float64)\n",
      "2 []\n",
      "Step:  3 Action:  41 Distance:  tensor(1.2908, dtype=torch.float64)\n",
      "Step:  3 Action:  49 Distance:  tensor(1.2627, dtype=torch.float64)\n",
      "Step:  3 Action:  61 Distance:  tensor(1.2172, dtype=torch.float64)\n",
      "Step:  3 Action:  74 Distance:  tensor(1.5797, dtype=torch.float64)\n",
      "Step:  3 Action:  79 Distance:  tensor(1.2516, dtype=torch.float64)\n",
      "Step:  3 Action:  82 Distance:  tensor(1.4621, dtype=torch.float64)\n",
      "Step:  3 Action:  87 Distance:  tensor(1.4322, dtype=torch.float64)\n",
      "Step:  3 Action:  95 Distance:  tensor(1.6009, dtype=torch.float64)\n",
      "3 []\n",
      "Step:  4 Action:  49 Distance:  tensor(1.3226, dtype=torch.float64)\n",
      "Step:  4 Action:  61 Distance:  tensor(1.3563, dtype=torch.float64)\n",
      "Step:  4 Action:  74 Distance:  tensor(1.5702, dtype=torch.float64)\n",
      "Step:  4 Action:  82 Distance:  tensor(1.5784, dtype=torch.float64)\n",
      "Step:  4 Action:  87 Distance:  tensor(1.2502, dtype=torch.float64)\n",
      "Step:  4 Action:  95 Distance:  tensor(1.5545, dtype=torch.float64)\n",
      "4 []\n",
      "Step:  5 Action:  49 Distance:  tensor(1.2380, dtype=torch.float64)\n",
      "Step:  5 Action:  61 Distance:  tensor(1.4426, dtype=torch.float64)\n",
      "Step:  5 Action:  69 Distance:  tensor(1.2523, dtype=torch.float64)\n",
      "Step:  5 Action:  74 Distance:  tensor(1.5910, dtype=torch.float64)\n",
      "Step:  5 Action:  82 Distance:  tensor(1.5806, dtype=torch.float64)\n",
      "Step:  5 Action:  87 Distance:  tensor(1.2100, dtype=torch.float64)\n",
      "Step:  5 Action:  95 Distance:  tensor(1.4956, dtype=torch.float64)\n",
      "5 []\n",
      "Step:  6 Action:  61 Distance:  tensor(1.5273, dtype=torch.float64)\n",
      "Step:  6 Action:  66 Distance:  tensor(1.3657, dtype=torch.float64)\n",
      "Step:  6 Action:  69 Distance:  tensor(1.2500, dtype=torch.float64)\n",
      "Step:  6 Action:  74 Distance:  tensor(1.6194, dtype=torch.float64)\n",
      "Step:  6 Action:  79 Distance:  tensor(1.2759, dtype=torch.float64)\n",
      "Step:  6 Action:  82 Distance:  tensor(1.5115, dtype=torch.float64)\n",
      "Step:  6 Action:  87 Distance:  tensor(1.2051, dtype=torch.float64)\n",
      "Step:  6 Action:  95 Distance:  tensor(1.3869, dtype=torch.float64)\n",
      "6 []\n",
      "Step:  7 Action:  61 Distance:  tensor(1.5700, dtype=torch.float64)\n",
      "Step:  7 Action:  66 Distance:  tensor(1.4237, dtype=torch.float64)\n",
      "Step:  7 Action:  69 Distance:  tensor(1.2798, dtype=torch.float64)\n",
      "Step:  7 Action:  74 Distance:  tensor(1.5954, dtype=torch.float64)\n",
      "Step:  7 Action:  79 Distance:  tensor(1.2693, dtype=torch.float64)\n",
      "Step:  7 Action:  82 Distance:  tensor(1.4712, dtype=torch.float64)\n",
      "Step:  7 Action:  95 Distance:  tensor(1.2862, dtype=torch.float64)\n",
      "7 []\n",
      "Step:  8 Action:  53 Distance:  tensor(1.2474, dtype=torch.float64)\n",
      "Step:  8 Action:  61 Distance:  tensor(1.6099, dtype=torch.float64)\n",
      "Step:  8 Action:  66 Distance:  tensor(1.4011, dtype=torch.float64)\n",
      "Step:  8 Action:  69 Distance:  tensor(1.3809, dtype=torch.float64)\n",
      "Step:  8 Action:  74 Distance:  tensor(1.5549, dtype=torch.float64)\n",
      "Step:  8 Action:  82 Distance:  tensor(1.4958, dtype=torch.float64)\n",
      "Step:  8 Action:  95 Distance:  tensor(1.2269, dtype=torch.float64)\n",
      "8 []\n",
      "Step:  9 Action:  53 Distance:  tensor(1.2052, dtype=torch.float64)\n",
      "Step:  9 Action:  56 Distance:  tensor(1.2501, dtype=torch.float64)\n",
      "Step:  9 Action:  61 Distance:  tensor(1.6062, dtype=torch.float64)\n",
      "Step:  9 Action:  66 Distance:  tensor(1.2593, dtype=torch.float64)\n",
      "Step:  9 Action:  69 Distance:  tensor(1.5104, dtype=torch.float64)\n",
      "Step:  9 Action:  74 Distance:  tensor(1.4608, dtype=torch.float64)\n",
      "Step:  9 Action:  82 Distance:  tensor(1.5458, dtype=torch.float64)\n",
      "9 []\n",
      "Step:  10 Action:  56 Distance:  tensor(1.2257, dtype=torch.float64)\n",
      "Step:  10 Action:  61 Distance:  tensor(1.5655, dtype=torch.float64)\n",
      "Step:  10 Action:  69 Distance:  tensor(1.5418, dtype=torch.float64)\n",
      "Step:  10 Action:  74 Distance:  tensor(1.4100, dtype=torch.float64)\n",
      "Step:  10 Action:  82 Distance:  tensor(1.5741, dtype=torch.float64)\n",
      "Step:  10 Action:  90 Distance:  tensor(1.2631, dtype=torch.float64)\n",
      "10 []\n",
      "Step:  11 Action:  56 Distance:  tensor(1.2257, dtype=torch.float64)\n",
      "Step:  11 Action:  61 Distance:  tensor(1.5655, dtype=torch.float64)\n",
      "Step:  11 Action:  69 Distance:  tensor(1.5418, dtype=torch.float64)\n",
      "Step:  11 Action:  74 Distance:  tensor(1.4100, dtype=torch.float64)\n",
      "Step:  11 Action:  82 Distance:  tensor(1.5741, dtype=torch.float64)\n",
      "Step:  11 Action:  90 Distance:  tensor(1.2631, dtype=torch.float64)\n",
      "11 []\n",
      "Step:  12 Action:  56 Distance:  tensor(1.3080, dtype=torch.float64)\n",
      "Step:  12 Action:  61 Distance:  tensor(1.5581, dtype=torch.float64)\n",
      "Step:  12 Action:  69 Distance:  tensor(1.5947, dtype=torch.float64)\n",
      "Step:  12 Action:  74 Distance:  tensor(1.3253, dtype=torch.float64)\n",
      "Step:  12 Action:  77 Distance:  tensor(1.2564, dtype=torch.float64)\n",
      "Step:  12 Action:  82 Distance:  tensor(1.5506, dtype=torch.float64)\n",
      "Step:  12 Action:  90 Distance:  tensor(1.2967, dtype=torch.float64)\n",
      "12 []\n",
      "Step:  13 Action:  56 Distance:  tensor(1.3643, dtype=torch.float64)\n",
      "Step:  13 Action:  61 Distance:  tensor(1.5247, dtype=torch.float64)\n",
      "Step:  13 Action:  64 Distance:  tensor(1.2298, dtype=torch.float64)\n",
      "Step:  13 Action:  69 Distance:  tensor(1.6218, dtype=torch.float64)\n",
      "Step:  13 Action:  74 Distance:  tensor(1.2146, dtype=torch.float64)\n",
      "Step:  13 Action:  77 Distance:  tensor(1.3332, dtype=torch.float64)\n",
      "Step:  13 Action:  82 Distance:  tensor(1.5012, dtype=torch.float64)\n",
      "Step:  13 Action:  90 Distance:  tensor(1.3043, dtype=torch.float64)\n",
      "13 []\n",
      "Step:  14 Action:  56 Distance:  tensor(1.3236, dtype=torch.float64)\n",
      "Step:  14 Action:  61 Distance:  tensor(1.4642, dtype=torch.float64)\n",
      "Step:  14 Action:  64 Distance:  tensor(1.2667, dtype=torch.float64)\n",
      "Step:  14 Action:  69 Distance:  tensor(1.6333, dtype=torch.float64)\n",
      "Step:  14 Action:  77 Distance:  tensor(1.4185, dtype=torch.float64)\n",
      "Step:  14 Action:  82 Distance:  tensor(1.5103, dtype=torch.float64)\n",
      "Step:  14 Action:  90 Distance:  tensor(1.3923, dtype=torch.float64)\n",
      "14 []\n",
      "Step:  15 Action:  56 Distance:  tensor(1.2585, dtype=torch.float64)\n",
      "Step:  15 Action:  61 Distance:  tensor(1.3793, dtype=torch.float64)\n",
      "Step:  15 Action:  64 Distance:  tensor(1.2792, dtype=torch.float64)\n",
      "Step:  15 Action:  69 Distance:  tensor(1.6204, dtype=torch.float64)\n",
      "Step:  15 Action:  77 Distance:  tensor(1.4794, dtype=torch.float64)\n",
      "Step:  15 Action:  82 Distance:  tensor(1.4951, dtype=torch.float64)\n",
      "Step:  15 Action:  90 Distance:  tensor(1.4558, dtype=torch.float64)\n",
      "15 []\n",
      "Step:  16 Action:  61 Distance:  tensor(1.2885, dtype=torch.float64)\n",
      "Step:  16 Action:  64 Distance:  tensor(1.2906, dtype=torch.float64)\n",
      "Step:  16 Action:  69 Distance:  tensor(1.6013, dtype=torch.float64)\n",
      "Step:  16 Action:  77 Distance:  tensor(1.5375, dtype=torch.float64)\n",
      "Step:  16 Action:  82 Distance:  tensor(1.4737, dtype=torch.float64)\n",
      "Step:  16 Action:  90 Distance:  tensor(1.5160, dtype=torch.float64)\n",
      "16 []\n",
      "Step:  17 Action:  64 Distance:  tensor(1.2763, dtype=torch.float64)\n",
      "Step:  17 Action:  69 Distance:  tensor(1.5565, dtype=torch.float64)\n",
      "Step:  17 Action:  77 Distance:  tensor(1.5700, dtype=torch.float64)\n",
      "Step:  17 Action:  82 Distance:  tensor(1.4267, dtype=torch.float64)\n",
      "Step:  17 Action:  90 Distance:  tensor(1.5504, dtype=torch.float64)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Step:  17 Action:  98 Distance:  tensor(1.2671, dtype=torch.float64)\n",
      "17 []\n",
      "Step:  18 Action:  64 Distance:  tensor(1.2763, dtype=torch.float64)\n",
      "Step:  18 Action:  69 Distance:  tensor(1.5565, dtype=torch.float64)\n",
      "Step:  18 Action:  77 Distance:  tensor(1.5700, dtype=torch.float64)\n",
      "Step:  18 Action:  82 Distance:  tensor(1.4267, dtype=torch.float64)\n",
      "Step:  18 Action:  90 Distance:  tensor(1.5504, dtype=torch.float64)\n",
      "Step:  18 Action:  98 Distance:  tensor(1.2671, dtype=torch.float64)\n",
      "18 []\n",
      "Step:  19 Action:  64 Distance:  tensor(1.2807, dtype=torch.float64)\n",
      "Step:  19 Action:  69 Distance:  tensor(1.5051, dtype=torch.float64)\n",
      "Step:  19 Action:  77 Distance:  tensor(1.6072, dtype=torch.float64)\n",
      "Step:  19 Action:  82 Distance:  tensor(1.3555, dtype=torch.float64)\n",
      "Step:  19 Action:  85 Distance:  tensor(1.2477, dtype=torch.float64)\n",
      "Step:  19 Action:  90 Distance:  tensor(1.5722, dtype=torch.float64)\n",
      "Step:  19 Action:  98 Distance:  tensor(1.3832, dtype=torch.float64)\n",
      "19 []\n",
      "Step:  20 Action:  44 Distance:  tensor(1.3385, dtype=torch.float64)\n",
      "Step:  20 Action:  49 Distance:  tensor(1.2286, dtype=torch.float64)\n",
      "Step:  20 Action:  69 Distance:  tensor(1.3823, dtype=torch.float64)\n",
      "Step:  20 Action:  77 Distance:  tensor(1.5818, dtype=torch.float64)\n",
      "Step:  20 Action:  82 Distance:  tensor(1.2872, dtype=torch.float64)\n",
      "Step:  20 Action:  85 Distance:  tensor(1.2530, dtype=torch.float64)\n",
      "Step:  20 Action:  90 Distance:  tensor(1.6020, dtype=torch.float64)\n",
      "Step:  20 Action:  98 Distance:  tensor(1.4867, dtype=torch.float64)\n",
      "20 []\n",
      "Step:  21 Action:  44 Distance:  tensor(1.4217, dtype=torch.float64)\n",
      "Step:  21 Action:  49 Distance:  tensor(1.2387, dtype=torch.float64)\n",
      "Step:  21 Action:  69 Distance:  tensor(1.2773, dtype=torch.float64)\n",
      "Step:  21 Action:  77 Distance:  tensor(1.5501, dtype=torch.float64)\n",
      "Step:  21 Action:  82 Distance:  tensor(1.2059, dtype=torch.float64)\n",
      "Step:  21 Action:  85 Distance:  tensor(1.2581, dtype=torch.float64)\n",
      "Step:  21 Action:  90 Distance:  tensor(1.5947, dtype=torch.float64)\n",
      "Step:  21 Action:  98 Distance:  tensor(1.5446, dtype=torch.float64)\n",
      "21 []\n",
      "Step:  22 Action:  44 Distance:  tensor(1.4126, dtype=torch.float64)\n",
      "Step:  22 Action:  69 Distance:  tensor(1.2116, dtype=torch.float64)\n",
      "Step:  22 Action:  77 Distance:  tensor(1.5488, dtype=torch.float64)\n",
      "Step:  22 Action:  85 Distance:  tensor(1.3282, dtype=torch.float64)\n",
      "Step:  22 Action:  90 Distance:  tensor(1.5470, dtype=torch.float64)\n",
      "Step:  22 Action:  98 Distance:  tensor(1.5829, dtype=torch.float64)\n",
      "22 []\n",
      "Step:  23 Action:  31 Distance:  tensor(1.2443, dtype=torch.float64)\n",
      "Step:  23 Action:  39 Distance:  tensor(1.2866, dtype=torch.float64)\n",
      "Step:  23 Action:  44 Distance:  tensor(1.3997, dtype=torch.float64)\n",
      "Step:  23 Action:  77 Distance:  tensor(1.5426, dtype=torch.float64)\n",
      "Step:  23 Action:  85 Distance:  tensor(1.3959, dtype=torch.float64)\n",
      "Step:  23 Action:  90 Distance:  tensor(1.4943, dtype=torch.float64)\n",
      "Step:  23 Action:  98 Distance:  tensor(1.6163, dtype=torch.float64)\n",
      "23 []\n",
      "Step:  24 Action:  31 Distance:  tensor(1.2934, dtype=torch.float64)\n",
      "Step:  24 Action:  39 Distance:  tensor(1.3726, dtype=torch.float64)\n",
      "Step:  24 Action:  44 Distance:  tensor(1.3641, dtype=torch.float64)\n",
      "Step:  24 Action:  77 Distance:  tensor(1.5137, dtype=torch.float64)\n",
      "Step:  24 Action:  85 Distance:  tensor(1.4408, dtype=torch.float64)\n",
      "Step:  24 Action:  90 Distance:  tensor(1.4189, dtype=torch.float64)\n",
      "Step:  24 Action:  98 Distance:  tensor(1.6270, dtype=torch.float64)\n",
      "24 []\n",
      "Step:  25 Action:  31 Distance:  tensor(1.3955, dtype=torch.float64)\n",
      "Step:  25 Action:  39 Distance:  tensor(1.4232, dtype=torch.float64)\n",
      "Step:  25 Action:  44 Distance:  tensor(1.4189, dtype=torch.float64)\n",
      "Step:  25 Action:  77 Distance:  tensor(1.4476, dtype=torch.float64)\n",
      "Step:  25 Action:  85 Distance:  tensor(1.4018, dtype=torch.float64)\n",
      "Step:  25 Action:  90 Distance:  tensor(1.3865, dtype=torch.float64)\n",
      "Step:  25 Action:  98 Distance:  tensor(1.6444, dtype=torch.float64)\n",
      "25 []\n",
      "Step:  26 Action:  23 Distance:  tensor(1.2010, dtype=torch.float64)\n",
      "Step:  26 Action:  31 Distance:  tensor(1.5438, dtype=torch.float64)\n",
      "Step:  26 Action:  39 Distance:  tensor(1.4724, dtype=torch.float64)\n",
      "Step:  26 Action:  44 Distance:  tensor(1.4670, dtype=torch.float64)\n",
      "Step:  26 Action:  77 Distance:  tensor(1.2564, dtype=torch.float64)\n",
      "Step:  26 Action:  85 Distance:  tensor(1.2705, dtype=torch.float64)\n",
      "Step:  26 Action:  90 Distance:  tensor(1.2592, dtype=torch.float64)\n",
      "Step:  26 Action:  98 Distance:  tensor(1.6194, dtype=torch.float64)\n",
      "26 []\n",
      "Step:  27 Action:  23 Distance:  tensor(1.2617, dtype=torch.float64)\n",
      "Step:  27 Action:  26 Distance:  tensor(1.3512, dtype=torch.float64)\n",
      "Step:  27 Action:  31 Distance:  tensor(1.6077, dtype=torch.float64)\n",
      "Step:  27 Action:  39 Distance:  tensor(1.5253, dtype=torch.float64)\n",
      "Step:  27 Action:  44 Distance:  tensor(1.3890, dtype=torch.float64)\n",
      "Step:  27 Action:  98 Distance:  tensor(1.5487, dtype=torch.float64)\n",
      "27 []\n",
      "Step:  28 Action:  18 Distance:  tensor(1.2351, dtype=torch.float64)\n",
      "Step:  28 Action:  23 Distance:  tensor(1.2164, dtype=torch.float64)\n",
      "Step:  28 Action:  26 Distance:  tensor(1.4285, dtype=torch.float64)\n",
      "Step:  28 Action:  31 Distance:  tensor(1.6014, dtype=torch.float64)\n",
      "Step:  28 Action:  39 Distance:  tensor(1.5558, dtype=torch.float64)\n",
      "Step:  28 Action:  44 Distance:  tensor(1.2939, dtype=torch.float64)\n",
      "Step:  28 Action:  98 Distance:  tensor(1.4966, dtype=torch.float64)\n",
      "28 []\n",
      "Step:  29 Action:  18 Distance:  tensor(1.3395, dtype=torch.float64)\n",
      "Step:  29 Action:  23 Distance:  tensor(1.2725, dtype=torch.float64)\n",
      "Step:  29 Action:  26 Distance:  tensor(1.4920, dtype=torch.float64)\n",
      "Step:  29 Action:  31 Distance:  tensor(1.6207, dtype=torch.float64)\n",
      "Step:  29 Action:  39 Distance:  tensor(1.5335, dtype=torch.float64)\n",
      "Step:  29 Action:  44 Distance:  tensor(1.2629, dtype=torch.float64)\n",
      "Step:  29 Action:  98 Distance:  tensor(1.4319, dtype=torch.float64)\n",
      "29 []\n",
      "Step:  30 Action:  18 Distance:  tensor(1.4184, dtype=torch.float64)\n",
      "Step:  30 Action:  23 Distance:  tensor(1.3032, dtype=torch.float64)\n",
      "Step:  30 Action:  26 Distance:  tensor(1.5302, dtype=torch.float64)\n",
      "Step:  30 Action:  31 Distance:  tensor(1.6147, dtype=torch.float64)\n",
      "Step:  30 Action:  39 Distance:  tensor(1.4859, dtype=torch.float64)\n",
      "Step:  30 Action:  44 Distance:  tensor(1.2065, dtype=torch.float64)\n",
      "Step:  30 Action:  98 Distance:  tensor(1.3418, dtype=torch.float64)\n",
      "30 []\n",
      "Step:  31 Action:  13 Distance:  tensor(1.2379, dtype=torch.float64)\n",
      "Step:  31 Action:  18 Distance:  tensor(1.4916, dtype=torch.float64)\n",
      "Step:  31 Action:  23 Distance:  tensor(1.3284, dtype=torch.float64)\n",
      "Step:  31 Action:  26 Distance:  tensor(1.5638, dtype=torch.float64)\n",
      "Step:  31 Action:  31 Distance:  tensor(1.6021, dtype=torch.float64)\n",
      "Step:  31 Action:  39 Distance:  tensor(1.4352, dtype=torch.float64)\n",
      "Step:  31 Action:  98 Distance:  tensor(1.2489, dtype=torch.float64)\n",
      "31 []\n",
      "Step:  32 Action:  0 Distance:  tensor(1.2495, dtype=torch.float64)\n",
      "Step:  32 Action:  13 Distance:  tensor(1.4117, dtype=torch.float64)\n",
      "Step:  32 Action:  18 Distance:  tensor(1.5820, dtype=torch.float64)\n",
      "Step:  32 Action:  23 Distance:  tensor(1.3226, dtype=torch.float64)\n",
      "Step:  32 Action:  26 Distance:  tensor(1.5775, dtype=torch.float64)\n",
      "Step:  32 Action:  31 Distance:  tensor(1.5211, dtype=torch.float64)\n",
      "Step:  32 Action:  39 Distance:  tensor(1.2828, dtype=torch.float64)\n",
      "32 []\n",
      "Step:  33 Action:  0 Distance:  tensor(1.4203, dtype=torch.float64)\n",
      "Step:  33 Action:  5 Distance:  tensor(1.3761, dtype=torch.float64)\n",
      "Step:  33 Action:  10 Distance:  tensor(1.2212, dtype=torch.float64)\n",
      "Step:  33 Action:  13 Distance:  tensor(1.5318, dtype=torch.float64)\n",
      "Step:  33 Action:  18 Distance:  tensor(1.6109, dtype=torch.float64)\n",
      "Step:  33 Action:  23 Distance:  tensor(1.2563, dtype=torch.float64)\n",
      "Step:  33 Action:  26 Distance:  tensor(1.5325, dtype=torch.float64)\n",
      "Step:  33 Action:  31 Distance:  tensor(1.3783, dtype=torch.float64)\n",
      "33 []\n",
      "Step:  34 Action:  0 Distance:  tensor(1.5741, dtype=torch.float64)\n",
      "Step:  34 Action:  5 Distance:  tensor(1.4806, dtype=torch.float64)\n",
      "Step:  34 Action:  8 Distance:  tensor(1.2429, dtype=torch.float64)\n",
      "Step:  34 Action:  10 Distance:  tensor(1.2187, dtype=torch.float64)\n",
      "Step:  34 Action:  13 Distance:  tensor(1.6071, dtype=torch.float64)\n",
      "Step:  34 Action:  18 Distance:  tensor(1.5614, dtype=torch.float64)\n",
      "Step:  34 Action:  21 Distance:  tensor(1.2155, dtype=torch.float64)\n",
      "Step:  34 Action:  26 Distance:  tensor(1.4623, dtype=torch.float64)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Step:  34 Action:  34 Distance:  tensor(1.2363, dtype=torch.float64)\n",
      "34 []\n",
      "Step:  35 Action:  0 Distance:  tensor(1.6504, dtype=torch.float64)\n",
      "Step:  35 Action:  5 Distance:  tensor(1.4896, dtype=torch.float64)\n",
      "Step:  35 Action:  8 Distance:  tensor(1.3297, dtype=torch.float64)\n",
      "Step:  35 Action:  13 Distance:  tensor(1.6255, dtype=torch.float64)\n",
      "Step:  35 Action:  18 Distance:  tensor(1.5023, dtype=torch.float64)\n",
      "Step:  35 Action:  21 Distance:  tensor(1.3069, dtype=torch.float64)\n",
      "Step:  35 Action:  26 Distance:  tensor(1.4191, dtype=torch.float64)\n",
      "Step:  35 Action:  34 Distance:  tensor(1.2754, dtype=torch.float64)\n",
      "35 []\n",
      "Step:  36 Action:  0 Distance:  tensor(1.6504, dtype=torch.float64)\n",
      "Step:  36 Action:  5 Distance:  tensor(1.4574, dtype=torch.float64)\n",
      "Step:  36 Action:  8 Distance:  tensor(1.3736, dtype=torch.float64)\n",
      "Step:  36 Action:  13 Distance:  tensor(1.6424, dtype=torch.float64)\n",
      "Step:  36 Action:  18 Distance:  tensor(1.4433, dtype=torch.float64)\n",
      "Step:  36 Action:  21 Distance:  tensor(1.3961, dtype=torch.float64)\n",
      "Step:  36 Action:  26 Distance:  tensor(1.4171, dtype=torch.float64)\n",
      "Step:  36 Action:  34 Distance:  tensor(1.3541, dtype=torch.float64)\n",
      "36 []\n",
      "Step:  37 Action:  0 Distance:  tensor(1.6297, dtype=torch.float64)\n",
      "Step:  37 Action:  5 Distance:  tensor(1.3586, dtype=torch.float64)\n",
      "Step:  37 Action:  8 Distance:  tensor(1.3157, dtype=torch.float64)\n",
      "Step:  37 Action:  13 Distance:  tensor(1.6391, dtype=torch.float64)\n",
      "Step:  37 Action:  18 Distance:  tensor(1.3957, dtype=torch.float64)\n",
      "Step:  37 Action:  21 Distance:  tensor(1.4311, dtype=torch.float64)\n",
      "Step:  37 Action:  26 Distance:  tensor(1.4701, dtype=torch.float64)\n",
      "Step:  37 Action:  34 Distance:  tensor(1.4513, dtype=torch.float64)\n",
      "37 []\n",
      "Step:  38 Action:  0 Distance:  tensor(1.5064, dtype=torch.float64)\n",
      "Step:  38 Action:  5 Distance:  tensor(1.2675, dtype=torch.float64)\n",
      "Step:  38 Action:  8 Distance:  tensor(1.2816, dtype=torch.float64)\n",
      "Step:  38 Action:  13 Distance:  tensor(1.6227, dtype=torch.float64)\n",
      "Step:  38 Action:  18 Distance:  tensor(1.3224, dtype=torch.float64)\n",
      "Step:  38 Action:  21 Distance:  tensor(1.4697, dtype=torch.float64)\n",
      "Step:  38 Action:  26 Distance:  tensor(1.4794, dtype=torch.float64)\n",
      "Step:  38 Action:  34 Distance:  tensor(1.5213, dtype=torch.float64)\n",
      "Step:  38 Action:  47 Distance:  tensor(1.2133, dtype=torch.float64)\n",
      "38 []\n",
      "Step:  39 Action:  0 Distance:  tensor(1.5209, dtype=torch.float64)\n",
      "Step:  39 Action:  5 Distance:  tensor(1.2129, dtype=torch.float64)\n",
      "Step:  39 Action:  8 Distance:  tensor(1.3191, dtype=torch.float64)\n",
      "Step:  39 Action:  13 Distance:  tensor(1.5965, dtype=torch.float64)\n",
      "Step:  39 Action:  18 Distance:  tensor(1.2075, dtype=torch.float64)\n",
      "Step:  39 Action:  21 Distance:  tensor(1.5323, dtype=torch.float64)\n",
      "Step:  39 Action:  26 Distance:  tensor(1.4036, dtype=torch.float64)\n",
      "Step:  39 Action:  34 Distance:  tensor(1.5428, dtype=torch.float64)\n",
      "39 []\n",
      "Step:  40 Action:  0 Distance:  tensor(1.5209, dtype=torch.float64)\n",
      "Step:  40 Action:  5 Distance:  tensor(1.2129, dtype=torch.float64)\n",
      "Step:  40 Action:  8 Distance:  tensor(1.3191, dtype=torch.float64)\n",
      "Step:  40 Action:  13 Distance:  tensor(1.5965, dtype=torch.float64)\n",
      "Step:  40 Action:  18 Distance:  tensor(1.2075, dtype=torch.float64)\n",
      "Step:  40 Action:  21 Distance:  tensor(1.5323, dtype=torch.float64)\n",
      "Step:  40 Action:  26 Distance:  tensor(1.4036, dtype=torch.float64)\n",
      "Step:  40 Action:  34 Distance:  tensor(1.5428, dtype=torch.float64)\n",
      "40 []\n",
      "Step:  41 Action:  0 Distance:  tensor(1.5209, dtype=torch.float64)\n",
      "Step:  41 Action:  5 Distance:  tensor(1.2129, dtype=torch.float64)\n",
      "Step:  41 Action:  8 Distance:  tensor(1.3191, dtype=torch.float64)\n",
      "Step:  41 Action:  13 Distance:  tensor(1.5965, dtype=torch.float64)\n",
      "Step:  41 Action:  18 Distance:  tensor(1.2075, dtype=torch.float64)\n",
      "Step:  41 Action:  21 Distance:  tensor(1.5323, dtype=torch.float64)\n",
      "Step:  41 Action:  26 Distance:  tensor(1.4036, dtype=torch.float64)\n",
      "Step:  41 Action:  34 Distance:  tensor(1.5428, dtype=torch.float64)\n",
      "41 []\n",
      "Step:  42 Action:  0 Distance:  tensor(1.5209, dtype=torch.float64)\n",
      "Step:  42 Action:  5 Distance:  tensor(1.2129, dtype=torch.float64)\n",
      "Step:  42 Action:  8 Distance:  tensor(1.3191, dtype=torch.float64)\n",
      "Step:  42 Action:  13 Distance:  tensor(1.5965, dtype=torch.float64)\n",
      "Step:  42 Action:  18 Distance:  tensor(1.2075, dtype=torch.float64)\n",
      "Step:  42 Action:  21 Distance:  tensor(1.5323, dtype=torch.float64)\n",
      "Step:  42 Action:  26 Distance:  tensor(1.4036, dtype=torch.float64)\n",
      "Step:  42 Action:  34 Distance:  tensor(1.5428, dtype=torch.float64)\n",
      "42 []\n",
      "Step:  43 Action:  0 Distance:  tensor(1.5209, dtype=torch.float64)\n",
      "Step:  43 Action:  5 Distance:  tensor(1.2129, dtype=torch.float64)\n",
      "Step:  43 Action:  8 Distance:  tensor(1.3191, dtype=torch.float64)\n",
      "Step:  43 Action:  13 Distance:  tensor(1.5965, dtype=torch.float64)\n",
      "Step:  43 Action:  18 Distance:  tensor(1.2075, dtype=torch.float64)\n",
      "Step:  43 Action:  21 Distance:  tensor(1.5323, dtype=torch.float64)\n",
      "Step:  43 Action:  26 Distance:  tensor(1.4036, dtype=torch.float64)\n",
      "Step:  43 Action:  34 Distance:  tensor(1.5428, dtype=torch.float64)\n",
      "43 []\n",
      "Step:  44 Action:  0 Distance:  tensor(1.5209, dtype=torch.float64)\n",
      "Step:  44 Action:  5 Distance:  tensor(1.2129, dtype=torch.float64)\n",
      "Step:  44 Action:  8 Distance:  tensor(1.3191, dtype=torch.float64)\n",
      "Step:  44 Action:  13 Distance:  tensor(1.5965, dtype=torch.float64)\n",
      "Step:  44 Action:  18 Distance:  tensor(1.2075, dtype=torch.float64)\n",
      "Step:  44 Action:  21 Distance:  tensor(1.5323, dtype=torch.float64)\n",
      "Step:  44 Action:  26 Distance:  tensor(1.4036, dtype=torch.float64)\n",
      "Step:  44 Action:  34 Distance:  tensor(1.5428, dtype=torch.float64)\n",
      "44 []\n",
      "Step:  45 Action:  0 Distance:  tensor(1.5209, dtype=torch.float64)\n",
      "Step:  45 Action:  5 Distance:  tensor(1.2129, dtype=torch.float64)\n",
      "Step:  45 Action:  8 Distance:  tensor(1.3191, dtype=torch.float64)\n",
      "Step:  45 Action:  13 Distance:  tensor(1.5965, dtype=torch.float64)\n",
      "Step:  45 Action:  18 Distance:  tensor(1.2075, dtype=torch.float64)\n",
      "Step:  45 Action:  21 Distance:  tensor(1.5323, dtype=torch.float64)\n",
      "Step:  45 Action:  26 Distance:  tensor(1.4036, dtype=torch.float64)\n",
      "Step:  45 Action:  34 Distance:  tensor(1.5428, dtype=torch.float64)\n",
      "45 []\n",
      "Step:  46 Action:  0 Distance:  tensor(1.5209, dtype=torch.float64)\n",
      "Step:  46 Action:  5 Distance:  tensor(1.2129, dtype=torch.float64)\n",
      "Step:  46 Action:  8 Distance:  tensor(1.3191, dtype=torch.float64)\n",
      "Step:  46 Action:  13 Distance:  tensor(1.5965, dtype=torch.float64)\n",
      "Step:  46 Action:  18 Distance:  tensor(1.2075, dtype=torch.float64)\n",
      "Step:  46 Action:  21 Distance:  tensor(1.5323, dtype=torch.float64)\n",
      "Step:  46 Action:  26 Distance:  tensor(1.4036, dtype=torch.float64)\n",
      "Step:  46 Action:  34 Distance:  tensor(1.5428, dtype=torch.float64)\n",
      "46 []\n",
      "Step:  47 Action:  0 Distance:  tensor(1.5209, dtype=torch.float64)\n",
      "Step:  47 Action:  8 Distance:  tensor(1.2639, dtype=torch.float64)\n",
      "Step:  47 Action:  13 Distance:  tensor(1.5583, dtype=torch.float64)\n",
      "Step:  47 Action:  21 Distance:  tensor(1.5480, dtype=torch.float64)\n",
      "Step:  47 Action:  26 Distance:  tensor(1.3944, dtype=torch.float64)\n",
      "Step:  47 Action:  34 Distance:  tensor(1.5913, dtype=torch.float64)\n",
      "Step:  47 Action:  42 Distance:  tensor(1.2956, dtype=torch.float64)\n",
      "Step:  47 Action:  47 Distance:  tensor(1.2660, dtype=torch.float64)\n",
      "47 []\n",
      "Step:  48 Action:  0 Distance:  tensor(1.3885, dtype=torch.float64)\n",
      "Step:  48 Action:  8 Distance:  tensor(1.2964, dtype=torch.float64)\n",
      "Step:  48 Action:  13 Distance:  tensor(1.5198, dtype=torch.float64)\n",
      "Step:  48 Action:  21 Distance:  tensor(1.5907, dtype=torch.float64)\n",
      "Step:  48 Action:  26 Distance:  tensor(1.3027, dtype=torch.float64)\n",
      "Step:  48 Action:  29 Distance:  tensor(1.2582, dtype=torch.float64)\n",
      "Step:  48 Action:  34 Distance:  tensor(1.5862, dtype=torch.float64)\n",
      "Step:  48 Action:  42 Distance:  tensor(1.3674, dtype=torch.float64)\n",
      "Step:  48 Action:  47 Distance:  tensor(1.2157, dtype=torch.float64)\n",
      "48 []\n",
      "Step:  49 Action:  0 Distance:  tensor(1.5321, dtype=torch.float64)\n",
      "Step:  49 Action:  8 Distance:  tensor(1.3821, dtype=torch.float64)\n",
      "Step:  49 Action:  13 Distance:  tensor(1.5176, dtype=torch.float64)\n",
      "Step:  49 Action:  21 Distance:  tensor(1.6158, dtype=torch.float64)\n",
      "Step:  49 Action:  26 Distance:  tensor(1.2182, dtype=torch.float64)\n",
      "Step:  49 Action:  29 Distance:  tensor(1.3106, dtype=torch.float64)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Step:  49 Action:  34 Distance:  tensor(1.5309, dtype=torch.float64)\n",
      "Step:  49 Action:  42 Distance:  tensor(1.3322, dtype=torch.float64)\n",
      "49 []\n",
      "Step:  50 Action:  0 Distance:  tensor(1.5322, dtype=torch.float64)\n",
      "Step:  50 Action:  8 Distance:  tensor(1.3821, dtype=torch.float64)\n",
      "Step:  50 Action:  13 Distance:  tensor(1.5176, dtype=torch.float64)\n",
      "Step:  50 Action:  21 Distance:  tensor(1.6158, dtype=torch.float64)\n",
      "Step:  50 Action:  26 Distance:  tensor(1.2182, dtype=torch.float64)\n",
      "Step:  50 Action:  29 Distance:  tensor(1.3106, dtype=torch.float64)\n",
      "Step:  50 Action:  34 Distance:  tensor(1.5309, dtype=torch.float64)\n",
      "Step:  50 Action:  42 Distance:  tensor(1.3322, dtype=torch.float64)\n",
      "50 []\n",
      "Step:  51 Action:  0 Distance:  tensor(1.5321, dtype=torch.float64)\n",
      "Step:  51 Action:  5 Distance:  tensor(1.2367, dtype=torch.float64)\n",
      "Step:  51 Action:  8 Distance:  tensor(1.4490, dtype=torch.float64)\n",
      "Step:  51 Action:  13 Distance:  tensor(1.5675, dtype=torch.float64)\n",
      "Step:  51 Action:  21 Distance:  tensor(1.6079, dtype=torch.float64)\n",
      "Step:  51 Action:  26 Distance:  tensor(1.2407, dtype=torch.float64)\n",
      "Step:  51 Action:  29 Distance:  tensor(1.2570, dtype=torch.float64)\n",
      "Step:  51 Action:  34 Distance:  tensor(1.4905, dtype=torch.float64)\n",
      "Step:  51 Action:  42 Distance:  tensor(1.2329, dtype=torch.float64)\n",
      "51 []\n",
      "Step:  52 Action:  0 Distance:  tensor(1.6565, dtype=torch.float64)\n",
      "Step:  52 Action:  5 Distance:  tensor(1.3360, dtype=torch.float64)\n",
      "Step:  52 Action:  8 Distance:  tensor(1.4893, dtype=torch.float64)\n",
      "Step:  52 Action:  13 Distance:  tensor(1.5909, dtype=torch.float64)\n",
      "Step:  52 Action:  21 Distance:  tensor(1.5736, dtype=torch.float64)\n",
      "Step:  52 Action:  26 Distance:  tensor(1.2366, dtype=torch.float64)\n",
      "Step:  52 Action:  34 Distance:  tensor(1.4237, dtype=torch.float64)\n",
      "52 []\n",
      "Step:  53 Action:  0 Distance:  tensor(1.6565, dtype=torch.float64)\n",
      "Step:  53 Action:  5 Distance:  tensor(1.3360, dtype=torch.float64)\n",
      "Step:  53 Action:  8 Distance:  tensor(1.4893, dtype=torch.float64)\n",
      "Step:  53 Action:  13 Distance:  tensor(1.5909, dtype=torch.float64)\n",
      "Step:  53 Action:  21 Distance:  tensor(1.5736, dtype=torch.float64)\n",
      "Step:  53 Action:  26 Distance:  tensor(1.2366, dtype=torch.float64)\n",
      "Step:  53 Action:  34 Distance:  tensor(1.4237, dtype=torch.float64)\n",
      "53 []\n",
      "Step:  54 Action:  0 Distance:  tensor(1.6565, dtype=torch.float64)\n",
      "Step:  54 Action:  5 Distance:  tensor(1.4373, dtype=torch.float64)\n",
      "Step:  54 Action:  8 Distance:  tensor(1.5157, dtype=torch.float64)\n",
      "Step:  54 Action:  13 Distance:  tensor(1.6149, dtype=torch.float64)\n",
      "Step:  54 Action:  18 Distance:  tensor(1.2637, dtype=torch.float64)\n",
      "Step:  54 Action:  21 Distance:  tensor(1.5260, dtype=torch.float64)\n",
      "Step:  54 Action:  26 Distance:  tensor(1.2495, dtype=torch.float64)\n",
      "Step:  54 Action:  34 Distance:  tensor(1.3568, dtype=torch.float64)\n",
      "54 []\n",
      "Step:  55 Action:  0 Distance:  tensor(1.7441, dtype=torch.float64)\n",
      "Step:  55 Action:  5 Distance:  tensor(1.5640, dtype=torch.float64)\n",
      "Step:  55 Action:  8 Distance:  tensor(1.5016, dtype=torch.float64)\n",
      "Step:  55 Action:  13 Distance:  tensor(1.5992, dtype=torch.float64)\n",
      "Step:  55 Action:  18 Distance:  tensor(1.3915, dtype=torch.float64)\n",
      "Step:  55 Action:  21 Distance:  tensor(1.3772, dtype=torch.float64)\n",
      "Step:  55 Action:  26 Distance:  tensor(1.2197, dtype=torch.float64)\n",
      "55 []\n",
      "Step:  56 Action:  0 Distance:  tensor(1.7894, dtype=torch.float64)\n"
     ]
    },
    {
     "ename": "IndexError",
     "evalue": "index 58 is out of bounds for dimension 0 with size 58",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mIndexError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-6-a7dce26ea5fa>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      7\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0mz\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mn_actions\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m         \u001b[0menv\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstate\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mTractographyState\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mreferenceLine\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0menv\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minterpolateDWIatState\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 9\u001b[0;31m         \u001b[0mnext_state\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mreward\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0menv\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mz\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     10\u001b[0m         \u001b[0menv\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstepCounter\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mi\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     11\u001b[0m         \u001b[0;31m#if reward == -1:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/fibre_tracking/deepFibreTracking/dfibert/envs/RLtractEnvironment.py\u001b[0m in \u001b[0;36mstep\u001b[0;34m(self, action)\u001b[0m\n\u001b[1;32m    138\u001b[0m         \u001b[0;31m#else:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    139\u001b[0m         \u001b[0;31m#    rewardNextState = rewardDistance\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 140\u001b[0;31m         \u001b[0mrewardNextState\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrewardForState\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnextState\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    141\u001b[0m         \u001b[0;31m#if rewardNextState < 0.:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    142\u001b[0m         \u001b[0;31m#    rewardNextState = -1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/fibre_tracking/deepFibreTracking/dfibert/envs/RLtractEnvironment.py\u001b[0m in \u001b[0;36mrewardForState\u001b[0;34m(self, state)\u001b[0m\n\u001b[1;32m    160\u001b[0m         \u001b[0mqry_pt\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mstate\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgetCoordinate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mview\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m3\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    161\u001b[0m         \u001b[0;31m#distance = torch.min(torch.sum( (self.referenceStreamline_ijk[np.max([self.stepCounter-1-2,0]):np.min([self.stepCounter-1+1,self.maxSteps])] - qry_pt)**2, dim =1 ))\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 162\u001b[0;31m         \u001b[0mdistance\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msum\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreferenceStreamline_ijk\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstepCounter\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m86\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0mqry_pt\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m**\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdim\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    163\u001b[0m         \u001b[0;31m#reward = torch.tanh(-distance+5.3)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    164\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mdistance\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mIndexError\u001b[0m: index 58 is out of bounds for dimension 0 with size 58"
     ]
    }
   ],
   "source": [
    "possible_actions = []\n",
    "past_state = env.reset()\n",
    "all_next_states = []\n",
    "for i in range(len(referenceLine)):\n",
    "    best_actions = []\n",
    "    next_states = []\n",
    "    for z in range(n_actions):\n",
    "        env.state = TractographyState(referenceLine[i], env.interpolateDWIatState)\n",
    "        next_state, reward, _ = env.step(z)\n",
    "        env.stepCounter = i\n",
    "        #if reward == -1:\n",
    "        #    reward = 0\n",
    "        #elif reward < 0.2:\n",
    "        if reward > 1.0:\n",
    "            print(\"Step: \", i, \"Action: \", z, \"Distance: \", reward)\n",
    "        #    reward = 1\n",
    "        #elif reward < 1.:\n",
    "        #    reward = 0\n",
    "        #else:\n",
    "        #    reward = -1\n",
    "        #if reward == 1:\n",
    "        #    best_actions.append(z)\n",
    "            #print(i, z, referenceLine[i].numpy(), next_state.getCoordinate().numpy(), reward)\n",
    "    print(i, best_actions)\n",
    "    #print(i, reward)\n",
    "    #if reward > 0.9:\n",
    "    #    best_actions.append(i)\n",
    "    possible_actions.append(best_actions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "step_distance = []\n",
    "optimal_steps = []#[100, 80, 75, 80, 75, 100, 62, 75, 83, 75, 83, 100, 83, 62, 67, 51, 67, 100, 59, 59, 59, 100, 59, 56, 51, 56, 66, 100, 66, 71, 71, 79, 58, 100, 71, 71, 84, 71, 100, 92, 84, 92, 97, 100, 97, 38, 97, 43, 38, 100, 43, 43, 89, 48]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[80]\n",
      "[80, 88]\n",
      "[80, 88, 54]\n",
      "[80, 88, 54, 96]\n",
      "[80, 88, 54, 96, 100]\n",
      "[80, 88, 54, 96, 100, 67]\n",
      "[80, 88, 54, 96, 100, 67, 83]\n",
      "[80, 88, 54, 96, 100, 67, 83, 75]\n",
      "[80, 88, 54, 96, 100, 67, 83, 75, 83]\n",
      "[80, 88, 54, 96, 100, 67, 83, 75, 83, 75]\n",
      "[80, 88, 54, 96, 100, 67, 83, 75, 83, 75, 100]\n",
      "[80, 88, 54, 96, 100, 67, 83, 75, 83, 75, 100, 83]\n",
      "[80, 88, 54, 96, 100, 67, 83, 75, 83, 75, 100, 83, 70]\n",
      "[80, 88, 54, 96, 100, 67, 83, 75, 83, 75, 100, 83, 70, 67]\n",
      "[80, 88, 54, 96, 100, 67, 83, 75, 83, 75, 100, 83, 70, 67, 59]\n",
      "[80, 88, 54, 96, 100, 67, 83, 75, 83, 75, 100, 83, 70, 67, 59, 100]\n",
      "[80, 88, 54, 96, 100, 67, 83, 75, 83, 75, 100, 83, 70, 67, 59, 100, 67]\n",
      "[80, 88, 54, 96, 100, 67, 83, 75, 83, 75, 100, 83, 70, 67, 59, 100, 67, 59]\n",
      "[80, 88, 54, 96, 100, 67, 83, 75, 83, 75, 100, 83, 70, 67, 59, 100, 67, 59, 59]\n",
      "[80, 88, 54, 96, 100, 67, 83, 75, 83, 75, 100, 83, 70, 67, 59, 100, 67, 59, 59, 59]\n",
      "[80, 88, 54, 96, 100, 67, 83, 75, 83, 75, 100, 83, 70, 67, 59, 100, 67, 59, 59, 59, 51]\n",
      "[80, 88, 54, 96, 100, 67, 83, 75, 83, 75, 100, 83, 70, 67, 59, 100, 67, 59, 59, 59, 51, 100]\n",
      "[80, 88, 54, 96, 100, 67, 83, 75, 83, 75, 100, 83, 70, 67, 59, 100, 67, 59, 59, 59, 51, 100, 59]\n",
      "[80, 88, 54, 96, 100, 67, 83, 75, 83, 75, 100, 83, 70, 67, 59, 100, 67, 59, 59, 59, 51, 100, 59, 56]\n",
      "[80, 88, 54, 96, 100, 67, 83, 75, 83, 75, 100, 83, 70, 67, 59, 100, 67, 59, 59, 59, 51, 100, 59, 56, 51]\n",
      "[80, 88, 54, 96, 100, 67, 83, 75, 83, 75, 100, 83, 70, 67, 59, 100, 67, 59, 59, 59, 51, 100, 59, 56, 51, 61]\n",
      "[80, 88, 54, 96, 100, 67, 83, 75, 83, 75, 100, 83, 70, 67, 59, 100, 67, 59, 59, 59, 51, 100, 59, 56, 51, 61, 100]\n",
      "[80, 88, 54, 96, 100, 67, 83, 75, 83, 75, 100, 83, 70, 67, 59, 100, 67, 59, 59, 59, 51, 100, 59, 56, 51, 61, 100, 66]\n",
      "[80, 88, 54, 96, 100, 67, 83, 75, 83, 75, 100, 83, 70, 67, 59, 100, 67, 59, 59, 59, 51, 100, 59, 56, 51, 61, 100, 66, 71]\n",
      "[80, 88, 54, 96, 100, 67, 83, 75, 83, 75, 100, 83, 70, 67, 59, 100, 67, 59, 59, 59, 51, 100, 59, 56, 51, 61, 100, 66, 71, 66]\n",
      "[80, 88, 54, 96, 100, 67, 83, 75, 83, 75, 100, 83, 70, 67, 59, 100, 67, 59, 59, 59, 51, 100, 59, 56, 51, 61, 100, 66, 71, 66, 71]\n",
      "[80, 88, 54, 96, 100, 67, 83, 75, 83, 75, 100, 83, 70, 67, 59, 100, 67, 59, 59, 59, 51, 100, 59, 56, 51, 61, 100, 66, 71, 66, 71, 71]\n",
      "[80, 88, 54, 96, 100, 67, 83, 75, 83, 75, 100, 83, 70, 67, 59, 100, 67, 59, 59, 59, 51, 100, 59, 56, 51, 61, 100, 66, 71, 66, 71, 71, 100]\n",
      "[80, 88, 54, 96, 100, 67, 83, 75, 83, 75, 100, 83, 70, 67, 59, 100, 67, 59, 59, 59, 51, 100, 59, 56, 51, 61, 100, 66, 71, 66, 71, 71, 100, 71]\n",
      "[80, 88, 54, 96, 100, 67, 83, 75, 83, 75, 100, 83, 70, 67, 59, 100, 67, 59, 59, 59, 51, 100, 59, 56, 51, 61, 100, 66, 71, 66, 71, 71, 100, 71, 71]\n",
      "[80, 88, 54, 96, 100, 67, 83, 75, 83, 75, 100, 83, 70, 67, 59, 100, 67, 59, 59, 59, 51, 100, 59, 56, 51, 61, 100, 66, 71, 66, 71, 71, 100, 71, 71, 71]\n",
      "[80, 88, 54, 96, 100, 67, 83, 75, 83, 75, 100, 83, 70, 67, 59, 100, 67, 59, 59, 59, 51, 100, 59, 56, 51, 61, 100, 66, 71, 66, 71, 71, 100, 71, 71, 71, 71]\n",
      "[80, 88, 54, 96, 100, 67, 83, 75, 83, 75, 100, 83, 70, 67, 59, 100, 67, 59, 59, 59, 51, 100, 59, 56, 51, 61, 100, 66, 71, 66, 71, 71, 100, 71, 71, 71, 71, 100]\n",
      "[80, 88, 54, 96, 100, 67, 83, 75, 83, 75, 100, 83, 70, 67, 59, 100, 67, 59, 59, 59, 51, 100, 59, 56, 51, 61, 100, 66, 71, 66, 71, 71, 100, 71, 71, 71, 71, 100, 92]\n",
      "[80, 88, 54, 96, 100, 67, 83, 75, 83, 75, 100, 83, 70, 67, 59, 100, 67, 59, 59, 59, 51, 100, 59, 56, 51, 61, 100, 66, 71, 66, 71, 71, 100, 71, 71, 71, 71, 100, 92, 84]\n",
      "[80, 88, 54, 96, 100, 67, 83, 75, 83, 75, 100, 83, 70, 67, 59, 100, 67, 59, 59, 59, 51, 100, 59, 56, 51, 61, 100, 66, 71, 66, 71, 71, 100, 71, 71, 71, 71, 100, 92, 84, 84]\n",
      "[80, 88, 54, 96, 100, 67, 83, 75, 83, 75, 100, 83, 70, 67, 59, 100, 67, 59, 59, 59, 51, 100, 59, 56, 51, 61, 100, 66, 71, 66, 71, 71, 100, 71, 71, 71, 71, 100, 92, 84, 84, 38]\n",
      "[80, 88, 54, 96, 100, 67, 83, 75, 83, 75, 100, 83, 70, 67, 59, 100, 67, 59, 59, 59, 51, 100, 59, 56, 51, 61, 100, 66, 71, 66, 71, 71, 100, 71, 71, 71, 71, 100, 92, 84, 84, 38, 100]\n",
      "[80, 88, 54, 96, 100, 67, 83, 75, 83, 75, 100, 83, 70, 67, 59, 100, 67, 59, 59, 59, 51, 100, 59, 56, 51, 61, 100, 66, 71, 66, 71, 71, 100, 71, 71, 71, 71, 100, 92, 84, 84, 38, 100, 97]\n",
      "[80, 88, 54, 96, 100, 67, 83, 75, 83, 75, 100, 83, 70, 67, 59, 100, 67, 59, 59, 59, 51, 100, 59, 56, 51, 61, 100, 66, 71, 66, 71, 71, 100, 71, 71, 71, 71, 100, 92, 84, 84, 38, 100, 97, 97]\n",
      "[80, 88, 54, 96, 100, 67, 83, 75, 83, 75, 100, 83, 70, 67, 59, 100, 67, 59, 59, 59, 51, 100, 59, 56, 51, 61, 100, 66, 71, 66, 71, 71, 100, 71, 71, 71, 71, 100, 92, 84, 84, 38, 100, 97, 97, 97]\n",
      "[80, 88, 54, 96, 100, 67, 83, 75, 83, 75, 100, 83, 70, 67, 59, 100, 67, 59, 59, 59, 51, 100, 59, 56, 51, 61, 100, 66, 71, 66, 71, 71, 100, 71, 71, 71, 71, 100, 92, 84, 84, 38, 100, 97, 97, 97, 38]\n",
      "[80, 88, 54, 96, 100, 67, 83, 75, 83, 75, 100, 83, 70, 67, 59, 100, 67, 59, 59, 59, 51, 100, 59, 56, 51, 61, 100, 66, 71, 66, 71, 71, 100, 71, 71, 71, 71, 100, 92, 84, 84, 38, 100, 97, 97, 97, 38, 100]\n",
      "[80, 88, 54, 96, 100, 67, 83, 75, 83, 75, 100, 83, 70, 67, 59, 100, 67, 59, 59, 59, 51, 100, 59, 56, 51, 61, 100, 66, 71, 66, 71, 71, 100, 71, 71, 71, 71, 100, 92, 84, 84, 38, 100, 97, 97, 97, 38, 100, 97]\n",
      "[80, 88, 54, 96, 100, 67, 83, 75, 83, 75, 100, 83, 70, 67, 59, 100, 67, 59, 59, 59, 51, 100, 59, 56, 51, 61, 100, 66, 71, 66, 71, 71, 100, 71, 71, 71, 71, 100, 92, 84, 84, 38, 100, 97, 97, 97, 38, 100, 97, 30]\n",
      "[80, 88, 54, 96, 100, 67, 83, 75, 83, 75, 100, 83, 70, 67, 59, 100, 67, 59, 59, 59, 51, 100, 59, 56, 51, 61, 100, 66, 71, 66, 71, 71, 100, 71, 71, 71, 71, 100, 92, 84, 84, 38, 100, 97, 97, 97, 38, 100, 97, 30, 43]\n",
      "[80, 88, 54, 96, 100, 67, 83, 75, 83, 75, 100, 83, 70, 67, 59, 100, 67, 59, 59, 59, 51, 100, 59, 56, 51, 61, 100, 66, 71, 66, 71, 71, 100, 71, 71, 71, 71, 100, 92, 84, 84, 38, 100, 97, 97, 97, 38, 100, 97, 30, 43, 43]\n",
      "[80, 88, 54, 96, 100, 67, 83, 75, 83, 75, 100, 83, 70, 67, 59, 100, 67, 59, 59, 59, 51, 100, 59, 56, 51, 61, 100, 66, 71, 66, 71, 71, 100, 71, 71, 71, 71, 100, 92, 84, 84, 38, 100, 97, 97, 97, 38, 100, 97, 30, 43, 43, 48]\n",
      "[80, 88, 54, 96, 100, 67, 83, 75, 83, 75, 100, 83, 70, 67, 59, 100, 67, 59, 59, 59, 51, 100, 59, 56, 51, 61, 100, 66, 71, 66, 71, 71, 100, 71, 71, 71, 71, 100, 92, 84, 84, 38, 100, 97, 97, 97, 38, 100, 97, 30, 43, 43, 48, 100]\n",
      "[80, 88, 54, 96, 100, 67, 83, 75, 83, 75, 100, 83, 70, 67, 59, 100, 67, 59, 59, 59, 51, 100, 59, 56, 51, 61, 100, 66, 71, 66, 71, 71, 100, 71, 71, 71, 71, 100, 92, 84, 84, 38, 100, 97, 97, 97, 38, 100, 97, 30, 43, 43, 48, 100, 94]\n",
      "[80, 88, 54, 96, 100, 67, 83, 75, 83, 75, 100, 83, 70, 67, 59, 100, 67, 59, 59, 59, 51, 100, 59, 56, 51, 61, 100, 66, 71, 66, 71, 71, 100, 71, 71, 71, 71, 100, 92, 84, 84, 38, 100, 97, 97, 97, 38, 100, 97, 30, 43, 43, 48, 100, 94, 81]\n",
      "[80, 88, 54, 96, 100, 67, 83, 75, 83, 75, 100, 83, 70, 67, 59, 100, 67, 59, 59, 59, 51, 100, 59, 56, 51, 61, 100, 66, 71, 66, 71, 71, 100, 71, 71, 71, 71, 100, 92, 84, 84, 38, 100, 97, 97, 97, 38, 100, 97, 30, 43, 43, 48, 100, 94, 81, 94]\n",
      "[80, 88, 54, 96, 100, 67, 83, 75, 83, 75, 100, 83, 70, 67, 59, 100, 67, 59, 59, 59, 51, 100, 59, 56, 51, 61, 100, 66, 71, 66, 71, 71, 100, 71, 71, 71, 71, 100, 92, 84, 84, 38, 100, 97, 97, 97, 38, 100, 97, 30, 43, 43, 48, 100, 94, 81, 94, 35]\n",
      "[80, 88, 54, 96, 100, 67, 83, 75, 83, 75, 100, 83, 70, 67, 59, 100, 67, 59, 59, 59, 51, 100, 59, 56, 51, 61, 100, 66, 71, 66, 71, 71, 100, 71, 71, 71, 71, 100, 92, 84, 84, 38, 100, 97, 97, 97, 38, 100, 97, 30, 43, 43, 48, 100, 94, 81, 94, 35, 97]\n",
      "[80, 88, 54, 96, 100, 67, 83, 75, 83, 75, 100, 83, 70, 67, 59, 100, 67, 59, 59, 59, 51, 100, 59, 56, 51, 61, 100, 66, 71, 66, 71, 71, 100, 71, 71, 71, 71, 100, 92, 84, 84, 38, 100, 97, 97, 97, 38, 100, 97, 30, 43, 43, 48, 100, 94, 81, 94, 35, 97, 100]\n",
      "[80, 88, 54, 96, 100, 67, 83, 75, 83, 75, 100, 83, 70, 67, 59, 100, 67, 59, 59, 59, 51, 100, 59, 56, 51, 61, 100, 66, 71, 66, 71, 71, 100, 71, 71, 71, 71, 100, 92, 84, 84, 38, 100, 97, 97, 97, 38, 100, 97, 30, 43, 43, 48, 100, 94, 81, 94, 35, 97, 100, 35]\n",
      "[80, 88, 54, 96, 100, 67, 83, 75, 83, 75, 100, 83, 70, 67, 59, 100, 67, 59, 59, 59, 51, 100, 59, 56, 51, 61, 100, 66, 71, 66, 71, 71, 100, 71, 71, 71, 71, 100, 92, 84, 84, 38, 100, 97, 97, 97, 38, 100, 97, 30, 43, 43, 48, 100, 94, 81, 94, 35, 97, 100, 35, 22]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[80, 88, 54, 96, 100, 67, 83, 75, 83, 75, 100, 83, 70, 67, 59, 100, 67, 59, 59, 59, 51, 100, 59, 56, 51, 61, 100, 66, 71, 66, 71, 71, 100, 71, 71, 71, 71, 100, 92, 84, 84, 38, 100, 97, 97, 97, 38, 100, 97, 30, 43, 43, 48, 100, 94, 81, 94, 35, 97, 100, 35, 22, 35]\n",
      "[80, 88, 54, 96, 100, 67, 83, 75, 83, 75, 100, 83, 70, 67, 59, 100, 67, 59, 59, 59, 51, 100, 59, 56, 51, 61, 100, 66, 71, 66, 71, 71, 100, 71, 71, 71, 71, 100, 92, 84, 84, 38, 100, 97, 97, 97, 38, 100, 97, 30, 43, 43, 48, 100, 94, 81, 94, 35, 97, 100, 35, 22, 35, 35]\n",
      "[80, 88, 54, 96, 100, 67, 83, 75, 83, 75, 100, 83, 70, 67, 59, 100, 67, 59, 59, 59, 51, 100, 59, 56, 51, 61, 100, 66, 71, 66, 71, 71, 100, 71, 71, 71, 71, 100, 92, 84, 84, 38, 100, 97, 97, 97, 38, 100, 97, 30, 43, 43, 48, 100, 94, 81, 94, 35, 97, 100, 35, 22, 35, 35, 6]\n",
      "[80, 88, 54, 96, 100, 67, 83, 75, 83, 75, 100, 83, 70, 67, 59, 100, 67, 59, 59, 59, 51, 100, 59, 56, 51, 61, 100, 66, 71, 66, 71, 71, 100, 71, 71, 71, 71, 100, 92, 84, 84, 38, 100, 97, 97, 97, 38, 100, 97, 30, 43, 43, 48, 100, 94, 81, 94, 35, 97, 100, 35, 22, 35, 35, 6, 100]\n",
      "[80, 88, 54, 96, 100, 67, 83, 75, 83, 75, 100, 83, 70, 67, 59, 100, 67, 59, 59, 59, 51, 100, 59, 56, 51, 61, 100, 66, 71, 66, 71, 71, 100, 71, 71, 71, 71, 100, 92, 84, 84, 38, 100, 97, 97, 97, 38, 100, 97, 30, 43, 43, 48, 100, 94, 81, 94, 35, 97, 100, 35, 22, 35, 35, 6, 100, 19]\n",
      "[80, 88, 54, 96, 100, 67, 83, 75, 83, 75, 100, 83, 70, 67, 59, 100, 67, 59, 59, 59, 51, 100, 59, 56, 51, 61, 100, 66, 71, 66, 71, 71, 100, 71, 71, 71, 71, 100, 92, 84, 84, 38, 100, 97, 97, 97, 38, 100, 97, 30, 43, 43, 48, 100, 94, 81, 94, 35, 97, 100, 35, 22, 35, 35, 6, 100, 19, 3]\n",
      "[80, 88, 54, 96, 100, 67, 83, 75, 83, 75, 100, 83, 70, 67, 59, 100, 67, 59, 59, 59, 51, 100, 59, 56, 51, 61, 100, 66, 71, 66, 71, 71, 100, 71, 71, 71, 71, 100, 92, 84, 84, 38, 100, 97, 97, 97, 38, 100, 97, 30, 43, 43, 48, 100, 94, 81, 94, 35, 97, 100, 35, 22, 35, 35, 6, 100, 19, 3, 16]\n",
      "[80, 88, 54, 96, 100, 67, 83, 75, 83, 75, 100, 83, 70, 67, 59, 100, 67, 59, 59, 59, 51, 100, 59, 56, 51, 61, 100, 66, 71, 66, 71, 71, 100, 71, 71, 71, 71, 100, 92, 84, 84, 38, 100, 97, 97, 97, 38, 100, 97, 30, 43, 43, 48, 100, 94, 81, 94, 35, 97, 100, 35, 22, 35, 35, 6, 100, 19, 3, 16, 3]\n",
      "[80, 88, 54, 96, 100, 67, 83, 75, 83, 75, 100, 83, 70, 67, 59, 100, 67, 59, 59, 59, 51, 100, 59, 56, 51, 61, 100, 66, 71, 66, 71, 71, 100, 71, 71, 71, 71, 100, 92, 84, 84, 38, 100, 97, 97, 97, 38, 100, 97, 30, 43, 43, 48, 100, 94, 81, 94, 35, 97, 100, 35, 22, 35, 35, 6, 100, 19, 3, 16, 3, 21]\n",
      "[80, 88, 54, 96, 100, 67, 83, 75, 83, 75, 100, 83, 70, 67, 59, 100, 67, 59, 59, 59, 51, 100, 59, 56, 51, 61, 100, 66, 71, 66, 71, 71, 100, 71, 71, 71, 71, 100, 92, 84, 84, 38, 100, 97, 97, 97, 38, 100, 97, 30, 43, 43, 48, 100, 94, 81, 94, 35, 97, 100, 35, 22, 35, 35, 6, 100, 19, 3, 16, 3, 21, 100]\n",
      "[80, 88, 54, 96, 100, 67, 83, 75, 83, 75, 100, 83, 70, 67, 59, 100, 67, 59, 59, 59, 51, 100, 59, 56, 51, 61, 100, 66, 71, 66, 71, 71, 100, 71, 71, 71, 71, 100, 92, 84, 84, 38, 100, 97, 97, 97, 38, 100, 97, 30, 43, 43, 48, 100, 94, 81, 94, 35, 97, 100, 35, 22, 35, 35, 6, 100, 19, 3, 16, 3, 21, 100, 21]\n",
      "[80, 88, 54, 96, 100, 67, 83, 75, 83, 75, 100, 83, 70, 67, 59, 100, 67, 59, 59, 59, 51, 100, 59, 56, 51, 61, 100, 66, 71, 66, 71, 71, 100, 71, 71, 71, 71, 100, 92, 84, 84, 38, 100, 97, 97, 97, 38, 100, 97, 30, 43, 43, 48, 100, 94, 81, 94, 35, 97, 100, 35, 22, 35, 35, 6, 100, 19, 3, 16, 3, 21, 100, 21, 16]\n",
      "[80, 88, 54, 96, 100, 67, 83, 75, 83, 75, 100, 83, 70, 67, 59, 100, 67, 59, 59, 59, 51, 100, 59, 56, 51, 61, 100, 66, 71, 66, 71, 71, 100, 71, 71, 71, 71, 100, 92, 84, 84, 38, 100, 97, 97, 97, 38, 100, 97, 30, 43, 43, 48, 100, 94, 81, 94, 35, 97, 100, 35, 22, 35, 35, 6, 100, 19, 3, 16, 3, 21, 100, 21, 16, 34]\n",
      "[80, 88, 54, 96, 100, 67, 83, 75, 83, 75, 100, 83, 70, 67, 59, 100, 67, 59, 59, 59, 51, 100, 59, 56, 51, 61, 100, 66, 71, 66, 71, 71, 100, 71, 71, 71, 71, 100, 92, 84, 84, 38, 100, 97, 97, 97, 38, 100, 97, 30, 43, 43, 48, 100, 94, 81, 94, 35, 97, 100, 35, 22, 35, 35, 6, 100, 19, 3, 16, 3, 21, 100, 21, 16, 34, 21]\n",
      "[80, 88, 54, 96, 100, 67, 83, 75, 83, 75, 100, 83, 70, 67, 59, 100, 67, 59, 59, 59, 51, 100, 59, 56, 51, 61, 100, 66, 71, 66, 71, 71, 100, 71, 71, 71, 71, 100, 92, 84, 84, 38, 100, 97, 97, 97, 38, 100, 97, 30, 43, 43, 48, 100, 94, 81, 94, 35, 97, 100, 35, 22, 35, 35, 6, 100, 19, 3, 16, 3, 21, 100, 21, 16, 34, 21, 98]\n",
      "[80, 88, 54, 96, 100, 67, 83, 75, 83, 75, 100, 83, 70, 67, 59, 100, 67, 59, 59, 59, 51, 100, 59, 56, 51, 61, 100, 66, 71, 66, 71, 71, 100, 71, 71, 71, 71, 100, 92, 84, 84, 38, 100, 97, 97, 97, 38, 100, 97, 30, 43, 43, 48, 100, 94, 81, 94, 35, 97, 100, 35, 22, 35, 35, 6, 100, 19, 3, 16, 3, 21, 100, 21, 16, 34, 21, 98, 34]\n",
      "[80, 88, 54, 96, 100, 67, 83, 75, 83, 75, 100, 83, 70, 67, 59, 100, 67, 59, 59, 59, 51, 100, 59, 56, 51, 61, 100, 66, 71, 66, 71, 71, 100, 71, 71, 71, 71, 100, 92, 84, 84, 38, 100, 97, 97, 97, 38, 100, 97, 30, 43, 43, 48, 100, 94, 81, 94, 35, 97, 100, 35, 22, 35, 35, 6, 100, 19, 3, 16, 3, 21, 100, 21, 16, 34, 21, 98, 34, 100]\n",
      "[80, 88, 54, 96, 100, 67, 83, 75, 83, 75, 100, 83, 70, 67, 59, 100, 67, 59, 59, 59, 51, 100, 59, 56, 51, 61, 100, 66, 71, 66, 71, 71, 100, 71, 71, 71, 71, 100, 92, 84, 84, 38, 100, 97, 97, 97, 38, 100, 97, 30, 43, 43, 48, 100, 94, 81, 94, 35, 97, 100, 35, 22, 35, 35, 6, 100, 19, 3, 16, 3, 21, 100, 21, 16, 34, 21, 98, 34, 100, 39]\n",
      "[80, 88, 54, 96, 100, 67, 83, 75, 83, 75, 100, 83, 70, 67, 59, 100, 67, 59, 59, 59, 51, 100, 59, 56, 51, 61, 100, 66, 71, 66, 71, 71, 100, 71, 71, 71, 71, 100, 92, 84, 84, 38, 100, 97, 97, 97, 38, 100, 97, 30, 43, 43, 48, 100, 94, 81, 94, 35, 97, 100, 35, 22, 35, 35, 6, 100, 19, 3, 16, 3, 21, 100, 21, 16, 34, 21, 98, 34, 100, 39, 93]\n",
      "[80, 88, 54, 96, 100, 67, 83, 75, 83, 75, 100, 83, 70, 67, 59, 100, 67, 59, 59, 59, 51, 100, 59, 56, 51, 61, 100, 66, 71, 66, 71, 71, 100, 71, 71, 71, 71, 100, 92, 84, 84, 38, 100, 97, 97, 97, 38, 100, 97, 30, 43, 43, 48, 100, 94, 81, 94, 35, 97, 100, 35, 22, 35, 35, 6, 100, 19, 3, 16, 3, 21, 100, 21, 16, 34, 21, 98, 34, 100, 39, 93, 39]\n",
      "[80, 88, 54, 96, 100, 67, 83, 75, 83, 75, 100, 83, 70, 67, 59, 100, 67, 59, 59, 59, 51, 100, 59, 56, 51, 61, 100, 66, 71, 66, 71, 71, 100, 71, 71, 71, 71, 100, 92, 84, 84, 38, 100, 97, 97, 97, 38, 100, 97, 30, 43, 43, 48, 100, 94, 81, 94, 35, 97, 100, 35, 22, 35, 35, 6, 100, 19, 3, 16, 3, 21, 100, 21, 16, 34, 21, 98, 34, 100, 39, 93, 39, 72]\n",
      "[80, 88, 54, 96, 100, 67, 83, 75, 83, 75, 100, 83, 70, 67, 59, 100, 67, 59, 59, 59, 51, 100, 59, 56, 51, 61, 100, 66, 71, 66, 71, 71, 100, 71, 71, 71, 71, 100, 92, 84, 84, 38, 100, 97, 97, 97, 38, 100, 97, 30, 43, 43, 48, 100, 94, 81, 94, 35, 97, 100, 35, 22, 35, 35, 6, 100, 19, 3, 16, 3, 21, 100, 21, 16, 34, 21, 98, 34, 100, 39, 93, 39, 72, 72]\n",
      "[80, 88, 54, 96, 100, 67, 83, 75, 83, 75, 100, 83, 70, 67, 59, 100, 67, 59, 59, 59, 51, 100, 59, 56, 51, 61, 100, 66, 71, 66, 71, 71, 100, 71, 71, 71, 71, 100, 92, 84, 84, 38, 100, 97, 97, 97, 38, 100, 97, 30, 43, 43, 48, 100, 94, 81, 94, 35, 97, 100, 35, 22, 35, 35, 6, 100, 19, 3, 16, 3, 21, 100, 21, 16, 34, 21, 98, 34, 100, 39, 93, 39, 72, 72, 100]\n"
     ]
    }
   ],
   "source": [
    "steps = 0\n",
    "while len(optimal_steps) < 87:\n",
    "    step_distance = []\n",
    "    for i in range(n_actions):\n",
    "        env.reset()\n",
    "        if len(optimal_steps)>0:\n",
    "            for z in range(len(optimal_steps)):\n",
    "                _,_,_ = env.step(optimal_steps[z])\n",
    "        next_state, _, terminal = env.step(i)\n",
    "        #distance = lineseg_dist(next_state.getCoordinate().numpy(), referenceLine[np.min([len(optimal_steps), 85])].numpy(), referenceLine[np.min([len(optimal_steps)+1, len(referenceLine)-1])].numpy())\n",
    "        distance = ((next_state.getCoordinate()[0] - env.referenceStreamline_ijk[np.min([env.stepCounter, 86])][0])**2 \\\n",
    "                      + (next_state.getCoordinate()[1] - env.referenceStreamline_ijk[np.min([env.stepCounter, 86])][1])**2 \\\n",
    "                      + (next_state.getCoordinate()[2] - env.referenceStreamline_ijk[np.min([env.stepCounter, 86])][2])**2)\n",
    "        step_distance.append(distance)\n",
    "    optimal_steps.append(np.argmin(step_distance))\n",
    "    print(optimal_steps)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# with line distance\n",
    "#optimal_steps = [80, 88, 54, 96, 46, 75, 75, 75, 83, 75, 83, 83, 62, 54, 1, 59, 54, 59, 59, 67, 56, 59, 51, 59, 61, 11, 53, 61, 66, 71, 71, 79, 58, 71, 71, 71, 21, 71, 84, 92, 84, 92, 97, 84, 43, 84, 30, 97, 47, 97, 43, 30, 89, 35, 94, 73, 48, 89, 22, 72, 43, 35, 22, 35, 35, 6, 19, 3, 16, 16, 66, 16, 8, 21, 29, 21, 26, 26, 93, 26, 93, 85, 35, 85, 72, 77, 100]\n",
    "optimal_steps = [100, 80, 75, 80, 75, 100, 62, 75, 83, 75, 83, 100, 83, 62, 67, 51, 67, 100, 59, 59, 59, 100, 59, 56, 51, 56, 66, 100, 66, 71, 71, 79, 58, 100, 71, 71, 84, 71, 100, 92, 84, 92, 97, 100, 97, 38, 97, 43, 38, 100, 43, 43, 89, 48, 100, 94, 81, 48, 43, 100, 35, 43, 35, 22, 27, 100, 6, 11, 3, 16, 100, 8, 29, 21, 21, 100, 34, 26, 26, 93, 39, 100, 93, 72, 77, 77, 101]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#optimal_steps = [80, 75, 80, 75, 62, 75, 83, 96, 51, 24, 62, 62, 62, 77, 65, 64, 67, 59, 56, 83, 82, 54, 56, 53, 56, 38, 56, 84, 66, 71, 71, 64, 97, 84, 71, 71, 38, 51, 30, 92, 97, 84, 43, 79, 27, 46, 89, 25, 81, 25, 48, 43, 86, 48, 57, 14, 89, 43, 43, 19, 92, 14, 27, 9, 78, 4, 16, 3, 29, 3, 47, 6, 42, 21, 39, 5, 72, 34, 98, 88, 90, 75, 77, 59, 49, 32, 82]\n",
    "print(optimal_steps) # <-- min of max distance reward streamline 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[80, 75, 80, 75, 62, 75, 83, 96, 51, 24, 62, 62, 62, 77, 65, 64, 67, 59, 56, 83, 82, 54, 56, 53, 56, 38, 56, 84, 66, 71, 71, 64, 97, 84, 71, 71, 38, 51, 30, 92, 97, 84, 43, 79, 27, 46, 89, 25, 81, 25, 48, 43, 86, 48, 57, 14, 89, 43, 43, 19, 92, 14, 27, 9, 78, 4, 16, 3, 29, 3, 47, 6, 42, 21, 39, 5, 72, 34, 98, 88, 90, 75, 77, 59, 49, 32, 82]\n"
     ]
    }
   ],
   "source": [
    "optimal_steps = [80, 75, 80, 75, 62, 75, 83, 96, 51, 24, 62, 62, 62, 77, 65, 64, 67, 59, 56, 83, 82, 54, 56, 53, 56, 38, 56, 84, 66, 71, 71, 64, 97, 84, 71, 71, 38, 51, 30, 92, 97, 84, 43, 79, 27, 46, 89, 25, 81, 25, 48, 43, 86, 48, 57, 14, 89, 43, 43, 19, 92, 14, 27, 9, 78, 4, 16, 3, 29, 3, 47, 6, 42, 21, 39, 5, 72, 34, 98, 88, 90, 75, 77, 59, 49, 32, 82]\n",
    "print(optimal_steps) # <-- min of max distance reward streamline 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[80, 88, 54, 96, 59, 37, 54, 37, 67, 91, 62, 78, 64, 70, 64, 62, 69, 83, 56, 59, 59, 53, 42, 53, 53, 56, 79, 58, 87, 60, 87, 58, 92, 52, 46, 58, 38, 58, 30, 58, 38, 84, 17, 55, 30, 76, 25, 76, 17, 76, 17, 81, 30, 86, 48, 65, 27, 97, 14, 84, 6, 97, 14, 89, 3, 27, 8, 19, 13, 19, 13, 29, 8, 96, 2, 88, 31, 47, 26, 59, 5, 72, 72, 85, 61, 39]\n"
     ]
    }
   ],
   "source": [
    "optimal_steps = [80, 88, 54, 96, 59, 37, 54, 37, 67, 91, 62, 78, 64, 70, 64, 62, 69, 83, 56, 59, 59, 53, 42, 53, 53, 56, 79, 58, 87, 60, 87, 58, 92, 52, 46, 58, 38, 58, 30, 58, 38, 84, 17, 55, 30, 76, 25, 76, 17, 76, 17, 81, 30, 86, 48, 65, 27, 97, 14, 84, 6, 97, 14, 89, 3, 27, 8, 19, 13, 19, 13, 29, 8, 96, 2, 88, 31, 47, 26, 59, 5, 72, 72, 85, 61, 39]\n",
    "print(optimal_steps) # <-- min reward"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 73.651344 107.88106   93.29415 ] tensor([ 73.6513, 107.8811,  93.2942])\n",
      "1 100 [ 73.651344 107.88106   93.29415 ] [ 74.42344 107.87124  93.08491] 0.6400096416473389\n",
      "2 80 [ 74.56195007 107.80595503  92.88775652] [ 75.16057  107.88882   92.774536] 0.3780286503520091\n",
      "3 75 [ 75.41803172 108.0619337   92.43875862] [ 75.78847 107.96255  92.28433] 0.17094774926353554\n",
      "4 80 [ 76.32863749 107.98683099  92.03236383] [ 76.45265  108.118454  91.86654 ] 0.06020208127816557\n",
      "5 75 [ 77.18471914 108.24280966  91.58336593] [ 77.116844 108.27435   91.448746] 0.023724592605490286\n",
      "6 100 [ 77.18471914 108.24280966  91.58336593] [ 77.739716 108.54131   91.02359 ] 0.710474378826848\n",
      "7 62 [ 77.77475787 108.59960994  90.85910916] [ 78.36259  108.80828   90.598434] 0.45703795478407117\n",
      "8 75 [ 78.63083952 108.85558861  90.41011125] [ 78.996666 109.15176   90.25207 ] 0.24652207806655307\n",
      "9 83 [ 79.32479042 109.42531442  89.96983334] [ 79.630745 109.495224  89.9057  ] 0.10260850870725366\n",
      "10 75 [ 80.18087208 109.6812931   89.52083543] [ 80.264824 109.8387    89.55933 ] 0.03330676084319823\n",
      "11 83 [ 80.87482298 110.25101891  89.08055751] [ 80.833374 110.28288   89.21371 ] 0.020462094952490108\n",
      "12 100 [ 80.87482298 110.25101891  89.08055751] [ 81.32385 110.75597  88.79464] 0.5383483563755606\n",
      "13 83 [ 81.56877388 110.82074472  88.64027959] [ 81.78852 111.07612  88.22755] 0.2838529125189824\n",
      "14 62 [ 82.15881261 111.177545    87.91602283] [ 82.26274  111.20639   87.596565] 0.11368633104589762\n",
      "15 67 [ 82.85555098 111.17999831  87.19870169] [ 82.764885 111.12094   86.97968 ] 0.059677296257879014\n",
      "16 51 [ 82.99346983 111.01769537  86.22164685] [ 83.17989 111.072    86.2975 ] 0.04345641443134025\n",
      "17 67 [ 83.69020821 111.02014868  85.50432572] [ 83.60093  110.91725   85.635086] 0.03565681069712101\n",
      "18 100 [ 83.69020821 111.02014868  85.50432572] [ 84.02196  110.762505  84.97268 ] 0.45908609427724045\n",
      "19 59 [ 84.15174358 110.7504595   84.65919091] [ 84.442986 110.60775   84.310265] 0.22693747190850422\n",
      "20 59 [ 84.61327895 110.48077032  83.8140561 ] [ 84.77493 110.3935   83.61463] 0.0735179803634374\n",
      "21 59 [ 85.07481433 110.21108113  82.96892129] [ 85.10689 110.17926  82.919  ] 0.004533540445638102\n",
      "22 100 [ 85.07481433 110.21108113  82.96892129] [ 85.345314 109.90936   82.20464 ] 0.7483249699804035\n",
      "23 59 [ 85.5363497  109.94139195  82.12378649] [ 85.58373  109.639465  81.49028 ] 0.4947350953188132\n",
      "24 56 [ 85.68688147 109.41814457  81.2850062 ] [ 85.82216  109.36957   80.775925] 0.2798236466913696\n",
      "25 51 [ 85.82480032 109.25584162  80.30795137] [ 85.85974 109.05764  80.0402 ] 0.11219589997336457\n",
      "26 56 [ 85.97533209 108.73259424  79.46917108] [ 85.799995 108.701836  79.32617 ] 0.0521378127060811\n",
      "27 66 [ 85.4841044  108.27891335  78.72561947] [ 85.42547  108.338684  78.719666] 0.00704616465329052\n",
      "28 100 [ 85.4841044  108.27891335  78.72561947] [ 84.95774 108.01203  78.15884] 0.6695276347529395\n",
      "29 66 [ 84.9928767  107.82523246  77.98206786] [ 84.405464 107.72696   77.65513 ] 0.46160046622737183\n",
      "30 71 [ 84.20507585 107.68643679  77.38197988] [ 83.82796 107.54751  77.13141] 0.22430557514753416\n",
      "31 71 [ 83.41727501 107.54764112  76.7818919 ] [ 83.25045  107.368065  76.60768 ] 0.0904275034548661\n",
      "32 79 [ 82.67787905 107.08639476  76.29143761] [ 82.67294  107.188614  76.08396 ] 0.05351945418577419\n",
      "33 58 [ 82.14762279 106.98016365  75.4502817 ] [ 82.095436 107.00916   75.56024 ] 0.015655608145770657\n",
      "34 100 [ 82.14762279 106.98016365  75.4502817 ] [ 81.50589 106.93699  75.02431] 0.5951394071788632\n",
      "35 71 [ 81.35982194 106.84136798  74.85019372] [ 80.85792  106.808914  74.572945] 0.32982808069245473\n",
      "36 71 [ 80.57202109 106.70257231  74.25010574] [ 80.209946 106.68083   74.12158 ] 0.14808959267637958\n",
      "37 84 [ 79.64286259 106.7821063   73.88908104] [ 79.50499  106.61171   73.749756] 0.0674555011205624\n",
      "38 71 [ 78.85506175 106.64331063  73.28899306] [ 78.80003  106.542595  73.37792 ] 0.021080123710391994\n",
      "39 100 [ 78.85506175 106.64331063  73.28899306] [ 78.05818  106.425224  73.10245 ] 0.7173785970618475\n",
      "40 92 [ 77.91714171 106.38118628  73.06184371] [ 77.31185 106.41967  72.81442] 0.4290744423594821\n",
      "41 84 [ 76.98798321 106.46072027  72.70081901] [ 76.53611 106.36668  72.62622] 0.21859863969870647\n",
      "42 92 [ 76.05006318 106.19859591  72.47366965] [ 75.74241  106.37777   72.526665] 0.12956288919041983\n",
      "43 97 [ 75.0946025  106.47948536  72.38313789] [ 74.96043  106.500565  72.4108  ] 0.019212609448132734\n",
      "44 100 [ 75.0946025  106.47948536  72.38313789] [ 74.178444 106.62336   72.29493 ] 0.8678270960303209\n",
      "45 97 [ 74.13914181 106.76037481  72.29260613] [ 73.40041  106.807594  72.267815] 0.5485637972970705\n",
      "46 38 [ 73.14271799 106.71439884  72.36349885] [ 72.62239 106.99183  72.24071] 0.36278562793148295\n",
      "47 97 [ 72.18725731 106.99528829  72.27296709] [ 71.83936  107.132996  72.32399 ] 0.14259700773405432\n",
      "48 43 [ 71.29116809 107.37093919  72.50942112] [ 71.056335 107.27416   72.40728 ] 0.07494495120045643\n",
      "49 38 [ 70.29474426 107.32496323  72.58031385] [ 70.2733  107.41533  72.49056] 0.016681132856630837\n",
      "50 100 [ 70.29474426 107.32496323  72.58031385] [ 69.52366 107.6402   72.65629] 0.6997177647653564\n",
      "51 43 [ 69.39865504 107.70061413  72.81676788] [ 68.77401 107.86507  72.82201] 0.4172538297596965\n",
      "52 43 [ 68.50256582 108.07626504  73.05322191] [ 68.10658 108.26655  73.00465] 0.19536993510372735\n",
      "53 89 [ 67.71856673 108.6951139   73.00452381] [ 67.49615 108.77019  73.12171] 0.06883950355591151\n",
      "54 48 [ 67.20429422 109.55213172  73.03683869] [ 67.14327 109.48129  73.02263] 0.008943746523217293\n",
      "55 100 [ 67.20429422 109.55213172  73.03683869] [ 66.87607  110.213646  72.84302 ] 0.582900061739134\n",
      "56 94 [ 66.96063926 110.50266183  72.84416081] [ 66.70416  110.95293   72.590195] 0.3330174610434144\n",
      "57 81 [ 66.39326387 111.25814778  72.51655412] [ 66.351295 111.664024  72.49112 ] 0.16714406426393735\n",
      "58 48 [ 65.87899136 112.11516559  72.54886901] [ 65.74086 112.16767  72.60818] 0.02535457627521191\n",
      "59 43 [ 64.98290214 112.4908165   72.78532304] [ 65.073425 112.569145  72.79082 ] 0.014360013304585037\n",
      "60 100 [ 64.98290214 112.4908165   72.78532304] [ 64.406   112.97062  72.97346] 0.5984232729007107\n",
      "61 35 [ 64.29398259 113.13638405  73.1149173 ] [ 63.763206 113.35222   73.25842 ] 0.3489016796264498\n",
      "62 43 [ 63.39789337 113.51203495  73.35137133] [ 63.12041 113.73381  73.54338] 0.16304847875532685\n",
      "63 35 [ 62.70897381 114.1576025   73.6809656 ] [ 62.549294 114.19059   73.86769 ] 0.061452353226441825\n",
      "64 22 [ 61.98248265 114.51257332  74.2693586 ] [ 62.059814 114.71285   74.22497 ] 0.04806247609881815\n",
      "65 27 [ 61.58600271 115.34751998  74.65102302] [ 61.72233 115.25674  74.70486] 0.029724314042606212\n",
      "66 100 [ 61.58600271 115.34751998  74.65102302] [ 61.57075  115.807274  75.26516 ] 0.5887699909023559\n",
      "67 6 [ 61.43547094 115.87076736  75.4898033 ] [ 61.606804 116.323166  75.87553 ] 0.382801741682267\n",
      "68 11 [ 61.63851001 116.56188373  76.18344104] [ 61.787964 116.686966  76.56461 ] 0.18327434356884859\n",
      "69 3 [ 61.81582543 116.94484254  77.09002903] [ 62.095764 116.984535  77.24041 ] 0.10255559240619931\n",
      "70 16 [ 62.30705312 117.39852343  77.83358064] [ 62.470287 117.347694  77.84692 ] 0.029406831507682626\n",
      "71 100 [ 62.30705312 117.39852343  77.83358064] [ 62.877445 117.6085    78.48426 ] 0.7928206578920195\n",
      "72 8 [ 62.83730938 117.50475454  78.67473654] [ 63.374397 117.829735  79.070854] 0.5509847641595047\n",
      "73 29 [ 63.57670534 117.9660009   79.16519084] [ 63.9519  118.00918  79.59458] 0.3270121008555045\n",
      "74 21 [ 64.36450619 118.10479657  79.76527882] [ 64.5294  118.18863  80.1183 ] 0.15884402409832032\n",
      "75 21 [ 65.15230704 118.24359224  80.3653668 ] [ 65.22164 118.36775  80.47709] 0.03270477251165042\n",
      "76 100 [ 65.15230704 118.24359224  80.3653668 ] [ 65.90502  118.204315  80.85954 ] 0.812331965175227\n",
      "77 34 [ 66.08146554 118.16405825  80.7263915 ] [ 66.56604 117.86175  81.1523 ] 0.5076004177073307\n",
      "78 26 [ 66.87848559 117.70622367  81.12027795] [ 67.275764 117.51218   81.270996] 0.21820076447030967\n",
      "79 26 [ 67.67550564 117.2483891   81.51416441] [ 67.98549  117.162605  81.389694] 0.11894130894032476\n",
      "80 93 [ 68.57159486 116.8727382   81.27771038] [ 68.68361  116.77217   81.403496] 0.038482895566179474\n",
      "81 39 [ 69.35559395 116.25388933  81.32640848] [ 69.38173  116.38174   81.417305] 0.02529018652631705\n",
      "82 100 [ 69.35559395 116.25388933  81.32640848] [ 70.049164 115.98026   81.234665] 0.5643275425360728\n",
      "83 93 [ 70.25168317 115.87823843  81.08995445] [ 70.653595 115.62223   80.851944] 0.28372212628478977\n",
      "84 72 [ 70.97817433 115.52326761  80.50156146] [ 71.17979 115.19152  80.43051] 0.15575165881868017\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "85 77 [ 71.37465427 114.68832095  80.11989703] [ 71.51727 114.64764  79.95062] 0.05064916668013303\n",
      "86 77 [ 71.77113421 113.85337429  79.73823261] [ 71.773056 113.966225  79.618576] 0.0270565948215478\n"
     ]
    },
    {
     "ename": "IndexError",
     "evalue": "index 101 is out of bounds for axis 0 with size 100",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mIndexError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-10-d5d9477b0f10>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0;31m#all_states.append(env.state.getCoordinate())\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0moptimal_steps\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 8\u001b[0;31m     \u001b[0mnext_state\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdistance\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mterminal\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0menv\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      9\u001b[0m     \u001b[0;31m#distance = lineseg_dist(next_state.getCoordinate().numpy(), referenceLine[step-1].numpy(), referenceLine[np.min([step, len(referenceLine)-1])].numpy())\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     10\u001b[0m     \u001b[0;31m#distance = 2 + (distance/10)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/fibre_tracking/deepFibreTracking/dfibert/envs/RLtractEnvironment.py\u001b[0m in \u001b[0;36mstep\u001b[0;34m(self, action)\u001b[0m\n\u001b[1;32m     86\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     87\u001b[0m             \u001b[0;31m## convert discrete action into tangent vector\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 88\u001b[0;31m             \u001b[0maction_vector\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdirections\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0maction\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     89\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     90\u001b[0m             \u001b[0;31m## apply step by step length and update state accordingly\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mIndexError\u001b[0m: index 101 is out of bounds for axis 0 with size 100"
     ]
    }
   ],
   "source": [
    "env.reset()\n",
    "print(env.state.getCoordinate().numpy(), env.referenceStreamline_ijk[0])\n",
    "step = 1\n",
    "all_distances = []\n",
    "all_states = []\n",
    "#all_states.append(env.state.getCoordinate())\n",
    "for i in optimal_steps:\n",
    "    next_state, distance, terminal = env.step(i)\n",
    "    #distance = lineseg_dist(next_state.getCoordinate().numpy(), referenceLine[step-1].numpy(), referenceLine[np.min([step, len(referenceLine)-1])].numpy())\n",
    "    #distance = 2 + (distance/10)\n",
    "    distance = ((next_state.getCoordinate()[0] - env.referenceStreamline_ijk[np.min([env.stepCounter, 86])][0])**2 \\\n",
    "                      + (next_state.getCoordinate()[1] - env.referenceStreamline_ijk[np.min([env.stepCounter, 86])][1])**2 \\\n",
    "                      + (next_state.getCoordinate()[2] - env.referenceStreamline_ijk[np.min([env.stepCounter, 86])][2])**2)\n",
    "    print(step, i, next_state.getCoordinate().numpy(), env.referenceStreamline_ijk[np.min([env.stepCounter,86])].numpy(), distance.item())\n",
    "    all_distances.append(distance)\n",
    "    all_states.append(next_state.getCoordinate())\n",
    "    #if distance < 0.71:\n",
    "    #    reward = 1 - distance\n",
    "    #    #print(reward)\n",
    "    #    if reward < 0.3:\n",
    "    #        reward = 1\n",
    "    step += 1\n",
    "\n",
    "print(np.min(all_distances), np.max(all_distances), np.sum(all_distances))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/javascript": [
       "/* Put everything inside the global mpl namespace */\n",
       "window.mpl = {};\n",
       "\n",
       "\n",
       "mpl.get_websocket_type = function() {\n",
       "    if (typeof(WebSocket) !== 'undefined') {\n",
       "        return WebSocket;\n",
       "    } else if (typeof(MozWebSocket) !== 'undefined') {\n",
       "        return MozWebSocket;\n",
       "    } else {\n",
       "        alert('Your browser does not have WebSocket support. ' +\n",
       "              'Please try Chrome, Safari or Firefox  6. ' +\n",
       "              'Firefox 4 and 5 are also supported but you ' +\n",
       "              'have to enable WebSockets in about:config.');\n",
       "    };\n",
       "}\n",
       "\n",
       "mpl.figure = function(figure_id, websocket, ondownload, parent_element) {\n",
       "    this.id = figure_id;\n",
       "\n",
       "    this.ws = websocket;\n",
       "\n",
       "    this.supports_binary = (this.ws.binaryType != undefined);\n",
       "\n",
       "    if (!this.supports_binary) {\n",
       "        var warnings = document.getElementById(\"mpl-warnings\");\n",
       "        if (warnings) {\n",
       "            warnings.style.display = 'block';\n",
       "            warnings.textContent = (\n",
       "                \"This browser does not support binary websocket messages. \" +\n",
       "                    \"Performance may be slow.\");\n",
       "        }\n",
       "    }\n",
       "\n",
       "    this.imageObj = new Image();\n",
       "\n",
       "    this.context = undefined;\n",
       "    this.message = undefined;\n",
       "    this.canvas = undefined;\n",
       "    this.rubberband_canvas = undefined;\n",
       "    this.rubberband_context = undefined;\n",
       "    this.format_dropdown = undefined;\n",
       "\n",
       "    this.image_mode = 'full';\n",
       "\n",
       "    this.root = $('<div/>');\n",
       "    this._root_extra_style(this.root)\n",
       "    this.root.attr('style', 'display: inline-block');\n",
       "\n",
       "    $(parent_element).append(this.root);\n",
       "\n",
       "    this._init_header(this);\n",
       "    this._init_canvas(this);\n",
       "    this._init_toolbar(this);\n",
       "\n",
       "    var fig = this;\n",
       "\n",
       "    this.waiting = false;\n",
       "\n",
       "    this.ws.onopen =  function () {\n",
       "            fig.send_message(\"supports_binary\", {value: fig.supports_binary});\n",
       "            fig.send_message(\"send_image_mode\", {});\n",
       "            if (mpl.ratio != 1) {\n",
       "                fig.send_message(\"set_dpi_ratio\", {'dpi_ratio': mpl.ratio});\n",
       "            }\n",
       "            fig.send_message(\"refresh\", {});\n",
       "        }\n",
       "\n",
       "    this.imageObj.onload = function() {\n",
       "            if (fig.image_mode == 'full') {\n",
       "                // Full images could contain transparency (where diff images\n",
       "                // almost always do), so we need to clear the canvas so that\n",
       "                // there is no ghosting.\n",
       "                fig.context.clearRect(0, 0, fig.canvas.width, fig.canvas.height);\n",
       "            }\n",
       "            fig.context.drawImage(fig.imageObj, 0, 0);\n",
       "        };\n",
       "\n",
       "    this.imageObj.onunload = function() {\n",
       "        fig.ws.close();\n",
       "    }\n",
       "\n",
       "    this.ws.onmessage = this._make_on_message_function(this);\n",
       "\n",
       "    this.ondownload = ondownload;\n",
       "}\n",
       "\n",
       "mpl.figure.prototype._init_header = function() {\n",
       "    var titlebar = $(\n",
       "        '<div class=\"ui-dialog-titlebar ui-widget-header ui-corner-all ' +\n",
       "        'ui-helper-clearfix\"/>');\n",
       "    var titletext = $(\n",
       "        '<div class=\"ui-dialog-title\" style=\"width: 100%; ' +\n",
       "        'text-align: center; padding: 3px;\"/>');\n",
       "    titlebar.append(titletext)\n",
       "    this.root.append(titlebar);\n",
       "    this.header = titletext[0];\n",
       "}\n",
       "\n",
       "\n",
       "\n",
       "mpl.figure.prototype._canvas_extra_style = function(canvas_div) {\n",
       "\n",
       "}\n",
       "\n",
       "\n",
       "mpl.figure.prototype._root_extra_style = function(canvas_div) {\n",
       "\n",
       "}\n",
       "\n",
       "mpl.figure.prototype._init_canvas = function() {\n",
       "    var fig = this;\n",
       "\n",
       "    var canvas_div = $('<div/>');\n",
       "\n",
       "    canvas_div.attr('style', 'position: relative; clear: both; outline: 0');\n",
       "\n",
       "    function canvas_keyboard_event(event) {\n",
       "        return fig.key_event(event, event['data']);\n",
       "    }\n",
       "\n",
       "    canvas_div.keydown('key_press', canvas_keyboard_event);\n",
       "    canvas_div.keyup('key_release', canvas_keyboard_event);\n",
       "    this.canvas_div = canvas_div\n",
       "    this._canvas_extra_style(canvas_div)\n",
       "    this.root.append(canvas_div);\n",
       "\n",
       "    var canvas = $('<canvas/>');\n",
       "    canvas.addClass('mpl-canvas');\n",
       "    canvas.attr('style', \"left: 0; top: 0; z-index: 0; outline: 0\")\n",
       "\n",
       "    this.canvas = canvas[0];\n",
       "    this.context = canvas[0].getContext(\"2d\");\n",
       "\n",
       "    var backingStore = this.context.backingStorePixelRatio ||\n",
       "\tthis.context.webkitBackingStorePixelRatio ||\n",
       "\tthis.context.mozBackingStorePixelRatio ||\n",
       "\tthis.context.msBackingStorePixelRatio ||\n",
       "\tthis.context.oBackingStorePixelRatio ||\n",
       "\tthis.context.backingStorePixelRatio || 1;\n",
       "\n",
       "    mpl.ratio = (window.devicePixelRatio || 1) / backingStore;\n",
       "\n",
       "    var rubberband = $('<canvas/>');\n",
       "    rubberband.attr('style', \"position: absolute; left: 0; top: 0; z-index: 1;\")\n",
       "\n",
       "    var pass_mouse_events = true;\n",
       "\n",
       "    canvas_div.resizable({\n",
       "        start: function(event, ui) {\n",
       "            pass_mouse_events = false;\n",
       "        },\n",
       "        resize: function(event, ui) {\n",
       "            fig.request_resize(ui.size.width, ui.size.height);\n",
       "        },\n",
       "        stop: function(event, ui) {\n",
       "            pass_mouse_events = true;\n",
       "            fig.request_resize(ui.size.width, ui.size.height);\n",
       "        },\n",
       "    });\n",
       "\n",
       "    function mouse_event_fn(event) {\n",
       "        if (pass_mouse_events)\n",
       "            return fig.mouse_event(event, event['data']);\n",
       "    }\n",
       "\n",
       "    rubberband.mousedown('button_press', mouse_event_fn);\n",
       "    rubberband.mouseup('button_release', mouse_event_fn);\n",
       "    // Throttle sequential mouse events to 1 every 20ms.\n",
       "    rubberband.mousemove('motion_notify', mouse_event_fn);\n",
       "\n",
       "    rubberband.mouseenter('figure_enter', mouse_event_fn);\n",
       "    rubberband.mouseleave('figure_leave', mouse_event_fn);\n",
       "\n",
       "    canvas_div.on(\"wheel\", function (event) {\n",
       "        event = event.originalEvent;\n",
       "        event['data'] = 'scroll'\n",
       "        if (event.deltaY < 0) {\n",
       "            event.step = 1;\n",
       "        } else {\n",
       "            event.step = -1;\n",
       "        }\n",
       "        mouse_event_fn(event);\n",
       "    });\n",
       "\n",
       "    canvas_div.append(canvas);\n",
       "    canvas_div.append(rubberband);\n",
       "\n",
       "    this.rubberband = rubberband;\n",
       "    this.rubberband_canvas = rubberband[0];\n",
       "    this.rubberband_context = rubberband[0].getContext(\"2d\");\n",
       "    this.rubberband_context.strokeStyle = \"#000000\";\n",
       "\n",
       "    this._resize_canvas = function(width, height) {\n",
       "        // Keep the size of the canvas, canvas container, and rubber band\n",
       "        // canvas in synch.\n",
       "        canvas_div.css('width', width)\n",
       "        canvas_div.css('height', height)\n",
       "\n",
       "        canvas.attr('width', width * mpl.ratio);\n",
       "        canvas.attr('height', height * mpl.ratio);\n",
       "        canvas.attr('style', 'width: ' + width + 'px; height: ' + height + 'px;');\n",
       "\n",
       "        rubberband.attr('width', width);\n",
       "        rubberband.attr('height', height);\n",
       "    }\n",
       "\n",
       "    // Set the figure to an initial 600x600px, this will subsequently be updated\n",
       "    // upon first draw.\n",
       "    this._resize_canvas(600, 600);\n",
       "\n",
       "    // Disable right mouse context menu.\n",
       "    $(this.rubberband_canvas).bind(\"contextmenu\",function(e){\n",
       "        return false;\n",
       "    });\n",
       "\n",
       "    function set_focus () {\n",
       "        canvas.focus();\n",
       "        canvas_div.focus();\n",
       "    }\n",
       "\n",
       "    window.setTimeout(set_focus, 100);\n",
       "}\n",
       "\n",
       "mpl.figure.prototype._init_toolbar = function() {\n",
       "    var fig = this;\n",
       "\n",
       "    var nav_element = $('<div/>');\n",
       "    nav_element.attr('style', 'width: 100%');\n",
       "    this.root.append(nav_element);\n",
       "\n",
       "    // Define a callback function for later on.\n",
       "    function toolbar_event(event) {\n",
       "        return fig.toolbar_button_onclick(event['data']);\n",
       "    }\n",
       "    function toolbar_mouse_event(event) {\n",
       "        return fig.toolbar_button_onmouseover(event['data']);\n",
       "    }\n",
       "\n",
       "    for(var toolbar_ind in mpl.toolbar_items) {\n",
       "        var name = mpl.toolbar_items[toolbar_ind][0];\n",
       "        var tooltip = mpl.toolbar_items[toolbar_ind][1];\n",
       "        var image = mpl.toolbar_items[toolbar_ind][2];\n",
       "        var method_name = mpl.toolbar_items[toolbar_ind][3];\n",
       "\n",
       "        if (!name) {\n",
       "            // put a spacer in here.\n",
       "            continue;\n",
       "        }\n",
       "        var button = $('<button/>');\n",
       "        button.addClass('ui-button ui-widget ui-state-default ui-corner-all ' +\n",
       "                        'ui-button-icon-only');\n",
       "        button.attr('role', 'button');\n",
       "        button.attr('aria-disabled', 'false');\n",
       "        button.click(method_name, toolbar_event);\n",
       "        button.mouseover(tooltip, toolbar_mouse_event);\n",
       "\n",
       "        var icon_img = $('<span/>');\n",
       "        icon_img.addClass('ui-button-icon-primary ui-icon');\n",
       "        icon_img.addClass(image);\n",
       "        icon_img.addClass('ui-corner-all');\n",
       "\n",
       "        var tooltip_span = $('<span/>');\n",
       "        tooltip_span.addClass('ui-button-text');\n",
       "        tooltip_span.html(tooltip);\n",
       "\n",
       "        button.append(icon_img);\n",
       "        button.append(tooltip_span);\n",
       "\n",
       "        nav_element.append(button);\n",
       "    }\n",
       "\n",
       "    var fmt_picker_span = $('<span/>');\n",
       "\n",
       "    var fmt_picker = $('<select/>');\n",
       "    fmt_picker.addClass('mpl-toolbar-option ui-widget ui-widget-content');\n",
       "    fmt_picker_span.append(fmt_picker);\n",
       "    nav_element.append(fmt_picker_span);\n",
       "    this.format_dropdown = fmt_picker[0];\n",
       "\n",
       "    for (var ind in mpl.extensions) {\n",
       "        var fmt = mpl.extensions[ind];\n",
       "        var option = $(\n",
       "            '<option/>', {selected: fmt === mpl.default_extension}).html(fmt);\n",
       "        fmt_picker.append(option);\n",
       "    }\n",
       "\n",
       "    // Add hover states to the ui-buttons\n",
       "    $( \".ui-button\" ).hover(\n",
       "        function() { $(this).addClass(\"ui-state-hover\");},\n",
       "        function() { $(this).removeClass(\"ui-state-hover\");}\n",
       "    );\n",
       "\n",
       "    var status_bar = $('<span class=\"mpl-message\"/>');\n",
       "    nav_element.append(status_bar);\n",
       "    this.message = status_bar[0];\n",
       "}\n",
       "\n",
       "mpl.figure.prototype.request_resize = function(x_pixels, y_pixels) {\n",
       "    // Request matplotlib to resize the figure. Matplotlib will then trigger a resize in the client,\n",
       "    // which will in turn request a refresh of the image.\n",
       "    this.send_message('resize', {'width': x_pixels, 'height': y_pixels});\n",
       "}\n",
       "\n",
       "mpl.figure.prototype.send_message = function(type, properties) {\n",
       "    properties['type'] = type;\n",
       "    properties['figure_id'] = this.id;\n",
       "    this.ws.send(JSON.stringify(properties));\n",
       "}\n",
       "\n",
       "mpl.figure.prototype.send_draw_message = function() {\n",
       "    if (!this.waiting) {\n",
       "        this.waiting = true;\n",
       "        this.ws.send(JSON.stringify({type: \"draw\", figure_id: this.id}));\n",
       "    }\n",
       "}\n",
       "\n",
       "\n",
       "mpl.figure.prototype.handle_save = function(fig, msg) {\n",
       "    var format_dropdown = fig.format_dropdown;\n",
       "    var format = format_dropdown.options[format_dropdown.selectedIndex].value;\n",
       "    fig.ondownload(fig, format);\n",
       "}\n",
       "\n",
       "\n",
       "mpl.figure.prototype.handle_resize = function(fig, msg) {\n",
       "    var size = msg['size'];\n",
       "    if (size[0] != fig.canvas.width || size[1] != fig.canvas.height) {\n",
       "        fig._resize_canvas(size[0], size[1]);\n",
       "        fig.send_message(\"refresh\", {});\n",
       "    };\n",
       "}\n",
       "\n",
       "mpl.figure.prototype.handle_rubberband = function(fig, msg) {\n",
       "    var x0 = msg['x0'] / mpl.ratio;\n",
       "    var y0 = (fig.canvas.height - msg['y0']) / mpl.ratio;\n",
       "    var x1 = msg['x1'] / mpl.ratio;\n",
       "    var y1 = (fig.canvas.height - msg['y1']) / mpl.ratio;\n",
       "    x0 = Math.floor(x0) + 0.5;\n",
       "    y0 = Math.floor(y0) + 0.5;\n",
       "    x1 = Math.floor(x1) + 0.5;\n",
       "    y1 = Math.floor(y1) + 0.5;\n",
       "    var min_x = Math.min(x0, x1);\n",
       "    var min_y = Math.min(y0, y1);\n",
       "    var width = Math.abs(x1 - x0);\n",
       "    var height = Math.abs(y1 - y0);\n",
       "\n",
       "    fig.rubberband_context.clearRect(\n",
       "        0, 0, fig.canvas.width / mpl.ratio, fig.canvas.height / mpl.ratio);\n",
       "\n",
       "    fig.rubberband_context.strokeRect(min_x, min_y, width, height);\n",
       "}\n",
       "\n",
       "mpl.figure.prototype.handle_figure_label = function(fig, msg) {\n",
       "    // Updates the figure title.\n",
       "    fig.header.textContent = msg['label'];\n",
       "}\n",
       "\n",
       "mpl.figure.prototype.handle_cursor = function(fig, msg) {\n",
       "    var cursor = msg['cursor'];\n",
       "    switch(cursor)\n",
       "    {\n",
       "    case 0:\n",
       "        cursor = 'pointer';\n",
       "        break;\n",
       "    case 1:\n",
       "        cursor = 'default';\n",
       "        break;\n",
       "    case 2:\n",
       "        cursor = 'crosshair';\n",
       "        break;\n",
       "    case 3:\n",
       "        cursor = 'move';\n",
       "        break;\n",
       "    }\n",
       "    fig.rubberband_canvas.style.cursor = cursor;\n",
       "}\n",
       "\n",
       "mpl.figure.prototype.handle_message = function(fig, msg) {\n",
       "    fig.message.textContent = msg['message'];\n",
       "}\n",
       "\n",
       "mpl.figure.prototype.handle_draw = function(fig, msg) {\n",
       "    // Request the server to send over a new figure.\n",
       "    fig.send_draw_message();\n",
       "}\n",
       "\n",
       "mpl.figure.prototype.handle_image_mode = function(fig, msg) {\n",
       "    fig.image_mode = msg['mode'];\n",
       "}\n",
       "\n",
       "mpl.figure.prototype.updated_canvas_event = function() {\n",
       "    // Called whenever the canvas gets updated.\n",
       "    this.send_message(\"ack\", {});\n",
       "}\n",
       "\n",
       "// A function to construct a web socket function for onmessage handling.\n",
       "// Called in the figure constructor.\n",
       "mpl.figure.prototype._make_on_message_function = function(fig) {\n",
       "    return function socket_on_message(evt) {\n",
       "        if (evt.data instanceof Blob) {\n",
       "            /* FIXME: We get \"Resource interpreted as Image but\n",
       "             * transferred with MIME type text/plain:\" errors on\n",
       "             * Chrome.  But how to set the MIME type?  It doesn't seem\n",
       "             * to be part of the websocket stream */\n",
       "            evt.data.type = \"image/png\";\n",
       "\n",
       "            /* Free the memory for the previous frames */\n",
       "            if (fig.imageObj.src) {\n",
       "                (window.URL || window.webkitURL).revokeObjectURL(\n",
       "                    fig.imageObj.src);\n",
       "            }\n",
       "\n",
       "            fig.imageObj.src = (window.URL || window.webkitURL).createObjectURL(\n",
       "                evt.data);\n",
       "            fig.updated_canvas_event();\n",
       "            fig.waiting = false;\n",
       "            return;\n",
       "        }\n",
       "        else if (typeof evt.data === 'string' && evt.data.slice(0, 21) == \"data:image/png;base64\") {\n",
       "            fig.imageObj.src = evt.data;\n",
       "            fig.updated_canvas_event();\n",
       "            fig.waiting = false;\n",
       "            return;\n",
       "        }\n",
       "\n",
       "        var msg = JSON.parse(evt.data);\n",
       "        var msg_type = msg['type'];\n",
       "\n",
       "        // Call the  \"handle_{type}\" callback, which takes\n",
       "        // the figure and JSON message as its only arguments.\n",
       "        try {\n",
       "            var callback = fig[\"handle_\" + msg_type];\n",
       "        } catch (e) {\n",
       "            console.log(\"No handler for the '\" + msg_type + \"' message type: \", msg);\n",
       "            return;\n",
       "        }\n",
       "\n",
       "        if (callback) {\n",
       "            try {\n",
       "                // console.log(\"Handling '\" + msg_type + \"' message: \", msg);\n",
       "                callback(fig, msg);\n",
       "            } catch (e) {\n",
       "                console.log(\"Exception inside the 'handler_\" + msg_type + \"' callback:\", e, e.stack, msg);\n",
       "            }\n",
       "        }\n",
       "    };\n",
       "}\n",
       "\n",
       "// from http://stackoverflow.com/questions/1114465/getting-mouse-location-in-canvas\n",
       "mpl.findpos = function(e) {\n",
       "    //this section is from http://www.quirksmode.org/js/events_properties.html\n",
       "    var targ;\n",
       "    if (!e)\n",
       "        e = window.event;\n",
       "    if (e.target)\n",
       "        targ = e.target;\n",
       "    else if (e.srcElement)\n",
       "        targ = e.srcElement;\n",
       "    if (targ.nodeType == 3) // defeat Safari bug\n",
       "        targ = targ.parentNode;\n",
       "\n",
       "    // jQuery normalizes the pageX and pageY\n",
       "    // pageX,Y are the mouse positions relative to the document\n",
       "    // offset() returns the position of the element relative to the document\n",
       "    var x = e.pageX - $(targ).offset().left;\n",
       "    var y = e.pageY - $(targ).offset().top;\n",
       "\n",
       "    return {\"x\": x, \"y\": y};\n",
       "};\n",
       "\n",
       "/*\n",
       " * return a copy of an object with only non-object keys\n",
       " * we need this to avoid circular references\n",
       " * http://stackoverflow.com/a/24161582/3208463\n",
       " */\n",
       "function simpleKeys (original) {\n",
       "  return Object.keys(original).reduce(function (obj, key) {\n",
       "    if (typeof original[key] !== 'object')\n",
       "        obj[key] = original[key]\n",
       "    return obj;\n",
       "  }, {});\n",
       "}\n",
       "\n",
       "mpl.figure.prototype.mouse_event = function(event, name) {\n",
       "    var canvas_pos = mpl.findpos(event)\n",
       "\n",
       "    if (name === 'button_press')\n",
       "    {\n",
       "        this.canvas.focus();\n",
       "        this.canvas_div.focus();\n",
       "    }\n",
       "\n",
       "    var x = canvas_pos.x * mpl.ratio;\n",
       "    var y = canvas_pos.y * mpl.ratio;\n",
       "\n",
       "    this.send_message(name, {x: x, y: y, button: event.button,\n",
       "                             step: event.step,\n",
       "                             guiEvent: simpleKeys(event)});\n",
       "\n",
       "    /* This prevents the web browser from automatically changing to\n",
       "     * the text insertion cursor when the button is pressed.  We want\n",
       "     * to control all of the cursor setting manually through the\n",
       "     * 'cursor' event from matplotlib */\n",
       "    event.preventDefault();\n",
       "    return false;\n",
       "}\n",
       "\n",
       "mpl.figure.prototype._key_event_extra = function(event, name) {\n",
       "    // Handle any extra behaviour associated with a key event\n",
       "}\n",
       "\n",
       "mpl.figure.prototype.key_event = function(event, name) {\n",
       "\n",
       "    // Prevent repeat events\n",
       "    if (name == 'key_press')\n",
       "    {\n",
       "        if (event.which === this._key)\n",
       "            return;\n",
       "        else\n",
       "            this._key = event.which;\n",
       "    }\n",
       "    if (name == 'key_release')\n",
       "        this._key = null;\n",
       "\n",
       "    var value = '';\n",
       "    if (event.ctrlKey && event.which != 17)\n",
       "        value += \"ctrl+\";\n",
       "    if (event.altKey && event.which != 18)\n",
       "        value += \"alt+\";\n",
       "    if (event.shiftKey && event.which != 16)\n",
       "        value += \"shift+\";\n",
       "\n",
       "    value += 'k';\n",
       "    value += event.which.toString();\n",
       "\n",
       "    this._key_event_extra(event, name);\n",
       "\n",
       "    this.send_message(name, {key: value,\n",
       "                             guiEvent: simpleKeys(event)});\n",
       "    return false;\n",
       "}\n",
       "\n",
       "mpl.figure.prototype.toolbar_button_onclick = function(name) {\n",
       "    if (name == 'download') {\n",
       "        this.handle_save(this, null);\n",
       "    } else {\n",
       "        this.send_message(\"toolbar_button\", {name: name});\n",
       "    }\n",
       "};\n",
       "\n",
       "mpl.figure.prototype.toolbar_button_onmouseover = function(tooltip) {\n",
       "    this.message.textContent = tooltip;\n",
       "};\n",
       "mpl.toolbar_items = [[\"Home\", \"Reset original view\", \"fa fa-home icon-home\", \"home\"], [\"Back\", \"Back to previous view\", \"fa fa-arrow-left icon-arrow-left\", \"back\"], [\"Forward\", \"Forward to next view\", \"fa fa-arrow-right icon-arrow-right\", \"forward\"], [\"\", \"\", \"\", \"\"], [\"Pan\", \"Pan axes with left mouse, zoom with right\", \"fa fa-arrows icon-move\", \"pan\"], [\"Zoom\", \"Zoom to rectangle\", \"fa fa-square-o icon-check-empty\", \"zoom\"], [\"\", \"\", \"\", \"\"], [\"Download\", \"Download plot\", \"fa fa-floppy-o icon-save\", \"download\"]];\n",
       "\n",
       "mpl.extensions = [\"eps\", \"jpeg\", \"pdf\", \"png\", \"ps\", \"raw\", \"svg\", \"tif\"];\n",
       "\n",
       "mpl.default_extension = \"png\";var comm_websocket_adapter = function(comm) {\n",
       "    // Create a \"websocket\"-like object which calls the given IPython comm\n",
       "    // object with the appropriate methods. Currently this is a non binary\n",
       "    // socket, so there is still some room for performance tuning.\n",
       "    var ws = {};\n",
       "\n",
       "    ws.close = function() {\n",
       "        comm.close()\n",
       "    };\n",
       "    ws.send = function(m) {\n",
       "        //console.log('sending', m);\n",
       "        comm.send(m);\n",
       "    };\n",
       "    // Register the callback with on_msg.\n",
       "    comm.on_msg(function(msg) {\n",
       "        //console.log('receiving', msg['content']['data'], msg);\n",
       "        // Pass the mpl event to the overridden (by mpl) onmessage function.\n",
       "        ws.onmessage(msg['content']['data'])\n",
       "    });\n",
       "    return ws;\n",
       "}\n",
       "\n",
       "mpl.mpl_figure_comm = function(comm, msg) {\n",
       "    // This is the function which gets called when the mpl process\n",
       "    // starts-up an IPython Comm through the \"matplotlib\" channel.\n",
       "\n",
       "    var id = msg.content.data.id;\n",
       "    // Get hold of the div created by the display call when the Comm\n",
       "    // socket was opened in Python.\n",
       "    var element = $(\"#\" + id);\n",
       "    var ws_proxy = comm_websocket_adapter(comm)\n",
       "\n",
       "    function ondownload(figure, format) {\n",
       "        window.open(figure.imageObj.src);\n",
       "    }\n",
       "\n",
       "    var fig = new mpl.figure(id, ws_proxy,\n",
       "                           ondownload,\n",
       "                           element.get(0));\n",
       "\n",
       "    // Call onopen now - mpl needs it, as it is assuming we've passed it a real\n",
       "    // web socket which is closed, not our websocket->open comm proxy.\n",
       "    ws_proxy.onopen();\n",
       "\n",
       "    fig.parent_element = element.get(0);\n",
       "    fig.cell_info = mpl.find_output_cell(\"<div id='\" + id + \"'></div>\");\n",
       "    if (!fig.cell_info) {\n",
       "        console.error(\"Failed to find cell for figure\", id, fig);\n",
       "        return;\n",
       "    }\n",
       "\n",
       "    var output_index = fig.cell_info[2]\n",
       "    var cell = fig.cell_info[0];\n",
       "\n",
       "};\n",
       "\n",
       "mpl.figure.prototype.handle_close = function(fig, msg) {\n",
       "    var width = fig.canvas.width/mpl.ratio\n",
       "    fig.root.unbind('remove')\n",
       "\n",
       "    // Update the output cell to use the data from the current canvas.\n",
       "    fig.push_to_output();\n",
       "    var dataURL = fig.canvas.toDataURL();\n",
       "    // Re-enable the keyboard manager in IPython - without this line, in FF,\n",
       "    // the notebook keyboard shortcuts fail.\n",
       "    IPython.keyboard_manager.enable()\n",
       "    $(fig.parent_element).html('<img src=\"' + dataURL + '\" width=\"' + width + '\">');\n",
       "    fig.close_ws(fig, msg);\n",
       "}\n",
       "\n",
       "mpl.figure.prototype.close_ws = function(fig, msg){\n",
       "    fig.send_message('closing', msg);\n",
       "    // fig.ws.close()\n",
       "}\n",
       "\n",
       "mpl.figure.prototype.push_to_output = function(remove_interactive) {\n",
       "    // Turn the data on the canvas into data in the output cell.\n",
       "    var width = this.canvas.width/mpl.ratio\n",
       "    var dataURL = this.canvas.toDataURL();\n",
       "    this.cell_info[1]['text/html'] = '<img src=\"' + dataURL + '\" width=\"' + width + '\">';\n",
       "}\n",
       "\n",
       "mpl.figure.prototype.updated_canvas_event = function() {\n",
       "    // Tell IPython that the notebook contents must change.\n",
       "    IPython.notebook.set_dirty(true);\n",
       "    this.send_message(\"ack\", {});\n",
       "    var fig = this;\n",
       "    // Wait a second, then push the new image to the DOM so\n",
       "    // that it is saved nicely (might be nice to debounce this).\n",
       "    setTimeout(function () { fig.push_to_output() }, 1000);\n",
       "}\n",
       "\n",
       "mpl.figure.prototype._init_toolbar = function() {\n",
       "    var fig = this;\n",
       "\n",
       "    var nav_element = $('<div/>');\n",
       "    nav_element.attr('style', 'width: 100%');\n",
       "    this.root.append(nav_element);\n",
       "\n",
       "    // Define a callback function for later on.\n",
       "    function toolbar_event(event) {\n",
       "        return fig.toolbar_button_onclick(event['data']);\n",
       "    }\n",
       "    function toolbar_mouse_event(event) {\n",
       "        return fig.toolbar_button_onmouseover(event['data']);\n",
       "    }\n",
       "\n",
       "    for(var toolbar_ind in mpl.toolbar_items){\n",
       "        var name = mpl.toolbar_items[toolbar_ind][0];\n",
       "        var tooltip = mpl.toolbar_items[toolbar_ind][1];\n",
       "        var image = mpl.toolbar_items[toolbar_ind][2];\n",
       "        var method_name = mpl.toolbar_items[toolbar_ind][3];\n",
       "\n",
       "        if (!name) { continue; };\n",
       "\n",
       "        var button = $('<button class=\"btn btn-default\" href=\"#\" title=\"' + name + '\"><i class=\"fa ' + image + ' fa-lg\"></i></button>');\n",
       "        button.click(method_name, toolbar_event);\n",
       "        button.mouseover(tooltip, toolbar_mouse_event);\n",
       "        nav_element.append(button);\n",
       "    }\n",
       "\n",
       "    // Add the status bar.\n",
       "    var status_bar = $('<span class=\"mpl-message\" style=\"text-align:right; float: right;\"/>');\n",
       "    nav_element.append(status_bar);\n",
       "    this.message = status_bar[0];\n",
       "\n",
       "    // Add the close button to the window.\n",
       "    var buttongrp = $('<div class=\"btn-group inline pull-right\"></div>');\n",
       "    var button = $('<button class=\"btn btn-mini btn-primary\" href=\"#\" title=\"Stop Interaction\"><i class=\"fa fa-power-off icon-remove icon-large\"></i></button>');\n",
       "    button.click(function (evt) { fig.handle_close(fig, {}); } );\n",
       "    button.mouseover('Stop Interaction', toolbar_mouse_event);\n",
       "    buttongrp.append(button);\n",
       "    var titlebar = this.root.find($('.ui-dialog-titlebar'));\n",
       "    titlebar.prepend(buttongrp);\n",
       "}\n",
       "\n",
       "mpl.figure.prototype._root_extra_style = function(el){\n",
       "    var fig = this\n",
       "    el.on(\"remove\", function(){\n",
       "\tfig.close_ws(fig, {});\n",
       "    });\n",
       "}\n",
       "\n",
       "mpl.figure.prototype._canvas_extra_style = function(el){\n",
       "    // this is important to make the div 'focusable\n",
       "    el.attr('tabindex', 0)\n",
       "    // reach out to IPython and tell the keyboard manager to turn it's self\n",
       "    // off when our div gets focus\n",
       "\n",
       "    // location in version 3\n",
       "    if (IPython.notebook.keyboard_manager) {\n",
       "        IPython.notebook.keyboard_manager.register_events(el);\n",
       "    }\n",
       "    else {\n",
       "        // location in version 2\n",
       "        IPython.keyboard_manager.register_events(el);\n",
       "    }\n",
       "\n",
       "}\n",
       "\n",
       "mpl.figure.prototype._key_event_extra = function(event, name) {\n",
       "    var manager = IPython.notebook.keyboard_manager;\n",
       "    if (!manager)\n",
       "        manager = IPython.keyboard_manager;\n",
       "\n",
       "    // Check for shift+enter\n",
       "    if (event.shiftKey && event.which == 13) {\n",
       "        this.canvas_div.blur();\n",
       "        // select the cell after this one\n",
       "        var index = IPython.notebook.find_cell_index(this.cell_info[0]);\n",
       "        IPython.notebook.select(index + 1);\n",
       "    }\n",
       "}\n",
       "\n",
       "mpl.figure.prototype.handle_save = function(fig, msg) {\n",
       "    fig.ondownload(fig, null);\n",
       "}\n",
       "\n",
       "\n",
       "mpl.find_output_cell = function(html_output) {\n",
       "    // Return the cell and output element which can be found *uniquely* in the notebook.\n",
       "    // Note - this is a bit hacky, but it is done because the \"notebook_saving.Notebook\"\n",
       "    // IPython event is triggered only after the cells have been serialised, which for\n",
       "    // our purposes (turning an active figure into a static one), is too late.\n",
       "    var cells = IPython.notebook.get_cells();\n",
       "    var ncells = cells.length;\n",
       "    for (var i=0; i<ncells; i++) {\n",
       "        var cell = cells[i];\n",
       "        if (cell.cell_type === 'code'){\n",
       "            for (var j=0; j<cell.output_area.outputs.length; j++) {\n",
       "                var data = cell.output_area.outputs[j];\n",
       "                if (data.data) {\n",
       "                    // IPython >= 3 moved mimebundle to data attribute of output\n",
       "                    data = data.data;\n",
       "                }\n",
       "                if (data['text/html'] == html_output) {\n",
       "                    return [cell, data, j];\n",
       "                }\n",
       "            }\n",
       "        }\n",
       "    }\n",
       "}\n",
       "\n",
       "// Register the function which deals with the matplotlib target/channel.\n",
       "// The kernel may be null if the page has been refreshed.\n",
       "if (IPython.notebook.kernel != null) {\n",
       "    IPython.notebook.kernel.comm_manager.register_target('matplotlib', mpl.mpl_figure_comm);\n",
       "}\n"
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<img src=\"data:image/png;base64,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\" width=\"640\">"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "[<mpl_toolkits.mplot3d.art3d.Line3D at 0x2aab4ceab0a0>]"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%matplotlib notebook\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "fig = plt.figure()\n",
    "ax = plt.axes(projection='3d')\n",
    "ax.plot3D(referenceLine.T[0], referenceLine.T[1], referenceLine.T[2])\n",
    "ax.plot3D(states.T[0], states.T[1], states.T[2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([73.6513, 74.0524, 74.4534, 74.8544, 75.2555, 75.6565, 75.7944, 75.9323,\n",
      "        76.0702, 76.2082, 76.3461, 76.4840, 76.4840, 76.4840, 77.0143, 77.5445,\n",
      "        77.4865, 78.0168, 78.5471, 79.0773, 79.8038, 80.5303, 81.2568, 81.9833,\n",
      "        82.7098, 83.4363, 84.1627, 84.8892, 85.6157, 86.3422, 87.0687, 86.8657,\n",
      "        86.6626, 86.4596, 86.2566, 86.0535, 85.8505, 85.6474, 85.4444, 85.2414,\n",
      "        85.0383, 84.8353, 84.6854, 84.5356, 84.3857, 84.2359, 84.0328, 83.8298,\n",
      "        83.6267, 83.4237, 83.2207, 83.0176, 82.8146, 82.6115, 82.4085, 82.2055,\n",
      "        82.0024, 81.7994, 81.5964, 81.3933, 81.2435, 81.0404, 80.8374, 80.6343,\n",
      "        80.4313, 80.2283, 80.0252, 79.8222, 79.6191, 78.7231, 78.5732, 78.3702,\n",
      "        78.1671, 77.9641, 77.7610, 77.5580, 77.6160, 77.6739, 77.7319, 77.7899,\n",
      "        77.8478, 77.9058, 77.1088, 76.3118, 75.5148, 74.7177, 73.9207, 73.1237,\n",
      "        72.3267, 71.5297, 70.7326, 69.9356, 69.1386, 69.6298, 70.1210, 70.6123,\n",
      "        71.1035, 71.5947, 72.0860, 72.5772, 73.0684, 73.5596, 74.0509, 73.2538,\n",
      "        72.4568, 71.6598, 70.8628, 71.3540, 71.8452, 72.3365, 72.3365],\n",
      "       dtype=torch.float64)\n"
     ]
    }
   ],
   "source": [
    "states = torch.stack(all_states)\n",
    "print(states.T[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([ 71.7731, 113.9662,  79.6186])\n"
     ]
    }
   ],
   "source": [
    "print(referenceLine[86])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 73.651344 107.88106   93.29415 ] tensor([ 73.6513, 107.8811,  93.2942])\n",
      "tensor(66.2049, dtype=torch.float64)\n"
     ]
    }
   ],
   "source": [
    "env.reset()\n",
    "print(env.state.getCoordinate().numpy(), referenceLine[0])\n",
    "step = 0\n",
    "#all_rewards = []\n",
    "eps_reward = 0\n",
    "for i in optimal_steps:\n",
    "    next_state, distance, terminal = env.step(i)\n",
    "    if distance < 0.71:\n",
    "        reward = 1 - distance\n",
    "        #print(reward)\n",
    "        if reward < 0.3:\n",
    "            reward = 1\n",
    "    eps_reward += reward\n",
    "    #all_rewards.append(reward)\n",
    "    step += 1\n",
    "print(eps_reward)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(n_actions):\n",
    "    \n",
    "    next_state, distance, terminal = env.step(i)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Action:  100 Step:  1 Coordinates:  [ 73.651344 107.88106   93.29415 ] [ 74.42344 107.87124  93.08491]\n",
      "Action:  67 Step:  2 Coordinates:  [ 74.34808267 107.88351105  92.57683017] [ 75.16057  107.88882   92.774536]\n",
      "Action:  100 Step:  3 Coordinates:  [ 74.34808267 107.88351105  92.57683017] [ 75.78847 107.96255  92.28433]\n",
      "Action:  100 Step:  4 Coordinates:  [ 74.34808267 107.88351105  92.57683017] [ 76.45265  108.118454  91.86654 ]\n",
      "Action:  100 Step:  5 Coordinates:  [ 74.34808267 107.88351105  92.57683017] [ 77.116844 108.27435   91.448746]\n",
      "Action:  100 Step:  6 Coordinates:  [ 74.34808267 107.88351105  92.57683017] [ 77.739716 108.54131   91.02359 ]\n",
      "Action:  100 Step:  7 Coordinates:  [ 74.34808267 107.88351105  92.57683017] [ 78.36259  108.80828   90.598434]\n",
      "Action:  100 Step:  8 Coordinates:  [ 74.34808267 107.88351105  92.57683017] [ 78.996666 109.15176   90.25207 ]\n",
      "Action:  100 Step:  9 Coordinates:  [ 74.34808267 107.88351105  92.57683017] [ 79.630745 109.495224  89.9057  ]\n",
      "Action:  100 Step:  10 Coordinates:  [ 74.34808267 107.88351105  92.57683017] [ 80.264824 109.8387    89.55933 ]\n",
      "Action:  100 Step:  11 Coordinates:  [ 74.34808267 107.88351105  92.57683017] [ 80.833374 110.28288   89.21371 ]\n",
      "Action:  100 Step:  12 Coordinates:  [ 74.34808267 107.88351105  92.57683017] [ 81.32385 110.75597  88.79464]\n",
      "Action:  100 Step:  13 Coordinates:  [ 74.34808267 107.88351105  92.57683017] [ 81.78852 111.07612  88.22755]\n",
      "Action:  100 Step:  14 Coordinates:  [ 74.34808267 107.88351105  92.57683017] [ 82.26274  111.20639   87.596565]\n",
      "Action:  100 Step:  15 Coordinates:  [ 74.34808267 107.88351105  92.57683017] [ 82.764885 111.12094   86.97968 ]\n",
      "Action:  100 Step:  16 Coordinates:  [ 74.34808267 107.88351105  92.57683017] [ 83.17989 111.072    86.2975 ]\n",
      "Action:  100 Step:  17 Coordinates:  [ 74.34808267 107.88351105  92.57683017] [ 83.60093  110.91725   85.635086]\n",
      "Action:  100 Step:  18 Coordinates:  [ 74.34808267 107.88351105  92.57683017] [ 84.02196  110.762505  84.97268 ]\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-8-9b9d7b386c25>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[0;32mwhile\u001b[0m \u001b[0mterminal\u001b[0m \u001b[0;34m!=\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m     \u001b[0maction\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrandom\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrandint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mn_actions\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 9\u001b[0;31m     \u001b[0mnext_state\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mreward\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mterminal\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0menv\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0maction\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     10\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mreward\u001b[0m \u001b[0;34m<\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     11\u001b[0m         \u001b[0mactions\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0maction\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/fibre_tracking/deepFibreTracking/dfibert/envs/RLtractEnvironment.py\u001b[0m in \u001b[0;36mstep\u001b[0;34m(self, action)\u001b[0m\n\u001b[1;32m    110\u001b[0m         \u001b[0mpositionNextState\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstate\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgetCoordinate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstepWidth\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0maction_vector\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    111\u001b[0m         \u001b[0mnextState\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mTractographyState\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpositionNextState\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minterpolateDWIatState\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 112\u001b[0;31m         \u001b[0;32mif\u001b[0m \u001b[0mnextState\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgetValue\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    113\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstate\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m-\u001b[0m\u001b[0;36m10\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    114\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/fibre_tracking/deepFibreTracking/dfibert/envs/_state.py\u001b[0m in \u001b[0;36mgetValue\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m     14\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minterpolatedDWI\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     15\u001b[0m         \u001b[0;31m# interpolate DWI value at self.coordinate\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 16\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minterpolatedDWI\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minterpolFuncHandle\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcoordinate\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     17\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minterpolatedDWI\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/fibre_tracking/deepFibreTracking/dfibert/envs/RLtractEnvironment.py\u001b[0m in \u001b[0;36minterpolateDWIatState\u001b[0;34m(self, stateCoordinates)\u001b[0m\n\u001b[1;32m     51\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     52\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 53\u001b[0;31m             \u001b[0minterpolated_dwi\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_interpolated_dwi\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mras_points\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpostprocessing\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdwi_postprocessor\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     54\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mValueError\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     55\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/fibre_tracking/deepFibreTracking/dfibert/data/__init__.py\u001b[0m in \u001b[0;36mget_interpolated_dwi\u001b[0;34m(self, points, postprocessing, ignore_outside_points)\u001b[0m\n\u001b[1;32m    286\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    287\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mpostprocessing\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 288\u001b[0;31m             result = postprocessing(result, self.data.b0, \n\u001b[0m\u001b[1;32m    289\u001b[0m                                  \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbvecs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    290\u001b[0m                                  self.data.bvals)\n",
      "\u001b[0;32m~/fibre_tracking/deepFibreTracking/dfibert/data/postprocessing.py\u001b[0m in \u001b[0;36m_wrapper\u001b[0;34m(dwi, b0, bvecs, bvals)\u001b[0m\n\u001b[1;32m     91\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     92\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_wrapper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdwi\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mb0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbvecs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbvals\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 93\u001b[0;31m         \u001b[0mdata_sh\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mspherical_harmonics\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msh_order\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msh_order\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msmooth\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msmooth\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdwi\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mb0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbvecs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbvals\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     94\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     95\u001b[0m         \u001b[0mdata_resampled\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdot\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata_sh\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mreal_sh\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mT\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/fibre_tracking/deepFibreTracking/dfibert/data/postprocessing.py\u001b[0m in \u001b[0;36m_wrapper\u001b[0;34m(dwi, _b0, bvecs, _bvals)\u001b[0m\n\u001b[1;32m     53\u001b[0m         \u001b[0mreal_sh\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mn\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mreal_sym_sh_mrtrix\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msh_order\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mraw_sphere\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtheta\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mraw_sphere\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mphi\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     54\u001b[0m         \u001b[0ml\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m-\u001b[0m\u001b[0mn\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mn\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 55\u001b[0;31m         \u001b[0minv_b\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msmooth_pinv\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mreal_sh\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msqrt\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msmooth\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0ml\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     56\u001b[0m         \u001b[0mdata_sh\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdot\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdwi\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minv_b\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mT\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     57\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.conda/envs/atari/lib/python3.8/site-packages/dipy/reconst/shm.py\u001b[0m in \u001b[0;36msmooth_pinv\u001b[0;34m(B, L)\u001b[0m\n\u001b[1;32m    661\u001b[0m     \"\"\"\n\u001b[1;32m    662\u001b[0m     \u001b[0mL\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdiag\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mL\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 663\u001b[0;31m     \u001b[0minv\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlinalg\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpinv\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconcatenate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mB\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mL\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    664\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0minv\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m:\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mB\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    665\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<__array_function__ internals>\u001b[0m in \u001b[0;36mpinv\u001b[0;34m(*args, **kwargs)\u001b[0m\n",
      "\u001b[0;32m~/.conda/envs/atari/lib/python3.8/site-packages/numpy/linalg/linalg.py\u001b[0m in \u001b[0;36mpinv\u001b[0;34m(a, rcond, hermitian)\u001b[0m\n\u001b[1;32m   1959\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mwrap\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mres\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1960\u001b[0m     \u001b[0ma\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0ma\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconjugate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1961\u001b[0;31m     \u001b[0mu\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0ms\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvt\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msvd\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0ma\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfull_matrices\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhermitian\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mhermitian\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1962\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1963\u001b[0m     \u001b[0;31m# discard small singular values\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<__array_function__ internals>\u001b[0m in \u001b[0;36msvd\u001b[0;34m(*args, **kwargs)\u001b[0m\n",
      "\u001b[0;32m~/.conda/envs/atari/lib/python3.8/site-packages/numpy/linalg/linalg.py\u001b[0m in \u001b[0;36msvd\u001b[0;34m(a, full_matrices, compute_uv, hermitian)\u001b[0m\n\u001b[1;32m   1624\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1625\u001b[0m         \u001b[0msignature\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m'D->DdD'\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0misComplexType\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mt\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0;34m'd->ddd'\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1626\u001b[0;31m         \u001b[0mu\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0ms\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvh\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mgufunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0ma\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msignature\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msignature\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mextobj\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mextobj\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1627\u001b[0m         \u001b[0mu\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mu\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mastype\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mresult_t\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcopy\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1628\u001b[0m         \u001b[0ms\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0ms\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mastype\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0m_realType\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mresult_t\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcopy\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "env.reset()\n",
    "terminal = False\n",
    "step = 0\n",
    "actions = []\n",
    "past_state = env.state\n",
    "step = 1\n",
    "while terminal != True:\n",
    "    for i in range(n_actions)\n",
    "    action = np.random.randint(n_actions)\n",
    "    next_state, reward, terminal = env.step(action)\n",
    "    if reward < 1:\n",
    "        actions.append(action)\n",
    "        past_state = next_state\n",
    "        print(\"Action: \", action, \"Step: \",step, \"Coordinates: \", next_state.getCoordinate().numpy(), referenceLine[step].numpy())\n",
    "        step += 1\n",
    "    else:\n",
    "        env.state = past_state\n",
    "        env.stepCounter = step\n",
    "    #action = np.random.choice(possible_actions[step])\n",
    "    #next_state, reward, terminal = env.step(action)\n",
    "    #step += 1\n",
    "\n",
    "print(actions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([ 77.7397, 108.5413,  91.0236])\n",
      "tensor([ 78.3626, 108.8083,  90.5984])\n"
     ]
    }
   ],
   "source": [
    "print(referenceLine[6])\n",
    "print(referenceLine[7])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([ 78.1077, 108.7354,  91.6977], dtype=torch.float64)\n",
      "tensor([ 77.7615, 108.8643,  91.6973], dtype=torch.float64)\n",
      "tensor([ 77.8808, 108.4698,  91.6927], dtype=torch.float64)\n",
      "tensor([ 78.0768, 109.0850,  91.6268], dtype=torch.float64)\n",
      "tensor([ 77.5148, 108.5987,  91.6375], dtype=torch.float64)\n",
      "tensor([ 78.3125, 108.4477,  91.5947], dtype=torch.float64)\n",
      "tensor([ 77.7489, 109.2253,  91.5590], dtype=torch.float64)\n",
      "tensor([ 77.6419, 108.2420,  91.5700], dtype=torch.float64)\n",
      "tensor([ 78.4297, 108.8083,  91.5614], dtype=torch.float64)\n",
      "tensor([ 77.4379, 108.9717,  91.5654], dtype=torch.float64)\n",
      "tensor([ 78.0813, 108.1849,  91.5566], dtype=torch.float64)\n",
      "tensor([ 78.1025, 109.3932,  91.4139], dtype=torch.float64)\n",
      "tensor([ 77.3094, 108.3452,  91.4445], dtype=torch.float64)\n",
      "tensor([ 78.6147, 108.4838,  91.3841], dtype=torch.float64)\n",
      "tensor([ 77.4417, 109.2998,  91.3783], dtype=torch.float64)\n",
      "tensor([ 77.8415, 107.9787,  91.4083], dtype=torch.float64)\n",
      "tensor([ 78.3907, 109.1557,  91.4638], dtype=torch.float64)\n",
      "tensor([ 77.2027, 108.6996,  91.4375], dtype=torch.float64)\n",
      "tensor([ 78.4256, 108.1555,  91.3717], dtype=torch.float64)\n",
      "tensor([ 77.7865, 109.5055,  91.3048], dtype=torch.float64)\n",
      "tensor([ 77.4984, 108.0024,  91.3116], dtype=torch.float64)\n",
      "tensor([ 78.6872, 108.8408,  91.3203], dtype=torch.float64)\n",
      "tensor([ 77.1729, 109.0570,  91.3086], dtype=torch.float64)\n",
      "tensor([ 78.1746, 107.9095,  91.2645], dtype=torch.float64)\n",
      "tensor([ 78.3889, 109.4422,  91.1813], dtype=torch.float64)\n",
      "tensor([ 77.0434, 108.4461,  91.1692], dtype=torch.float64)\n",
      "tensor([ 78.6965, 108.2442,  91.1141], dtype=torch.float64)\n",
      "tensor([ 77.5030, 109.5370,  91.1019], dtype=torch.float64)\n",
      "tensor([ 77.5000, 107.8270,  90.9938], dtype=torch.float64)\n",
      "tensor([ 78.6388, 109.1633,  91.2107], dtype=torch.float64)\n",
      "tensor([ 76.9888, 108.7771,  91.1266], dtype=torch.float64)\n",
      "tensor([ 78.4668, 107.9465,  91.0478], dtype=torch.float64)\n",
      "tensor([ 78.0655, 109.6183,  91.0848], dtype=torch.float64)\n",
      "tensor([ 77.2055, 108.1323,  91.1605], dtype=torch.float64)\n",
      "tensor([ 78.8286, 108.6225,  91.0812], dtype=torch.float64)\n",
      "tensor([ 77.2105, 109.3476,  91.0498], dtype=torch.float64)\n",
      "tensor([ 77.8390, 107.7826,  91.1087], dtype=torch.float64)\n",
      "tensor([ 78.6632, 109.3198,  90.9072], dtype=torch.float64)\n",
      "tensor([ 76.9030, 108.6561,  90.7911], dtype=torch.float64)\n",
      "tensor([ 78.6834, 108.0832,  90.7689], dtype=torch.float64)\n",
      "tensor([ 77.7496, 109.6751,  90.8953], dtype=torch.float64)\n",
      "tensor([ 77.2161, 107.9836,  90.8505], dtype=torch.float64)\n",
      "tensor([ 78.8374, 108.9642,  90.9474], dtype=torch.float64)\n",
      "tensor([ 77.0033, 109.0777,  90.9567], dtype=torch.float64)\n",
      "tensor([ 78.1431, 107.7515,  90.9129], dtype=torch.float64)\n",
      "tensor([ 78.3585, 109.5817,  90.8446], dtype=torch.float64)\n",
      "tensor([ 76.9926, 108.2972,  90.8376], dtype=torch.float64)\n",
      "tensor([ 78.8549, 108.4211,  90.8108], dtype=torch.float64)\n",
      "tensor([ 77.3852, 109.5591,  90.7525], dtype=torch.float64)\n",
      "tensor([ 77.7615, 107.7120,  90.7482], dtype=torch.float64)\n",
      "tensor([ 77.6912, 108.6687,  89.7427], dtype=torch.float64)\n",
      "tensor([ 78.0374, 108.5397,  89.7432], dtype=torch.float64)\n",
      "tensor([ 77.9181, 108.9343,  89.7477], dtype=torch.float64)\n",
      "tensor([ 77.7221, 108.3191,  89.8136], dtype=torch.float64)\n",
      "tensor([ 78.2841, 108.8053,  89.8029], dtype=torch.float64)\n",
      "tensor([ 77.4863, 108.9563,  89.8458], dtype=torch.float64)\n",
      "tensor([ 78.0500, 108.1788,  89.8814], dtype=torch.float64)\n",
      "tensor([ 78.1570, 109.1620,  89.8705], dtype=torch.float64)\n",
      "tensor([ 77.3692, 108.5958,  89.8791], dtype=torch.float64)\n",
      "tensor([ 78.3610, 108.4323,  89.8751], dtype=torch.float64)\n",
      "tensor([ 77.7176, 109.2191,  89.8838], dtype=torch.float64)\n",
      "tensor([ 77.6964, 108.0109,  90.0266], dtype=torch.float64)\n",
      "tensor([ 78.4895, 109.0588,  89.9960], dtype=torch.float64)\n",
      "tensor([ 77.1842, 108.9202,  90.0563], dtype=torch.float64)\n",
      "tensor([ 78.3572, 108.1042,  90.0621], dtype=torch.float64)\n",
      "tensor([ 77.9574, 109.4254,  90.0322], dtype=torch.float64)\n",
      "tensor([ 77.4082, 108.2484,  89.9767], dtype=torch.float64)\n",
      "tensor([ 78.5962, 108.7045,  90.0029], dtype=torch.float64)\n",
      "tensor([ 77.3733, 109.2486,  90.0688], dtype=torch.float64)\n",
      "tensor([ 78.0123, 107.8986,  90.1357], dtype=torch.float64)\n",
      "tensor([ 78.3005, 109.4017,  90.1289], dtype=torch.float64)\n",
      "tensor([ 77.1116, 108.5632,  90.1201], dtype=torch.float64)\n",
      "tensor([ 78.6259, 108.3471,  90.1318], dtype=torch.float64)\n",
      "tensor([ 77.6242, 109.4945,  90.1760], dtype=torch.float64)\n",
      "tensor([ 77.4100, 107.9618,  90.2592], dtype=torch.float64)\n",
      "tensor([ 78.7555, 108.9580,  90.2712], dtype=torch.float64)\n",
      "75 [ 78.7555186  108.95801267  90.27122457] [ 78.36259  108.80828   90.598434] 0.2838811622505798\n",
      "tensor([ 77.1024, 109.1599,  90.3263], dtype=torch.float64)\n",
      "tensor([ 78.2959, 107.8671,  90.3386], dtype=torch.float64)\n",
      "tensor([ 78.2988, 109.5771,  90.4467], dtype=torch.float64)\n",
      "tensor([ 77.1600, 108.2408,  90.2298], dtype=torch.float64)\n",
      "tensor([ 78.8100, 108.6269,  90.3138], dtype=torch.float64)\n",
      "tensor([ 77.3321, 109.4575,  90.3926], dtype=torch.float64)\n",
      "tensor([ 77.7333, 107.7858,  90.3557], dtype=torch.float64)\n",
      "tensor([ 78.5934, 109.2718,  90.2799], dtype=torch.float64)\n",
      "tensor([ 76.9703, 108.7816,  90.3592], dtype=torch.float64)\n",
      "tensor([ 78.5884, 108.0565,  90.3906], dtype=torch.float64)\n",
      "tensor([ 77.9598, 109.6215,  90.3317], dtype=torch.float64)\n",
      "tensor([ 77.1356, 108.0842,  90.5333], dtype=torch.float64)\n",
      "tensor([ 78.8959, 108.7480,  90.6493], dtype=torch.float64)\n",
      "88 [ 78.89586077 108.74800996  90.64932975] [ 78.36259  108.80828   90.598434] 0.2906038664155419\n",
      "tensor([ 77.1154, 109.3209,  90.6715], dtype=torch.float64)\n",
      "tensor([ 78.0493, 107.7290,  90.5451], dtype=torch.float64)\n",
      "tensor([ 78.5828, 109.4204,  90.5900], dtype=torch.float64)\n",
      "tensor([ 76.9615, 108.4399,  90.4931], dtype=torch.float64)\n",
      "tensor([ 78.7955, 108.3264,  90.4838], dtype=torch.float64)\n",
      "tensor([ 77.6558, 109.6526,  90.5275], dtype=torch.float64)\n",
      "tensor([ 77.4404, 107.8224,  90.5959], dtype=torch.float64)\n",
      "tensor([ 78.8063, 109.1069,  90.6029], dtype=torch.float64)\n",
      "96 [ 78.80625982 109.10688665  90.60289128] [ 78.36259  108.80828   90.598434] 0.28603082585170475\n",
      "tensor([ 76.9440, 108.9829,  90.6297], dtype=torch.float64)\n",
      "tensor([ 78.4137, 107.8450,  90.6879], dtype=torch.float64)\n",
      "tensor([ 78.0373, 109.6921,  90.6923], dtype=torch.float64)\n",
      "100 [ 77.89944  108.702034  90.72022 ] [ 78.36259  108.80828   90.598434] 0.24062869\n"
     ]
    }
   ],
   "source": [
    "state = TractographyState(torch.Tensor([ 77.8994346, 108.7020324, 90.72022516]), env.interpolateDWIatState)\n",
    "for i in range(n_actions):\n",
    "    env.state = state\n",
    "    env.stepCounter -= 1\n",
    "    next_state, _, terminal = env.step(i)\n",
    "    qry_pt = next_state.getCoordinate().view(-1,3)\n",
    "    distance = torch.min(torch.sum((referenceLine[7] - qry_pt)**2, dim=1))\n",
    "    if distance < 0.3:\n",
    "        print(i, next_state.getCoordinate().numpy(), referenceLine[7].numpy(), distance.numpy())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(187.0214)\n",
      "[ 73.651344 107.88106   93.29415 ]\n",
      "-1\n",
      "True\n"
     ]
    }
   ],
   "source": [
    "env.reset()\n",
    "next_state, reward, terminal = env.step(100)\n",
    "print(next_state.getCoordinate().numpy())\n",
    "print(reward)\n",
    "print(terminal)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[47, 75, 80, 88, 93, 96], [67, 75, 80, 88, 93], [62, 67, 75, 80], [62, 67, 75, 80, 83], [62, 67, 75, 80, 83], [62, 67, 75, 83, 96], [62, 67, 75, 83, 96], [62, 75, 83, 91, 96], [62, 75, 83, 91, 96], [62, 75, 83, 91, 96], [62, 70, 75, 83, 91, 96], [62, 70, 75, 78, 83, 91], [54, 57, 62, 67, 70, 75, 83], [54, 62, 67, 75], [54, 59, 67, 72], [51, 54, 59, 62, 67, 72], [51, 54, 59, 64, 67, 72], [51, 54, 59, 64, 67, 72], [51, 54, 59, 64, 67, 72], [51, 54, 56, 59, 64, 67, 72], [51, 54, 56, 59, 64, 67, 72], [51, 56, 59, 64], [51, 56, 59, 64], [51, 56, 59, 64], [50, 51, 53, 56, 59], [50, 51, 53, 56, 61, 66], [53, 58, 61, 66, 74, 79], [58, 66, 71, 74, 79], [58, 66, 71, 79], [58, 63, 66, 71, 79], [58, 63, 66, 71, 79], [58, 63, 66, 71, 79], [58, 63, 66, 71, 79], [58, 63, 66, 71, 79, 84], [58, 63, 71, 79, 84, 92], [58, 63, 71, 79, 84, 92], [63, 71, 79, 84, 92], [63, 71, 79, 84, 92], [38, 71, 79, 84, 92], [38, 63, 71, 84, 92, 97], [38, 71, 84, 92, 97], [38, 84, 92, 97], [38, 76, 84, 92, 97], [38, 76, 84, 92, 97], [38, 43, 84, 89, 97], [38, 43, 84, 89, 97], [30, 38, 43, 97], [30, 38, 43, 97], [30, 38, 43, 97], [22, 30, 38, 43, 97], [22, 30, 38, 43, 97], [22, 35, 43, 89, 97], [35, 43, 48, 89], [40, 48, 81, 89, 94], [40, 48, 73, 81, 86, 94], [73, 81, 86, 94], [40, 48, 81, 89, 94], [35, 43, 48, 89], [22, 35, 43, 89, 97], [22, 35, 43, 89, 97], [22, 30, 35, 43, 89], [22, 30, 35, 43, 89], [14, 22, 27, 35, 43], [14, 22, 27, 35], [6, 14, 19, 22, 27, 35], [6, 11, 14, 19, 27], [3, 6, 11, 19], [3, 6, 11, 16], [3, 8, 11, 16], [3, 8, 11, 16, 24, 29], [3, 8, 16, 21, 29], [8, 16, 21, 29], [8, 13, 16, 21, 29], [8, 13, 16, 21, 29], [21, 29, 34, 42], [13, 21, 26, 34, 47], [13, 18, 26, 31, 34, 39, 47], [26, 34, 39, 47, 93], [26, 34, 39, 47, 93], [26, 39, 47, 85, 93], [26, 39, 47, 85, 93], [39, 47, 72, 85, 93], [64, 72, 80, 85, 93], [64, 72, 77, 85, 93], [56, 64, 69, 72, 77, 85], [64, 69, 77, 85, 90, 98], [100]]\n"
     ]
    }
   ],
   "source": [
    "print(possible_actions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([ 71.5173, 114.6476,  79.9506])\n",
      "tensor([ 71.7731, 113.9662,  79.6186])\n",
      "[64, 69, 77, 85, 90, 98]\n",
      "tensor([ 71.5173, 114.6476,  79.9506]) tensor(0.4643)\n",
      "tensor([ 71.5173, 114.6476,  79.9506]) tensor(0.4643)\n",
      "tensor([ 71.5173, 114.6476,  79.9506]) tensor(0.4643)\n",
      "tensor([ 71.5173, 114.6476,  79.9506]) tensor(0.4643)\n",
      "tensor([ 71.5173, 114.6476,  79.9506]) tensor(0.4643)\n",
      "tensor([ 71.5173, 114.6476,  79.9506]) tensor(0.4643)\n"
     ]
    }
   ],
   "source": [
    "env.state = TractographyState(referenceLine[85], env.interpolateDWIatState)\n",
    "print(env.state.getCoordinate())\n",
    "print(referenceLine[86])\n",
    "print(possible_actions[85])\n",
    "for i in possible_actions[85]:\n",
    "    env.state = TractographyState(referenceLine[85], env.interpolateDWIatState)\n",
    "    env.stepCounter = 84\n",
    "    next_state, reward, _ = env.step(z)\n",
    "    print(next_state.getCoordinate(), reward)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 71.773056 113.966225  79.618576] [ 72.30127204 114.02878755  79.99932066] 0.27901215525974304\n",
      "[ 71.773056 113.966225  79.618576] [ 71.7609279  113.6971063   80.14330044] 0.2753356828217112\n",
      "[ 71.773056 113.966225  79.618576] [ 71.37937604 113.65758474  79.97858924] 0.15498393104601757\n",
      "[ 71.773056 113.966225  79.618576] [ 71.66780472 114.12438903  79.11184227] 0.2567791198339029\n",
      "[ 71.773056 113.966225  79.618576] [ 71.97880832 114.37794723  79.10548775] 0.26325960220840583\n",
      "[ 71.773056 113.966225  79.618576] [ 71.31423388 113.95652005  79.25698482] 0.2105177635246191\n",
      "[ 71.773056 113.966225  79.618576] [ 71.97504289 114.04982978  79.29253904] 0.10630013104166292\n",
      "[ 71.773056 113.966225  79.618576] [ 71.63016002 113.84417747  79.3660627 ] 0.06376299386222199\n",
      "[ 71.773056 113.966225  79.618576] [ 72.24376411 114.29266559  79.36222956] 0.2215660937612901\n",
      "[ 71.773056 113.966225  79.618576] [ 71.91375289 113.81268975  79.56895814] 0.023572970787664616\n",
      "[ 71.773056 113.966225  79.618576] [ 71.35118583 113.73139254  79.58605126] 0.1779744651043897\n",
      "[ 71.773056 113.966225  79.618576] [ 72.20619251 114.00206886  79.62102829] 0.18760720625139998\n",
      "[ 71.773056 113.966225  79.618576] [ 71.66712842 113.67455586  79.7755295 ] 0.08507069391326497\n",
      "[ 71.773056 113.966225  79.618576] [ 72.03154546 113.7906186   79.91830767] 0.0898390464981324\n"
     ]
    }
   ],
   "source": [
    "#env.state = TractographyState(referenceLine[85], env.interpolateDWIatState)\n",
    "for i in range(n_actions):\n",
    "    env.reset()\n",
    "    env.state = TractographyState(referenceLine[85], env.interpolateDWIatState)\n",
    "    next_state, reward, _ = env.step(i)\n",
    "    distance = env.rewardForTerminalState(next_state)\n",
    "    if distance < 0.3:\n",
    "        print(referenceLine[86].numpy(), next_state.getCoordinate().numpy(), distance.item())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([ 71.7731, 113.9662,  79.6186])\n",
      "tensor(122.0777, dtype=torch.float64)\n"
     ]
    }
   ],
   "source": [
    "distance = env.rewardForTerminalState(next_state)\n",
    "print(referenceLine[86])\n",
    "print(distance)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(n_actions):\n",
    "    env.state = TractographyState(torch.FloatTensor([ 74.64776812, 107.9270337, 93.22325858]), env.interpolateDWIatState)\n",
    "    next_state, reward, _ = env.step(i)\n",
    "    env.stepCounter = 2\n",
    "    if reward < 0.1:\n",
    "        reward = 1\n",
    "    elif reward < 0.5:\n",
    "        reward = 0\n",
    "    else:\n",
    "        reward = -1\n",
    "    if reward == 1:\n",
    "        #best_actions.append(i)\n",
    "        print(\"[{}]\".format(i), referenceLine[2].numpy(), next_state.getCoordinate().numpy(), reward)\n",
    "#print(best_actions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "state = TractographyState(torch.FloatTensor(referenceLine[0]), env.interpolateDWIatState)\n",
    "coordinates = state.getCoordinate()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(referenceLine[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(referenceLine[0])\n",
    "print(referenceLine[70])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "state = TractographyState(referenceLine[69], env.interpolateDWIatState)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "shape = env.reset().getValue().reshape(-1).shape[0]\n",
    "print(shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "state = torch.FloatTensor(state.getValue()).unsqueeze(0).to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "q_vals = agent.main_dqn(state)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(state.getValue().shape)\n",
    "shape = state.getValue().shape\n",
    "shape = np.prod(np.array(shape))\n",
    "print(shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "state = TractographyState(referenceLine[70], env.interpolateDWIatState)\n",
    "qry_pt = torch.FloatTensor(state.getCoordinate()).view(-1,3)\n",
    "distance = torch.min(torch.sum( (referenceLine - qry_pt)**2, dim =1 ))\n",
    "qry_pt = torch.FloatTensor(state.getCoordinate()).view(3)\n",
    "distance_terminal = torch.sum( (referenceLine[-1,:] - qry_pt)**2 )\n",
    "\n",
    "#print(distance)\n",
    "#print(distance_terminal)\n",
    "reward = (torch.tanh(-distance+5.3) + 2*torch.tanh(-distance_terminal+5.3))/2\n",
    "print(reward)\n",
    "\n",
    "print(torch.tanh(-distance+5.3))\n",
    "print(torch.tanh(-distance_terminal+5.3))\n",
    "\n",
    "reward += 200/20 * reward.sign()\n",
    "print(reward)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(torch.tanh(-distance_terminal+5.3)+2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "state = TractographyState([32., 84., 94.], env.interpolateDWIatState)\n",
    "qry_pt = torch.FloatTensor(state.getCoordinate()).view(-1,3)\n",
    "distance = torch.min(torch.sum( (referenceLine - qry_pt)**2, dim =1 ))\n",
    "print(torch.tanh(-distance+5.3))\n",
    "qry_pt = torch.FloatTensor(state.getCoordinate()).view(3)\n",
    "distance = torch.sum( (referenceLine[-1,:] - qry_pt)**2 )\n",
    "print(-distance)\n",
    "print(torch.tanh(-distance)+2)\n",
    "#print(torch.where(distance < env.maxL2dist_to_terminalState, 1, 0 ))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(-1.5 + 5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "qry_pt = torch.FloatTensor(state.getCoordinate()).view(3)\n",
    "distance = torch.sum( (referenceLine[-1,:] - qry_pt)**2 )\n",
    "print(round(-distance.item(),4))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Init agent\")\n",
    "#memory = ReplayMemory(size=replay_memory_size)\n",
    "state = env.reset()\n",
    "agent = Agent(n_actions=n_actions, inp_size=state.getValue().shape, device=device, hidden=256, agent_history_length=agent_history_length, memory_size=replay_memory_size, learning_rate=learning_rate)\n",
    "\n",
    "print(\"Init epsilon-greedy action scheduler\")\n",
    "action_scheduler = Action_Scheduler(num_actions=n_actions, max_steps=max_steps, eps_annealing_steps=100000, replay_memory_start_size=replay_memory_size, model=agent.main_dqn)\n",
    "\n",
    "step_counter = 0\n",
    "    \n",
    "eps_rewards = []\n",
    "\n",
    "print(\"Start training...\")\n",
    "while step_counter < max_steps:\n",
    "    epoch_step = 0\n",
    "\n",
    "######## fill memory begins here\n",
    "    while epoch_step < evaluate_every:  # To Do implement evaluation\n",
    "        state = env.reset()\n",
    "        episode_reward_sum = 0\n",
    "        \n",
    "        #fill replay memory while interacting with env\n",
    "        for episode_counter in range(max_episode_length):\n",
    "            # get action with epsilon-greedy strategy       \n",
    "            action = action_scheduler.get_action(step_counter, torch.FloatTensor(state.getValue()).to(device).unsqueeze(0))\n",
    "                    \n",
    "            next_state, reward, terminal = env.step(action)\n",
    "\n",
    "            if reward >= 1:\n",
    "                reward = 10\n",
    "            elif reward > -0.05:\n",
    "                reward = 1\n",
    "            \n",
    "            if episode_counter == max_episode_length-1:\n",
    "                reward = -100\n",
    "                terminal = True\n",
    "            # increase counter\n",
    "            step_counter += 1\n",
    "            epoch_step += 1\n",
    "\n",
    "            # accumulate reward for current episode\n",
    "            episode_reward_sum += reward\n",
    "\n",
    "\n",
    "            agent.replay_memory.add_experience(action=action,\n",
    "                                state=state.getValue(),\n",
    "                                reward=reward,\n",
    "                                new_state=next_state.getValue(),\n",
    "                                terminal=terminal)\n",
    "\n",
    "\n",
    "            state = next_state\n",
    "\n",
    "        \n",
    "\n",
    "            ####### optimization is happening here\n",
    "            if step_counter > replay_memory_size:\n",
    "                loss = agent.optimize()\n",
    "\n",
    "\n",
    "            ####### target network update\n",
    "            if step_counter > replay_memory_size and step_counter % network_update_every == 0:\n",
    "                agent.target_dqn.load_state_dict(agent.main_dqn.state_dict())\n",
    "            \n",
    "            # if episode ended before maximum step\n",
    "            if terminal:\n",
    "                terminal = False\n",
    "                state = env.reset()\n",
    "                break\n",
    "                \n",
    "        eps_rewards.append(episode_reward_sum)\n",
    "        \n",
    "        if len(eps_rewards) % 10 == 0:\n",
    "            with open(path+'/logs/rewards.dat', 'a') as reward_file:\n",
    "                print(\"[{}] {}, {}\".format(len(eps_rewards), step_counter, np.mean(eps_rewards[-100:])), file=reward_file)\n",
    "            print(\"[{}] {}, {}\".format(len(eps_rewards), step_counter, np.mean(eps_rewards[-100:])) )\n",
    "    torch.save(agent.main_dqn.state_dict(), path+'/checkpoints/fibre_agent_{}_reward_{:.2f}.pth'.format(step_counter, np.mean(eps_rewards[-100:])))\n",
    "########## evaluation starting here\n",
    "    eval_rewards = []\n",
    "    for _ in range(eval_runs):\n",
    "        eval_steps = 0\n",
    "        state = env.reset()\n",
    "        eval_episode_reward = 0\n",
    "        while eval_steps < max_episode_length:\n",
    "            action = action_scheduler.get_action(step_counter, torch.FloatTensor(state.getValue()).to(device).unsqueeze(0), evaluation=True)\n",
    "\n",
    "            next_state, reward, terminal = env.step(action)\n",
    "\n",
    "            eval_steps += 1\n",
    "            eval_episode_reward += reward\n",
    "            state = next_state\n",
    "\n",
    "            if terminal:\n",
    "                terminal = False\n",
    "                break\n",
    "\n",
    "        eval_rewards.append(eval_episode_reward)\n",
    "    \n",
    "    print(\"Evaluation score:\", np.mean(eval_rewards))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#!mkdir -p 'checkpoints/'\n",
    "#torch.save(agent.main_dqn.state_dict(), 'checkpoints/fiber_agent_{}_reward_{:.2f}.pth'.format(step_counter, np.mean(rewards[-100:])))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "CONDA (atari)",
   "language": "python",
   "name": "atari"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
